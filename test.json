{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Kim", "P N2", "V RD1", "Remote Sensing", "Novikov", "J", "Deferred Proofs", "Woodworth", "Lerer", "Eftekhari", "Chou", "V RH1", "Kadri", "Upper", "W", "Deep Convolutional Neural Networks Wies", "Mohlenkamp", "Mulayoff", "Yakira", "Grasedyck", "Felser", "Montangero", "Which", "Hazan", "Gidel", "Yun", "Si S", "Grant", "Li", "Paszke", "Vidal", "R", "M. J. Multivariate", "Terstiege", "J. D. Algorithmic", "W RH1", "Bader", "Vardi", "Criminisi", "Wies", "Ayache", "Bah", "Machine Learning", "Abnar", "Tay", "Left", "Jagadeesan", "H1", "Kohn", "Soudry", "Mont", "Shamir", "P", "Golan", "Weight Decay Ours", "Beylkin", "Blanc", "Lin", "J. L.", "Delingette", "Neyshabur", "Linsley", "Azulay", "Gupta", "Deep Convolutional Neural Networks Cohen", "Yao", "Lee", "Hardt", "Cao", "Desmaison", "Sharir", "Fann", "Taylor", "Sarussi", "Analysis", "Trenti", "Kolda", "Hence", "Wang", "Yanai", "Saxe", "Denote", "Van Gool", "Matrix Analysis", "Deep Learning Workshop", "Tarmoun", "Ergen", "Same Class", "J. Graph", "Tang", "Moroshko", "Low", "Deep Convolutional Neural Networks Contradictions", "Gao", "Elkabetz", "Lampinen", "Razin", "Lyu", "Zygalakis", "Zhang", "Stojevic", "Gissin", "Shashua", "Adlam", "Trager", "Linear Algebra", "Telgarsky", "Steinlechner", "Deep Convolutional Neural Networks Proof", "Zuliani", "Hitchcock", "Implicit", "Krizhevsky", "Lemmas", "Frobenius", "Oymak", "Pennington", "Dehghani", "Metzler", "Mathar", "B", "Globerson", "Sestini", "Bengio", "Recht", "Soltanolkotabi", "Qiao", "U V", "V RD2", "Herrmann", "Gunasekar", "Quantum Science", "Rao", "Implicit Regularization", "Levine", "Harrison", "Chanussot", "T. G. Multilinear", "Pattern Recognition", "Mlynarski", "Luo", "N. Kernel", "Maman", "Arti", "Deep Learning Theory", "Schneider", "Wh1", "Lemma 15", "Standard", "Lemma 3", "Springer", "Navon", "Da Silva", "Perfect P", "Cohen", "Arbitrary Initialization", "Khrulkov", "Deep", "Merkh", "Yang", "Fix T", "Krishnan", "Gross", "Pesme", "Lucchesi", "Bata", "Wei", "Pilanci", "Ganguli", "Physics", "J. D.", "Machine Learning Research", "Oseledets", "Shachaf", "Lemma 2", "Research Institute", "Hackbusch", "J. Gradient", "Teschl", "Deep Convolutional Neural Networks Furthermore", "Tobler", "Benedetti", "L", "Nacson", "Quantum Information", "Rauhut", "Ruder", "Ren", "Joint Conference", "Deep Convolutional Neural Networks Noticing", "Numerical", "Margin", "Chanan", "H. Gradient", "Deep Convolutional Neural Networks", "Jannai", "Optimization", "M. J. Numerical", "A. K.", "Kronecker", "Plaza", "Balda", "Arora", "Kressner", "Garcke", "Bartlett", "Milanesi", "Network Figure", "Source", "N V", "Lemma", "Appendix", "B. W. Tensor", "Deep Convolutional Neural Networks Ji"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Tomassini", "Zhao", "Nature PPSN IV", "Beume", "Springer International Publishing", "Liu", "Nature PPSN XVI", "Agarwal", "Voigt", "Verel", "Tsou", "Nanyang", "Applied Soft", "Tusar", "Li", "Liefooghe", "Ochoa", "Paquete", "Fieldsend", "Springer Berlin Heidelberg", "Miettinen", "Sch", "Doerr", "Batista", "Whitley", "Deb", "Naujoks", "Vega", "Wang", "Blum", "European Journal", "Springer Berlin", "Trautmann", "Bossek", "Louren", "Laredo", "Berlin", "Guo", "Castillo", "Deutz", "Jim enez", "Nature PPSN XV", "Schwefel", "Machinery", "G. Ochoa", "Rechenberg", "Zhang", "Aranha", "Swarm", "Filipic", "Alyahya", "Zhou", "Suganthan", "Meyarivan", "Emmerich", "Colchester", "Campelo", "Aguirre", "Jim", "Kerschke", "Fonseca"]}{"title": ["Model Agnostic Interpretability for Multiple Instance Learning"], "authors": ["[arxiv.Result.Author('Joseph Early'), arxiv.Result.Author('Christine Evers'), arxiv.Result.Author('Sarvapali Ramchurn')]"], "link": ["http://arxiv.org/pdf/2201.11701v1"], "summary": "In Multiple Instance Learning (MIL), models are trained using bags of\ninstances, where only a single label is provided for each bag. A bag label is\noften only determined by a handful of key instances within a bag, making it\ndifficult to interpret what information a classifier is using to make\ndecisions. In this work, we establish the key requirements for interpreting MIL\nmodels. We then go on to develop several model-agnostic approaches that meet\nthese requirements. Our methods are compared against existing inherently\ninterpretable MIL models on several datasets, and achieve an increase in\ninterpretability accuracy of up to 30%. We also examine the ability of the\nmethods to identify interactions between instances and scale to larger\ndatasets, improving their applicability to real-world problems.", "entities_include_in_text": ["Carbonneau\net al., 2018", "Liu et al., 2012", "Gilpin et al., 2018", "Amores, 2013", "Li et al., 2015", "Scott et al.,\n2005; Weidmann et al., 2003", "Tu et al., 2019; Zhou et al., 2009", "Molnar, 2020", "Liu et al., 2012", "Ilse et al., 2018", "Wang et al., 2018), as it produces\ninstance-level predictions as part of its processing. However, these instance-level predictions do\nnot take account of interactions between the instances, so are often inaccurate. A related piece\nof work on MIL interpretability is Tibo et al. (2020", "Wang et al., 2018", "Shapley, 1953", "Dietterich et al., 1997; Andrews et al., 2002", "Sirinukunwattana\net al., 2016) is a collection of microscopy images with annotated nuclei. We follow the same setup as\nIlse et al. (2018", "Everingham et al., 2010", "Garrett, 2021", "as done by Ilse et al. (2018)), however this method then requires\nthe nuclei to be marked for unseen data. This accounts for the difference between our results and\nthe results of Ilse et al. (2018"], "entities_from_reference": ["Plusieurs"]}{"title": ["Constrained Structure Learning for Scene Graph Generation"], "authors": ["[arxiv.Result.Author('Daqi Liu'), arxiv.Result.Author('Miroslaw Bober'), arxiv.Result.Author('Josef Kittler')]"], "link": ["http://arxiv.org/pdf/2201.11697v1"], "summary": "As a structured prediction task, scene graph generation aims to build a\nvisually-grounded scene graph to explicitly model objects and their\nrelationships in an input image. Currently, the mean field variational Bayesian\nframework is the de facto methodology used by the existing methods, in which\nthe unconstrained inference step is often implemented by a message passing\nneural network. However, such formulation fails to explore other inference\nstrategies, and largely ignores the more general constrained optimization\nmodels. In this paper, we present a constrained structure learning method, for\nwhich an explicit constrained variational inference objective is proposed.\nInstead of applying the ubiquitous message-passing strategy, a generic\nconstrained optimization method - entropic mirror descent - is utilized to\nsolve the constrained variational inference step. We validate the proposed\ngeneric model on various popular scene graph generation benchmarks and show\nthat it outperforms the state-of-the-art methods.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Recursive Binding for Similarity-Preserving Hypervector Representations of Sequences"], "authors": ["[arxiv.Result.Author('Dmitri A. Rachkovskij'), arxiv.Result.Author('Denis Kleyko')]"], "link": ["http://arxiv.org/pdf/2201.11691v1"], "summary": "Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC/VSA models.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Generative Adversarial Exploration for Reinforcement Learning"], "authors": ["[arxiv.Result.Author('Weijun Hong'), arxiv.Result.Author('Menghui Zhu'), arxiv.Result.Author('Minghuan Liu'), arxiv.Result.Author('Weinan Zhang'), arxiv.Result.Author('Ming Zhou'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Peng Sun')]"], "link": ["http://arxiv.org/pdf/2201.11685v1"], "summary": "Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Learning Stance Embeddings from Signed Social Graphs"], "authors": ["[arxiv.Result.Author('John Pougu\u00e9-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]"], "link": ["http://arxiv.org/pdf/2201.11675v1"], "summary": "A key challenge in social network analysis is understanding the position, or\nstance, of people in the graph on a large set of topics. While past work has\nmodeled (dis)agreement in social networks using signed graphs, these approaches\nhave not modeled agreement patterns across a range of correlated topics. For\ninstance, disagreement on one topic may make disagreement(or agreement) more\nlikely for related topics. We propose the Stance Embeddings Model(SEM), which\njointly learns embeddings for each user and topic in signed social graphs with\ndistinct edge types for each topic. By jointly learning user and topic\nembeddings, SEM is able to perform cold-start topic stance detection,\npredicting the stance of a user on topics for which we have not observed their\nengagement. We demonstrate the effectiveness of SEM using two large-scale\nTwitter signed graph datasets we open-source. One dataset, TwitterSG, labels\n(dis)agreements using engagements between users via tweets to derive\ntopic-informed, signed edges. The other, BirdwatchSG, leverages community\nreports on misinformation and misleading content. On TwitterSG and BirdwatchSG,\nSEM shows a 39% and 26% error reduction respectively against strong baselines.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrence"], "authors": ["[arxiv.Result.Author('Thomas Guyet'), arxiv.Result.Author('Wenbin Zhang'), arxiv.Result.Author('Albert Bifet')]"], "link": ["http://arxiv.org/pdf/2201.11650v1"], "summary": "The need to analyze information from streams arises in a variety of\napplications. One of the fundamental research directions is to mine sequential\npatterns over data streams. Current studies mine series of items based on the\nexistence of the pattern in transactions but pay no attention to the series of\nitemsets and their multiple occurrences. The pattern over a window of itemsets\nstream and their multiple occurrences, however, provides additional capability\nto recognize the essential characteristics of the patterns and the\ninter-relationships among them that are unidentifiable by the existing items\nand existence based studies. In this paper, we study such a new sequential\npattern mining problem and propose a corresponding efficient sequential miner\nwith novel strategies to prune search space efficiently. Experiments on both\nreal and synthetic data show the utility of our approach.", "entities_include_in_text": [], "entities_from_reference": ["Albert Bifet", "Future Generation", "Liming Zhang", "Knowl", "Mining", "P. F. Wang", "Morteza Zihayat", "Farf", "T. Guyet", "Dieter Pfoser", "Feat", "B. Mortazavi-Asl", "Data Mining Workshops", "Aijun An", "Liang Zhao", "Yun", "Xin Huang", "Daeho Jin", "Mingli Zhang", "J. Han", "Data Sc", "Nele Dexters", "Jeremy", "Nikolaj Tatti", "Zhen Liu", "Nathalie Japkowicz", "Joong Hyuk Chang", "Zhibo Zhang", "Joris JM Gillis", "H. Pinto", "W. Zhang", "Jeremy Weiss", "Research", "Cognitive", "Jianwu Wang", "Wenbin Zhang", "Quiniou", "Boris Cule", "Jie Zhao", "Springer", "J. Wang", "Ruoyu Wang", "Hui Li", "Deyu Tang", "Data Mining", "Xuejiao Tang", "Huang", "Jingjing Li", "Faht", "Joris", "Fair", "Jiangtao Cui", "Jerry Chun-Wei Lin", "Discov", "Vincent S Tseng", "Advanced Applications", "Nuo Wang", "Uday Kiran", "Chu-Feng Li", "Tyler Derr", "Lee", "Data", "Philippe Fournier-Viger", "Lstm", "Knowledge Discovery", "Arnaud Giacometti", "Rincy Thomas", "Thomas Guyet", "Vincent S.", "Yun Sing Koh", "Bart Goethals", "Liuhua Zhang", "Q. Chen", "Bijay Prasad Jaysawal", "Ren", "Wang", "Vincent S. Tseng", "Jeremy C Weiss", "Pat", "Jerry C.", "Mengyu Wang", "Jian Li", "Jerry Chun-Wei", "Actes IAF", "Jerry C. C. Tseng", "Zhichuan Huang", "Rage", "Jianfeng Ma", "Xiangliang Zhang", "Sizhe Peng", "R. Srikant", "Wolfgang Nejdl", "Wenbin", "Zhang", "Chien Lin", "Philippe", "Kea Turner", "Yi Yu", "J. Pei", "U. Dayal", "Jian Tang", "Eirini Ntoutsi", "Won Suk Lee", "Arnaud Soulet", "Jia-Yuan Gu", "Lazaros Oreopoulos"]}{"title": ["Deep Video Prior for Video Consistency and Propagation"], "authors": ["[arxiv.Result.Author('Chenyang Lei'), arxiv.Result.Author('Yazhou Xing'), arxiv.Result.Author('Hao Ouyang'), arxiv.Result.Author('Qifeng Chen')]"], "link": ["http://arxiv.org/pdf/2201.11632v1"], "summary": "Applying an image processing algorithm independently to each video frame\noften leads to temporal inconsistency in the resulting video. To address this\nissue, we present a novel and general approach for blind video temporal\nconsistency. Our method is only trained on a pair of original and processed\nvideos directly instead of a large dataset. Unlike most previous methods that\nenforce temporal consistency with optical flow, we show that temporal\nconsistency can be achieved by training a convolutional neural network on a\nvideo with Deep Video Prior (DVP). Moreover, a carefully designed iteratively\nreweighted training strategy is proposed to address the challenging multimodal\ninconsistency problem. We demonstrate the effectiveness of our approach on 7\ncomputer vision tasks on videos. Extensive quantitative and perceptual\nexperiments show that our approach obtains superior performance than\nstate-of-the-art methods on blind video temporal consistency. We further extend\nDVP to video propagation and demonstrate its effectiveness in propagating three\ndifferent types of information (color, artistic style, and object\nsegmentation). A progressive propagation strategy with pseudo labels is also\nproposed to enhance DVP's performance on video propagation. Our source codes\nare publicly available at https://github.com/ChenyangLEI/deep-video-prior.", "entities_include_in_text": [], "entities_from_reference": ["Abhinav Shrivastava", "Richard Zhang", "Alexander Sorkine-Hornung", "Guilin Liu", "Jonathan Long", "Johannes Kopf", "Michael", "Dan B Goldman", "John Collomosse", "Yizhou Yu", "Jing Liao", "Jia-Bin Huang", "Raviteja Vemulapalli", "Victor Lempitsky", "Victor Lempitsky.", "Shai Avidan", "Boyan Bonev", "Xuhua Huang", "Occlusionaware", "Thomas Brox", "James MacQueen", "James Tompkin", "Jordi Pont-Tuset", "Assaf Shocher", "Frank Wang", "Mach", "Gang Hua", "Chen Chen", "Sylvain Paris", "Nicolas M", "Jian Sun", "Eddy Ilg", "Pattern Anal", "Alan L Yuille", "Shalini De Mello", "Eli Shechtman", "Mohamed Hefeeda", "Matthew Brown", "Li Erran Li", "Satoshi Iizuka", "Andrea Vedaldi", "Nicolas Bonneel", "Chen Fang", "Colorful", "Kevin J. Shih", "James", "Qiong Yan", "Qifeng Chen", "Jumpcut", "Hao Zhang", "Daniel Cremers", "Bryan Catanzaro", "Luc Van Gool", "Michal Irani", "Hanspeter Pfister", "Wenhan Luo", "Justin Johnson", "Changil Kim", "Markus H. Gross.", "Jonas Unger.", "Oliver Wang", "Gharbi", "Jonathan T Barron", "Seoung Wug Oh", "Anat Levin", "Li Fei-Fei", "Alexei A Efros", "Victor Cornill", "Haozhi Huang", "Patchmatch", "Lee", "Markus Gross.", "Sean Bell", "Michael J Black", "Taesung Park", "Rafal K Mantiuk", "Matthias Bethge", "Micha", "Yossi Gandelsman", "Xiaodong Yang", "Brian McWilliams", "Eugene Hsu", "Adam", "Peter V. Gehler", "Zhifeng Li", "Seon Joo Kim", "Ersin", "Erase", "Aysegul Dundar", "Fan Zhong", "Laura LealTaix", "Narendra Ahuja", "Thomas Brox.", "Shai", "Jiawen Chen", "Rodrigo Benenson", "Michael F. Cohen", "Markus Gross", "Noah Snavely", "Jimmy Ba", "Alexey Dosovitskiy", "Zhicheng Yan", "Peter V. Gehler.", "Alireza Fathi", "Chenyang Lei", "Carl Vondrick", "Robust", "Image", "Raquel Urtasun.", "Roy E Welsch", "Zhu", "Nadav Cohen", "Fully", "Yazhou Xing", "Trevor Darrell", "Edgar Simo-Serra", "Markus H. Gross", "Baoyuan Wang", "Light", "Jimmy Ba.", "Single", "Tom Mertens", "Matthew Brown.", "Automatic", "Anna Khoreva", "Video", "Mohammad Shoeybi", "Dan", "Philip Lenz", "Dahun Kim", "Ersin Yumer", "Xiaolong Zhu", "Edgar", "Yair Weiss", "Jan Kautz", "Tomer Michaeli.", "Tamar Rott", "Wojciech Matusik", "Kavita Bala", "Hanspeter Pfister.", "Tali Dekel", "Zhuwen Li", "Alexandre Alahi", "Lu Yuan", "Wenxiu Sun", "Federico Perazzi", "Olaf Ronneberger", "Dani Lischinski", "Varun Jampani", "Vladlen Koltun.", "Haotian Zhang", "Pattern Recognition", "Evan Shelhamer", "Gabriel Eilertsen", "Simone Meyer", "Xiaoou Tang", "Hailin Jin", "Rott Shaham", "Kalyan Sunkavalli", "Raquel Urtasun", "Jiaxin Xie", "Paul W Holland", "Nicolas", "Qingnan Fan", "Wenhan Yang", "Aljoscha Smolic", "Guangyu Zhong", "Lin Ma", "Deep", "Edgar Simo-Serra.", "Dmitry Ulyanov", "Bryan Catanzaro.", "Yang", "Bernt Schiele. Lucid", "Jonas Unger", "Samuel W Hasinoff", "Wei Liu", "Sanghyun Woo", "Jimei Yang", "Tomer Michaeli", "Shuai Yang", "Baoquan Chen", "Victor Cornill`ere", "James MacQueen.", "Nenghai Yu", "Yu Zhu", "Deqing Sun", "Lang", "Jinwei Gu", "Fitsum A. Reda", "Minh N Do", "Alexander S Ecker", "Zhaowen Wang", "Kevin Murphy", "Raghudeep Gadde", "Mohamed Elgharib", "Andreas Geiger", "Adam Finkelstein", "Ingan", "Andrew Tao", "Rick Chang", "Philipp Fischer", "Abdelaziz Djelouah", "Sergio Guadarrama", "Phillip Isola", "Bernt Schiele", "William T Freeman", "Singan", "Xin Lu", "Universal", "Artistic", "Sergi Caelles", "Hao Wang", "Wenhao Jiang", "Christopher Schroers", "Jampani", "Diederik P Kingma", "Hiroshi Ishikawa", "Matthew Joint", "Mengdi Zhang", "Tinghui Zhou", "Daniel Cohen-Or", "Blind", "Tunc Aydin", "Lucid", "Shai Bagon", "Vladlen Koltun"]}{"title": ["LiteLSTM Architecture for Deep Recurrent Neural Networks"], "authors": ["[arxiv.Result.Author('Nelly Elsayed'), arxiv.Result.Author('Zag ElSayed'), arxiv.Result.Author('Anthony S. Maida')]"], "link": ["http://arxiv.org/pdf/2201.11624v1"], "summary": "Long short-term memory (LSTM) is a robust recurrent neural network\narchitecture for learning spatiotemporal sequential data. However, it requires\nsignificant computational power for learning and implementing from both\nsoftware and hardware aspects. This paper proposes a novel LiteLSTM\narchitecture based on reducing the computation components of the LSTM using the\nweights sharing concept to reduce the overall architecture cost and maintain\nthe architecture performance. The proposed LiteLSTM can be significant for\nlearning big data where time-consumption is crucial such as the security of IoT\ndevices and medical data. Moreover, it helps to reduce the CO2 footprint. The\nproposed model was evaluated and tested empirically on two different datasets\nfrom computer vision and cybersecurity domains.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Sharir", "Ganguli", "Recht", "Same Class", "B", "R", "H. Gradient", "Zygalakis", "Rauhut", "Sarussi", "Rao", "Fix T", "Deep Learning Theory", "Deep Convolutional Neural Networks Noticing", "Deep Convolutional Neural Networks Ji", "Lin", "Globerson", "Lee", "Bata", "Steinlechner", "Implicit Regularization", "Zuliani", "Grant", "Si S", "Saxe", "Elkabetz", "Mont", "Trenti", "L", "Hazan", "Deep", "Gao", "Arora", "Qiao", "Perfect P", "Hence", "Da Silva", "Van Gool", "Yakira", "A. K.", "P N2", "Chanan", "Mathar", "Harrison", "Kadri", "Source", "Fann", "Upper", "Physics", "Azulay", "T. G. Multilinear", "Tarmoun", "Bah", "Adlam", "Shachaf", "Arti", "Linear Algebra", "Li", "Lemmas", "Hitchcock", "H1", "Khrulkov", "Lyu", "Mohlenkamp", "Pattern Recognition", "Zhang", "Taylor", "Ren", "Herrmann", "Desmaison", "Blanc", "Vidal", "U V", "Oymak", "Weight Decay Ours", "Implicit", "Arbitrary Initialization", "J", "Joint Conference", "Trager", "N V", "Appendix", "Yun", "J. D. Algorithmic", "Milanesi", "Tang", "Numerical", "Montangero", "Stojevic", "Wies", "J. Gradient", "Garcke", "Woodworth", "Bartlett", "Lampinen", "Cohen", "Merkh", "Deferred Proofs", "Criminisi", "Benedetti", "Which", "Lemma", "Yao", "Bader", "Denote", "Low", "Moroshko", "Ruder", "M. J. Numerical", "Gupta", "Dehghani", "Vardi", "J. D.", "Novikov", "Kressner", "Pesme", "Shamir", "B. W. Tensor", "Machine Learning Research", "Balda", "Chou", "Deep Learning Workshop", "Krishnan", "Soudry", "Metzler", "Machine Learning", "Beylkin", "Network Figure", "Quantum Science", "Left", "Maman", "Krizhevsky", "Jannai", "Golan", "Gissin", "Lerer", "Remote Sensing", "Analysis", "Jagadeesan", "N. Kernel", "Delingette", "Yang", "Telgarsky", "Grasedyck", "Ayache", "Chanussot", "Frobenius", "Felser", "Tobler", "J. L.", "Oseledets", "Standard", "Pennington", "Luo", "Cao", "Shashua", "Kolda", "Levine", "Abnar", "W RH1", "Matrix Analysis", "Deep Convolutional Neural Networks Cohen", "Yanai", "Hackbusch", "Kim", "Deep Convolutional Neural Networks Furthermore", "Lemma 2", "Margin", "Quantum Information", "Hardt", "Kohn", "Bengio", "Pilanci", "Linsley", "Wang", "Ergen", "V RH1", "Lemma 3", "Schneider", "Tay", "J. Graph", "M. J. Multivariate", "Neyshabur", "Terstiege", "Nacson", "Wh1", "Gidel", "Eftekhari", "Mlynarski", "Kronecker", "Deep Convolutional Neural Networks Contradictions", "Navon", "Wei", "Soltanolkotabi", "V RD1", "Teschl", "Lucchesi", "W", "Research Institute", "Optimization", "V RD2", "Springer", "Gross", "Deep Convolutional Neural Networks", "Gunasekar", "Razin", "Lemma 15", "Mulayoff", "Paszke", "Deep Convolutional Neural Networks Wies", "P", "Deep Convolutional Neural Networks Proof", "Plaza", "Sestini"]}