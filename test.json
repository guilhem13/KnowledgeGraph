{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Kim", "P N2", "V RD1", "Remote Sensing", "Novikov", "J", "Deferred Proofs", "Woodworth", "Lerer", "Eftekhari", "Chou", "V RH1", "Kadri", "Upper", "W", "Deep Convolutional Neural Networks Wies", "Mohlenkamp", "Mulayoff", "Yakira", "Grasedyck", "Felser", "Montangero", "Which", "Hazan", "Gidel", "Yun", "Si S", "Grant", "Li", "Paszke", "Vidal", "R", "M. J. Multivariate", "Terstiege", "J. D. Algorithmic", "W RH1", "Bader", "Vardi", "Criminisi", "Wies", "Ayache", "Bah", "Machine Learning", "Abnar", "Tay", "Left", "Jagadeesan", "H1", "Kohn", "Soudry", "Mont", "Shamir", "P", "Golan", "Weight Decay Ours", "Beylkin", "Blanc", "Lin", "J. L.", "Delingette", "Neyshabur", "Linsley", "Azulay", "Gupta", "Deep Convolutional Neural Networks Cohen", "Yao", "Lee", "Hardt", "Cao", "Desmaison", "Sharir", "Fann", "Taylor", "Sarussi", "Analysis", "Trenti", "Kolda", "Hence", "Wang", "Yanai", "Saxe", "Denote", "Van Gool", "Matrix Analysis", "Deep Learning Workshop", "Tarmoun", "Ergen", "Same Class", "J. Graph", "Tang", "Moroshko", "Low", "Deep Convolutional Neural Networks Contradictions", "Gao", "Elkabetz", "Lampinen", "Razin", "Lyu", "Zygalakis", "Zhang", "Stojevic", "Gissin", "Shashua", "Adlam", "Trager", "Linear Algebra", "Telgarsky", "Steinlechner", "Deep Convolutional Neural Networks Proof", "Zuliani", "Hitchcock", "Implicit", "Krizhevsky", "Lemmas", "Frobenius", "Oymak", "Pennington", "Dehghani", "Metzler", "Mathar", "B", "Globerson", "Sestini", "Bengio", "Recht", "Soltanolkotabi", "Qiao", "U V", "V RD2", "Herrmann", "Gunasekar", "Quantum Science", "Rao", "Implicit Regularization", "Levine", "Harrison", "Chanussot", "T. G. Multilinear", "Pattern Recognition", "Mlynarski", "Luo", "N. Kernel", "Maman", "Arti", "Deep Learning Theory", "Schneider", "Wh1", "Lemma 15", "Standard", "Lemma 3", "Springer", "Navon", "Da Silva", "Perfect P", "Cohen", "Arbitrary Initialization", "Khrulkov", "Deep", "Merkh", "Yang", "Fix T", "Krishnan", "Gross", "Pesme", "Lucchesi", "Bata", "Wei", "Pilanci", "Ganguli", "Physics", "J. D.", "Machine Learning Research", "Oseledets", "Shachaf", "Lemma 2", "Research Institute", "Hackbusch", "J. Gradient", "Teschl", "Deep Convolutional Neural Networks Furthermore", "Tobler", "Benedetti", "L", "Nacson", "Quantum Information", "Rauhut", "Ruder", "Ren", "Joint Conference", "Deep Convolutional Neural Networks Noticing", "Numerical", "Margin", "Chanan", "H. Gradient", "Deep Convolutional Neural Networks", "Jannai", "Optimization", "M. J. Numerical", "A. K.", "Kronecker", "Plaza", "Balda", "Arora", "Kressner", "Garcke", "Bartlett", "Milanesi", "Network Figure", "Source", "N V", "Lemma", "Appendix", "B. W. Tensor", "Deep Convolutional Neural Networks Ji"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Tomassini", "Zhao", "Nature PPSN IV", "Beume", "Springer International Publishing", "Liu", "Nature PPSN XVI", "Agarwal", "Voigt", "Verel", "Tsou", "Nanyang", "Applied Soft", "Tusar", "Li", "Liefooghe", "Ochoa", "Paquete", "Fieldsend", "Springer Berlin Heidelberg", "Miettinen", "Sch", "Doerr", "Batista", "Whitley", "Deb", "Naujoks", "Vega", "Wang", "Blum", "European Journal", "Springer Berlin", "Trautmann", "Bossek", "Louren", "Laredo", "Berlin", "Guo", "Castillo", "Deutz", "Jim enez", "Nature PPSN XV", "Schwefel", "Machinery", "G. Ochoa", "Rechenberg", "Zhang", "Aranha", "Swarm", "Filipic", "Alyahya", "Zhou", "Suganthan", "Meyarivan", "Emmerich", "Colchester", "Campelo", "Aguirre", "Jim", "Kerschke", "Fonseca"]}{"title": ["Model Agnostic Interpretability for Multiple Instance Learning"], "authors": ["[arxiv.Result.Author('Joseph Early'), arxiv.Result.Author('Christine Evers'), arxiv.Result.Author('Sarvapali Ramchurn')]"], "link": ["http://arxiv.org/pdf/2201.11701v1"], "summary": "In Multiple Instance Learning (MIL), models are trained using bags of\ninstances, where only a single label is provided for each bag. A bag label is\noften only determined by a handful of key instances within a bag, making it\ndifficult to interpret what information a classifier is using to make\ndecisions. In this work, we establish the key requirements for interpreting MIL\nmodels. We then go on to develop several model-agnostic approaches that meet\nthese requirements. Our methods are compared against existing inherently\ninterpretable MIL models on several datasets, and achieve an increase in\ninterpretability accuracy of up to 30%. We also examine the ability of the\nmethods to identify interactions between instances and scale to larger\ndatasets, improving their applicability to real-world problems.", "entities_include_in_text": ["Carbonneau\net al., 2018", "Liu et al., 2012", "Gilpin et al., 2018", "Amores, 2013", "Li et al., 2015", "Scott et al.,\n2005; Weidmann et al., 2003", "Tu et al., 2019; Zhou et al., 2009", "Molnar, 2020", "Liu et al., 2012", "Ilse et al., 2018", "Wang et al., 2018), as it produces\ninstance-level predictions as part of its processing. However, these instance-level predictions do\nnot take account of interactions between the instances, so are often inaccurate. A related piece\nof work on MIL interpretability is Tibo et al. (2020", "Wang et al., 2018", "Shapley, 1953", "Dietterich et al., 1997; Andrews et al., 2002", "Sirinukunwattana\net al., 2016) is a collection of microscopy images with annotated nuclei. We follow the same setup as\nIlse et al. (2018", "Everingham et al., 2010", "Garrett, 2021", "as done by Ilse et al. (2018)), however this method then requires\nthe nuclei to be marked for unseen data. This accounts for the difference between our results and\nthe results of Ilse et al. (2018"], "entities_from_reference": ["Plusieurs"]}{"title": ["Constrained Structure Learning for Scene Graph Generation"], "authors": ["[arxiv.Result.Author('Daqi Liu'), arxiv.Result.Author('Miroslaw Bober'), arxiv.Result.Author('Josef Kittler')]"], "link": ["http://arxiv.org/pdf/2201.11697v1"], "summary": "As a structured prediction task, scene graph generation aims to build a\nvisually-grounded scene graph to explicitly model objects and their\nrelationships in an input image. Currently, the mean field variational Bayesian\nframework is the de facto methodology used by the existing methods, in which\nthe unconstrained inference step is often implemented by a message passing\nneural network. However, such formulation fails to explore other inference\nstrategies, and largely ignores the more general constrained optimization\nmodels. In this paper, we present a constrained structure learning method, for\nwhich an explicit constrained variational inference objective is proposed.\nInstead of applying the ubiquitous message-passing strategy, a generic\nconstrained optimization method - entropic mirror descent - is utilized to\nsolve the constrained variational inference step. We validate the proposed\ngeneric model on various popular scene graph generation benchmarks and show\nthat it outperforms the state-of-the-art methods.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Recursive Binding for Similarity-Preserving Hypervector Representations of Sequences"], "authors": ["[arxiv.Result.Author('Dmitri A. Rachkovskij'), arxiv.Result.Author('Denis Kleyko')]"], "link": ["http://arxiv.org/pdf/2201.11691v1"], "summary": "Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC/VSA models.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Generative Adversarial Exploration for Reinforcement Learning"], "authors": ["[arxiv.Result.Author('Weijun Hong'), arxiv.Result.Author('Menghui Zhu'), arxiv.Result.Author('Minghuan Liu'), arxiv.Result.Author('Weinan Zhang'), arxiv.Result.Author('Ming Zhou'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Peng Sun')]"], "link": ["http://arxiv.org/pdf/2201.11685v1"], "summary": "Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Learning Stance Embeddings from Signed Social Graphs"], "authors": ["[arxiv.Result.Author('John Pougu\u00e9-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]"], "link": ["http://arxiv.org/pdf/2201.11675v1"], "summary": "A key challenge in social network analysis is understanding the position, or\nstance, of people in the graph on a large set of topics. While past work has\nmodeled (dis)agreement in social networks using signed graphs, these approaches\nhave not modeled agreement patterns across a range of correlated topics. For\ninstance, disagreement on one topic may make disagreement(or agreement) more\nlikely for related topics. We propose the Stance Embeddings Model(SEM), which\njointly learns embeddings for each user and topic in signed social graphs with\ndistinct edge types for each topic. By jointly learning user and topic\nembeddings, SEM is able to perform cold-start topic stance detection,\npredicting the stance of a user on topics for which we have not observed their\nengagement. We demonstrate the effectiveness of SEM using two large-scale\nTwitter signed graph datasets we open-source. One dataset, TwitterSG, labels\n(dis)agreements using engagements between users via tweets to derive\ntopic-informed, signed edges. The other, BirdwatchSG, leverages community\nreports on misinformation and misleading content. On TwitterSG and BirdwatchSG,\nSEM shows a 39% and 26% error reduction respectively against strong baselines.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrence"], "authors": ["[arxiv.Result.Author('Thomas Guyet'), arxiv.Result.Author('Wenbin Zhang'), arxiv.Result.Author('Albert Bifet')]"], "link": ["http://arxiv.org/pdf/2201.11650v1"], "summary": "The need to analyze information from streams arises in a variety of\napplications. One of the fundamental research directions is to mine sequential\npatterns over data streams. Current studies mine series of items based on the\nexistence of the pattern in transactions but pay no attention to the series of\nitemsets and their multiple occurrences. The pattern over a window of itemsets\nstream and their multiple occurrences, however, provides additional capability\nto recognize the essential characteristics of the patterns and the\ninter-relationships among them that are unidentifiable by the existing items\nand existence based studies. In this paper, we study such a new sequential\npattern mining problem and propose a corresponding efficient sequential miner\nwith novel strategies to prune search space efficiently. Experiments on both\nreal and synthetic data show the utility of our approach.", "entities_include_in_text": [], "entities_from_reference": ["Albert Bifet", "Future Generation", "Liming Zhang", "Knowl", "Mining", "P. F. Wang", "Morteza Zihayat", "Farf", "T. Guyet", "Dieter Pfoser", "Feat", "B. Mortazavi-Asl", "Data Mining Workshops", "Aijun An", "Liang Zhao", "Yun", "Xin Huang", "Daeho Jin", "Mingli Zhang", "J. Han", "Data Sc", "Nele Dexters", "Jeremy", "Nikolaj Tatti", "Zhen Liu", "Nathalie Japkowicz", "Joong Hyuk Chang", "Zhibo Zhang", "Joris JM Gillis", "H. Pinto", "W. Zhang", "Jeremy Weiss", "Research", "Cognitive", "Jianwu Wang", "Wenbin Zhang", "Quiniou", "Boris Cule", "Jie Zhao", "Springer", "J. Wang", "Ruoyu Wang", "Hui Li", "Deyu Tang", "Data Mining", "Xuejiao Tang", "Huang", "Jingjing Li", "Faht", "Joris", "Fair", "Jiangtao Cui", "Jerry Chun-Wei Lin", "Discov", "Vincent S Tseng", "Advanced Applications", "Nuo Wang", "Uday Kiran", "Chu-Feng Li", "Tyler Derr", "Lee", "Data", "Philippe Fournier-Viger", "Lstm", "Knowledge Discovery", "Arnaud Giacometti", "Rincy Thomas", "Thomas Guyet", "Vincent S.", "Yun Sing Koh", "Bart Goethals", "Liuhua Zhang", "Q. Chen", "Bijay Prasad Jaysawal", "Ren", "Wang", "Vincent S. Tseng", "Jeremy C Weiss", "Pat", "Jerry C.", "Mengyu Wang", "Jian Li", "Jerry Chun-Wei", "Actes IAF", "Jerry C. C. Tseng", "Zhichuan Huang", "Rage", "Jianfeng Ma", "Xiangliang Zhang", "Sizhe Peng", "R. Srikant", "Wolfgang Nejdl", "Wenbin", "Zhang", "Chien Lin", "Philippe", "Kea Turner", "Yi Yu", "J. Pei", "U. Dayal", "Jian Tang", "Eirini Ntoutsi", "Won Suk Lee", "Arnaud Soulet", "Jia-Yuan Gu", "Lazaros Oreopoulos"]}{"title": ["Deep Video Prior for Video Consistency and Propagation"], "authors": ["[arxiv.Result.Author('Chenyang Lei'), arxiv.Result.Author('Yazhou Xing'), arxiv.Result.Author('Hao Ouyang'), arxiv.Result.Author('Qifeng Chen')]"], "link": ["http://arxiv.org/pdf/2201.11632v1"], "summary": "Applying an image processing algorithm independently to each video frame\noften leads to temporal inconsistency in the resulting video. To address this\nissue, we present a novel and general approach for blind video temporal\nconsistency. Our method is only trained on a pair of original and processed\nvideos directly instead of a large dataset. Unlike most previous methods that\nenforce temporal consistency with optical flow, we show that temporal\nconsistency can be achieved by training a convolutional neural network on a\nvideo with Deep Video Prior (DVP). Moreover, a carefully designed iteratively\nreweighted training strategy is proposed to address the challenging multimodal\ninconsistency problem. We demonstrate the effectiveness of our approach on 7\ncomputer vision tasks on videos. Extensive quantitative and perceptual\nexperiments show that our approach obtains superior performance than\nstate-of-the-art methods on blind video temporal consistency. We further extend\nDVP to video propagation and demonstrate its effectiveness in propagating three\ndifferent types of information (color, artistic style, and object\nsegmentation). A progressive propagation strategy with pseudo labels is also\nproposed to enhance DVP's performance on video propagation. Our source codes\nare publicly available at https://github.com/ChenyangLEI/deep-video-prior.", "entities_include_in_text": [], "entities_from_reference": ["Abhinav Shrivastava", "Richard Zhang", "Alexander Sorkine-Hornung", "Guilin Liu", "Jonathan Long", "Johannes Kopf", "Michael", "Dan B Goldman", "John Collomosse", "Yizhou Yu", "Jing Liao", "Jia-Bin Huang", "Raviteja Vemulapalli", "Victor Lempitsky", "Victor Lempitsky.", "Shai Avidan", "Boyan Bonev", "Xuhua Huang", "Occlusionaware", "Thomas Brox", "James MacQueen", "James Tompkin", "Jordi Pont-Tuset", "Assaf Shocher", "Frank Wang", "Mach", "Gang Hua", "Chen Chen", "Sylvain Paris", "Nicolas M", "Jian Sun", "Eddy Ilg", "Pattern Anal", "Alan L Yuille", "Shalini De Mello", "Eli Shechtman", "Mohamed Hefeeda", "Matthew Brown", "Li Erran Li", "Satoshi Iizuka", "Andrea Vedaldi", "Nicolas Bonneel", "Chen Fang", "Colorful", "Kevin J. Shih", "James", "Qiong Yan", "Qifeng Chen", "Jumpcut", "Hao Zhang", "Daniel Cremers", "Bryan Catanzaro", "Luc Van Gool", "Michal Irani", "Hanspeter Pfister", "Wenhan Luo", "Justin Johnson", "Changil Kim", "Markus H. Gross.", "Jonas Unger.", "Oliver Wang", "Gharbi", "Jonathan T Barron", "Seoung Wug Oh", "Anat Levin", "Li Fei-Fei", "Alexei A Efros", "Victor Cornill", "Haozhi Huang", "Patchmatch", "Lee", "Markus Gross.", "Sean Bell", "Michael J Black", "Taesung Park", "Rafal K Mantiuk", "Matthias Bethge", "Micha", "Yossi Gandelsman", "Xiaodong Yang", "Brian McWilliams", "Eugene Hsu", "Adam", "Peter V. Gehler", "Zhifeng Li", "Seon Joo Kim", "Ersin", "Erase", "Aysegul Dundar", "Fan Zhong", "Laura LealTaix", "Narendra Ahuja", "Thomas Brox.", "Shai", "Jiawen Chen", "Rodrigo Benenson", "Michael F. Cohen", "Markus Gross", "Noah Snavely", "Jimmy Ba", "Alexey Dosovitskiy", "Zhicheng Yan", "Peter V. Gehler.", "Alireza Fathi", "Chenyang Lei", "Carl Vondrick", "Robust", "Image", "Raquel Urtasun.", "Roy E Welsch", "Zhu", "Nadav Cohen", "Fully", "Yazhou Xing", "Trevor Darrell", "Edgar Simo-Serra", "Markus H. Gross", "Baoyuan Wang", "Light", "Jimmy Ba.", "Single", "Tom Mertens", "Matthew Brown.", "Automatic", "Anna Khoreva", "Video", "Mohammad Shoeybi", "Dan", "Philip Lenz", "Dahun Kim", "Ersin Yumer", "Xiaolong Zhu", "Edgar", "Yair Weiss", "Jan Kautz", "Tomer Michaeli.", "Tamar Rott", "Wojciech Matusik", "Kavita Bala", "Hanspeter Pfister.", "Tali Dekel", "Zhuwen Li", "Alexandre Alahi", "Lu Yuan", "Wenxiu Sun", "Federico Perazzi", "Olaf Ronneberger", "Dani Lischinski", "Varun Jampani", "Vladlen Koltun.", "Haotian Zhang", "Pattern Recognition", "Evan Shelhamer", "Gabriel Eilertsen", "Simone Meyer", "Xiaoou Tang", "Hailin Jin", "Rott Shaham", "Kalyan Sunkavalli", "Raquel Urtasun", "Jiaxin Xie", "Paul W Holland", "Nicolas", "Qingnan Fan", "Wenhan Yang", "Aljoscha Smolic", "Guangyu Zhong", "Lin Ma", "Deep", "Edgar Simo-Serra.", "Dmitry Ulyanov", "Bryan Catanzaro.", "Yang", "Bernt Schiele. Lucid", "Jonas Unger", "Samuel W Hasinoff", "Wei Liu", "Sanghyun Woo", "Jimei Yang", "Tomer Michaeli", "Shuai Yang", "Baoquan Chen", "Victor Cornill`ere", "James MacQueen.", "Nenghai Yu", "Yu Zhu", "Deqing Sun", "Lang", "Jinwei Gu", "Fitsum A. Reda", "Minh N Do", "Alexander S Ecker", "Zhaowen Wang", "Kevin Murphy", "Raghudeep Gadde", "Mohamed Elgharib", "Andreas Geiger", "Adam Finkelstein", "Ingan", "Andrew Tao", "Rick Chang", "Philipp Fischer", "Abdelaziz Djelouah", "Sergio Guadarrama", "Phillip Isola", "Bernt Schiele", "William T Freeman", "Singan", "Xin Lu", "Universal", "Artistic", "Sergi Caelles", "Hao Wang", "Wenhao Jiang", "Christopher Schroers", "Jampani", "Diederik P Kingma", "Hiroshi Ishikawa", "Matthew Joint", "Mengdi Zhang", "Tinghui Zhou", "Daniel Cohen-Or", "Blind", "Tunc Aydin", "Lucid", "Shai Bagon", "Vladlen Koltun"]}{"title": ["LiteLSTM Architecture for Deep Recurrent Neural Networks"], "authors": ["[arxiv.Result.Author('Nelly Elsayed'), arxiv.Result.Author('Zag ElSayed'), arxiv.Result.Author('Anthony S. Maida')]"], "link": ["http://arxiv.org/pdf/2201.11624v1"], "summary": "Long short-term memory (LSTM) is a robust recurrent neural network\narchitecture for learning spatiotemporal sequential data. However, it requires\nsignificant computational power for learning and implementing from both\nsoftware and hardware aspects. This paper proposes a novel LiteLSTM\narchitecture based on reducing the computation components of the LSTM using the\nweights sharing concept to reduce the overall architecture cost and maintain\nthe architecture performance. The proposed LiteLSTM can be significant for\nlearning big data where time-consumption is crucial such as the security of IoT\ndevices and medical data. Moreover, it helps to reduce the CO2 footprint. The\nproposed model was evaluated and tested empirically on two different datasets\nfrom computer vision and cybersecurity domains.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Sharir", "Ganguli", "Recht", "Same Class", "B", "R", "H. Gradient", "Zygalakis", "Rauhut", "Sarussi", "Rao", "Fix T", "Deep Learning Theory", "Deep Convolutional Neural Networks Noticing", "Deep Convolutional Neural Networks Ji", "Lin", "Globerson", "Lee", "Bata", "Steinlechner", "Implicit Regularization", "Zuliani", "Grant", "Si S", "Saxe", "Elkabetz", "Mont", "Trenti", "L", "Hazan", "Deep", "Gao", "Arora", "Qiao", "Perfect P", "Hence", "Da Silva", "Van Gool", "Yakira", "A. K.", "P N2", "Chanan", "Mathar", "Harrison", "Kadri", "Source", "Fann", "Upper", "Physics", "Azulay", "T. G. Multilinear", "Tarmoun", "Bah", "Adlam", "Shachaf", "Arti", "Linear Algebra", "Li", "Lemmas", "Hitchcock", "H1", "Khrulkov", "Lyu", "Mohlenkamp", "Pattern Recognition", "Zhang", "Taylor", "Ren", "Herrmann", "Desmaison", "Blanc", "Vidal", "U V", "Oymak", "Weight Decay Ours", "Implicit", "Arbitrary Initialization", "J", "Joint Conference", "Trager", "N V", "Appendix", "Yun", "J. D. Algorithmic", "Milanesi", "Tang", "Numerical", "Montangero", "Stojevic", "Wies", "J. Gradient", "Garcke", "Woodworth", "Bartlett", "Lampinen", "Cohen", "Merkh", "Deferred Proofs", "Criminisi", "Benedetti", "Which", "Lemma", "Yao", "Bader", "Denote", "Low", "Moroshko", "Ruder", "M. J. Numerical", "Gupta", "Dehghani", "Vardi", "J. D.", "Novikov", "Kressner", "Pesme", "Shamir", "B. W. Tensor", "Machine Learning Research", "Balda", "Chou", "Deep Learning Workshop", "Krishnan", "Soudry", "Metzler", "Machine Learning", "Beylkin", "Network Figure", "Quantum Science", "Left", "Maman", "Krizhevsky", "Jannai", "Golan", "Gissin", "Lerer", "Remote Sensing", "Analysis", "Jagadeesan", "N. Kernel", "Delingette", "Yang", "Telgarsky", "Grasedyck", "Ayache", "Chanussot", "Frobenius", "Felser", "Tobler", "J. L.", "Oseledets", "Standard", "Pennington", "Luo", "Cao", "Shashua", "Kolda", "Levine", "Abnar", "W RH1", "Matrix Analysis", "Deep Convolutional Neural Networks Cohen", "Yanai", "Hackbusch", "Kim", "Deep Convolutional Neural Networks Furthermore", "Lemma 2", "Margin", "Quantum Information", "Hardt", "Kohn", "Bengio", "Pilanci", "Linsley", "Wang", "Ergen", "V RH1", "Lemma 3", "Schneider", "Tay", "J. Graph", "M. J. Multivariate", "Neyshabur", "Terstiege", "Nacson", "Wh1", "Gidel", "Eftekhari", "Mlynarski", "Kronecker", "Deep Convolutional Neural Networks Contradictions", "Navon", "Wei", "Soltanolkotabi", "V RD1", "Teschl", "Lucchesi", "W", "Research Institute", "Optimization", "V RD2", "Springer", "Gross", "Deep Convolutional Neural Networks", "Gunasekar", "Razin", "Lemma 15", "Mulayoff", "Paszke", "Deep Convolutional Neural Networks Wies", "P", "Deep Convolutional Neural Networks Proof", "Plaza", "Sestini"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Implicit", "Benedetti", "Ren", "Kadri", "Same Class", "Implicit Regularization", "Arti", "Oymak", "J. Gradient", "Grasedyck", "Jagadeesan", "Adlam", "Arora", "Eftekhari", "Navon", "Numerical", "Kolda", "Wies", "Ruder", "Hardt", "Hence", "V RD1", "Matrix Analysis", "Grant", "Yang", "Montangero", "Kohn", "Zhang", "Yanai", "Deep Learning Theory", "Bata", "Razin", "Hackbusch", "Levine", "J. Graph", "Si S", "Azulay", "Lucchesi", "N V", "Deep Convolutional Neural Networks Noticing", "Lin", "Golan", "Bengio", "Wang", "Yun", "Lemma", "Abnar", "Metzler", "Vidal", "Physics", "Van Gool", "V RD2", "Mathar", "Lampinen", "Tarmoun", "Milanesi", "Mohlenkamp", "Telgarsky", "Arbitrary Initialization", "Oseledets", "Quantum Information", "Lerer", "Garcke", "Tang", "J. D. Algorithmic", "Linear Algebra", "Blanc", "Bah", "Pennington", "Pesme", "Analysis", "P N2", "Deep Convolutional Neural Networks", "Appendix", "Deferred Proofs", "Khrulkov", "Kronecker", "Chanussot", "T. G. Multilinear", "Nacson", "Krizhevsky", "Remote Sensing", "Sarussi", "Gissin", "Joint Conference", "Quantum Science", "Chou", "Springer", "Merkh", "Yao", "Soudry", "Deep Convolutional Neural Networks Contradictions", "M. J. Numerical", "Terstiege", "Da Silva", "Balda", "J. L.", "Wh1", "Kim", "Ganguli", "Optimization", "Lyu", "Which", "Taylor", "Machine Learning Research", "Deep Convolutional Neural Networks Proof", "Neyshabur", "Delingette", "Bartlett", "Denote", "Sestini", "Shamir", "Deep", "Dehghani", "Deep Convolutional Neural Networks Ji", "Tobler", "Teschl", "A. K.", "Elkabetz", "Stojevic", "Jannai", "Wei", "H1", "Steinlechner", "Lemmas", "Network Figure", "Left", "Qiao", "U V", "Fix T", "Maman", "Kressner", "Research Institute", "Mulayoff", "Gunasekar", "Ergen", "Luo", "Zygalakis", "Felser", "Upper", "J. D.", "Vardi", "N. Kernel", "Pilanci", "Soltanolkotabi", "Shachaf", "Moroshko", "V RH1", "Gross", "W RH1", "Plaza", "Machine Learning", "Trenti", "Lemma 15", "Gupta", "Recht", "Saxe", "Gidel", "Frobenius", "Weight Decay Ours", "Lemma 2", "Novikov", "H. Gradient", "M. J. Multivariate", "Yakira", "Zuliani", "Gao", "Hitchcock", "B. W. Tensor", "Trager", "Paszke", "Criminisi", "Cohen", "Lee", "Bader", "Fann", "Chanan", "Harrison", "Mont", "Deep Convolutional Neural Networks Cohen", "Ayache", "Deep Convolutional Neural Networks Wies", "Schneider", "Mlynarski", "Woodworth", "Rao", "Low", "Li", "Perfect P", "Deep Convolutional Neural Networks Furthermore", "Krishnan", "Sharir", "Source", "Herrmann", "Hazan", "Linsley", "Cao", "Shashua", "Tay", "Standard", "Rauhut", "Globerson", "Lemma 3", "Beylkin", "Pattern Recognition", "Margin", "Deep Learning Workshop", "Desmaison"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Naujoks", "Berlin", "Aguirre", "Tomassini", "Campelo", "Liu", "Trautmann", "Colchester", "Springer Berlin", "Paquete", "Beume", "Aranha", "Guo", "Sch", "Springer International Publishing", "Jim", "Whitley", "Laredo", "Emmerich", "Machinery", "Kerschke", "Miettinen", "Fieldsend", "Nature PPSN XVI", "Jim enez", "Suganthan", "Verel", "Zhang", "Blum", "Li", "Vega", "Tusar", "Nature PPSN XV", "Tsou", "European Journal", "Meyarivan", "Alyahya", "Filipic", "Schwefel", "Springer Berlin Heidelberg", "Swarm", "Voigt", "Liefooghe", "Louren", "Applied Soft", "Zhao", "Ochoa", "Wang", "Deutz", "Nanyang", "Fonseca", "Zhou", "Bossek", "Agarwal", "Batista", "Rechenberg", "Castillo", "Doerr", "Nature PPSN IV", "G. Ochoa", "Deb"]}{"title": ["Model Agnostic Interpretability for Multiple Instance Learning"], "authors": ["[arxiv.Result.Author('Joseph Early'), arxiv.Result.Author('Christine Evers'), arxiv.Result.Author('Sarvapali Ramchurn')]"], "link": ["http://arxiv.org/pdf/2201.11701v1"], "summary": "In Multiple Instance Learning (MIL), models are trained using bags of\ninstances, where only a single label is provided for each bag. A bag label is\noften only determined by a handful of key instances within a bag, making it\ndifficult to interpret what information a classifier is using to make\ndecisions. In this work, we establish the key requirements for interpreting MIL\nmodels. We then go on to develop several model-agnostic approaches that meet\nthese requirements. Our methods are compared against existing inherently\ninterpretable MIL models on several datasets, and achieve an increase in\ninterpretability accuracy of up to 30%. We also examine the ability of the\nmethods to identify interactions between instances and scale to larger\ndatasets, improving their applicability to real-world problems.", "entities_include_in_text": ["Carbonneau\net al., 2018", "Liu et al., 2012", "Gilpin et al., 2018", "Amores, 2013", "Li et al., 2015", "Scott et al.,\n2005; Weidmann et al., 2003", "Tu et al., 2019; Zhou et al., 2009", "Molnar, 2020", "Liu et al., 2012", "Ilse et al., 2018", "Wang et al., 2018), as it produces\ninstance-level predictions as part of its processing. However, these instance-level predictions do\nnot take account of interactions between the instances, so are often inaccurate. A related piece\nof work on MIL interpretability is Tibo et al. (2020", "Wang et al., 2018", "Shapley, 1953", "Dietterich et al., 1997; Andrews et al., 2002", "Sirinukunwattana\net al., 2016) is a collection of microscopy images with annotated nuclei. We follow the same setup as\nIlse et al. (2018", "Everingham et al., 2010", "Garrett, 2021", "as done by Ilse et al. (2018)), however this method then requires\nthe nuclei to be marked for unseen data. This accounts for the difference between our results and\nthe results of Ilse et al. (2018"], "entities_from_reference": ["Plusieurs"]}{"title": ["Constrained Structure Learning for Scene Graph Generation"], "authors": ["[arxiv.Result.Author('Daqi Liu'), arxiv.Result.Author('Miroslaw Bober'), arxiv.Result.Author('Josef Kittler')]"], "link": ["http://arxiv.org/pdf/2201.11697v1"], "summary": "As a structured prediction task, scene graph generation aims to build a\nvisually-grounded scene graph to explicitly model objects and their\nrelationships in an input image. Currently, the mean field variational Bayesian\nframework is the de facto methodology used by the existing methods, in which\nthe unconstrained inference step is often implemented by a message passing\nneural network. However, such formulation fails to explore other inference\nstrategies, and largely ignores the more general constrained optimization\nmodels. In this paper, we present a constrained structure learning method, for\nwhich an explicit constrained variational inference objective is proposed.\nInstead of applying the ubiquitous message-passing strategy, a generic\nconstrained optimization method - entropic mirror descent - is utilized to\nsolve the constrained variational inference step. We validate the proposed\ngeneric model on various popular scene graph generation benchmarks and show\nthat it outperforms the state-of-the-art methods.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Recursive Binding for Similarity-Preserving Hypervector Representations of Sequences"], "authors": ["[arxiv.Result.Author('Dmitri A. Rachkovskij'), arxiv.Result.Author('Denis Kleyko')]"], "link": ["http://arxiv.org/pdf/2201.11691v1"], "summary": "Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC/VSA models.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Generative Adversarial Exploration for Reinforcement Learning"], "authors": ["[arxiv.Result.Author('Weijun Hong'), arxiv.Result.Author('Menghui Zhu'), arxiv.Result.Author('Minghuan Liu'), arxiv.Result.Author('Weinan Zhang'), arxiv.Result.Author('Ming Zhou'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Peng Sun')]"], "link": ["http://arxiv.org/pdf/2201.11685v1"], "summary": "Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Learning Stance Embeddings from Signed Social Graphs"], "authors": ["[arxiv.Result.Author('John Pougu\u00e9-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]"], "link": ["http://arxiv.org/pdf/2201.11675v1"], "summary": "A key challenge in social network analysis is understanding the position, or\nstance, of people in the graph on a large set of topics. While past work has\nmodeled (dis)agreement in social networks using signed graphs, these approaches\nhave not modeled agreement patterns across a range of correlated topics. For\ninstance, disagreement on one topic may make disagreement(or agreement) more\nlikely for related topics. We propose the Stance Embeddings Model(SEM), which\njointly learns embeddings for each user and topic in signed social graphs with\ndistinct edge types for each topic. By jointly learning user and topic\nembeddings, SEM is able to perform cold-start topic stance detection,\npredicting the stance of a user on topics for which we have not observed their\nengagement. We demonstrate the effectiveness of SEM using two large-scale\nTwitter signed graph datasets we open-source. One dataset, TwitterSG, labels\n(dis)agreements using engagements between users via tweets to derive\ntopic-informed, signed edges. The other, BirdwatchSG, leverages community\nreports on misinformation and misleading content. On TwitterSG and BirdwatchSG,\nSEM shows a 39% and 26% error reduction respectively against strong baselines.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrence"], "authors": ["[arxiv.Result.Author('Thomas Guyet'), arxiv.Result.Author('Wenbin Zhang'), arxiv.Result.Author('Albert Bifet')]"], "link": ["http://arxiv.org/pdf/2201.11650v1"], "summary": "The need to analyze information from streams arises in a variety of\napplications. One of the fundamental research directions is to mine sequential\npatterns over data streams. Current studies mine series of items based on the\nexistence of the pattern in transactions but pay no attention to the series of\nitemsets and their multiple occurrences. The pattern over a window of itemsets\nstream and their multiple occurrences, however, provides additional capability\nto recognize the essential characteristics of the patterns and the\ninter-relationships among them that are unidentifiable by the existing items\nand existence based studies. In this paper, we study such a new sequential\npattern mining problem and propose a corresponding efficient sequential miner\nwith novel strategies to prune search space efficiently. Experiments on both\nreal and synthetic data show the utility of our approach.", "entities_include_in_text": [], "entities_from_reference": ["Zhen Liu", "W. Zhang", "Jeremy", "Nikolaj Tatti", "Ren", "Faht", "Arnaud Giacometti", "Mengyu Wang", "Philippe", "Vincent S. Tseng", "Knowledge Discovery", "Jerry Chun-Wei Lin", "Future Generation", "Data Sc", "Nuo Wang", "Joris JM Gillis", "Jian Li", "Data Mining Workshops", "Zhibo Zhang", "Won Suk Lee", "Actes IAF", "Farf", "Chu-Feng Li", "Hui Li", "Zhang", "Uday Kiran", "Arnaud Soulet", "Wenbin", "Lstm", "Jerry C. C. Tseng", "Aijun An", "Boris Cule", "Jia-Yuan Gu", "Vincent S.", "Zhichuan Huang", "Tyler Derr", "Jingjing Li", "Rincy Thomas", "Advanced Applications", "Eirini Ntoutsi", "Rage", "Jeremy Weiss", "Wenbin Zhang", "Sizhe Peng", "Wang", "Yun", "Wolfgang Nejdl", "Q. Chen", "Joris", "Xiangliang Zhang", "Bart Goethals", "P. F. Wang", "Xuejiao Tang", "Nathalie Japkowicz", "Liuhua Zhang", "Pat", "Liang Zhao", "Chien Lin", "Thomas Guyet", "Ruoyu Wang", "U. Dayal", "Yi Yu", "Kea Turner", "Deyu Tang", "J. Pei", "H. Pinto", "Vincent S Tseng", "Jianwu Wang", "Lee", "Research", "Feat", "Jianfeng Ma", "J. Han", "B. Mortazavi-Asl", "Dieter Pfoser", "Jerry Chun-Wei", "Huang", "Liming Zhang", "Philippe Fournier-Viger", "Springer", "Knowl", "Joong Hyuk Chang", "Albert Bifet", "Jerry C.", "Jie Zhao", "R. Srikant", "Mining", "Jiangtao Cui", "Data Mining", "Jeremy C Weiss", "Nele Dexters", "Yun Sing Koh", "Quiniou", "Daeho Jin", "Cognitive", "Morteza Zihayat", "Bijay Prasad Jaysawal", "J. Wang", "Mingli Zhang", "Fair", "T. Guyet", "Jian Tang", "Data", "Lazaros Oreopoulos", "Xin Huang", "Discov"]}{"title": ["Deep Video Prior for Video Consistency and Propagation"], "authors": ["[arxiv.Result.Author('Chenyang Lei'), arxiv.Result.Author('Yazhou Xing'), arxiv.Result.Author('Hao Ouyang'), arxiv.Result.Author('Qifeng Chen')]"], "link": ["http://arxiv.org/pdf/2201.11632v1"], "summary": "Applying an image processing algorithm independently to each video frame\noften leads to temporal inconsistency in the resulting video. To address this\nissue, we present a novel and general approach for blind video temporal\nconsistency. Our method is only trained on a pair of original and processed\nvideos directly instead of a large dataset. Unlike most previous methods that\nenforce temporal consistency with optical flow, we show that temporal\nconsistency can be achieved by training a convolutional neural network on a\nvideo with Deep Video Prior (DVP). Moreover, a carefully designed iteratively\nreweighted training strategy is proposed to address the challenging multimodal\ninconsistency problem. We demonstrate the effectiveness of our approach on 7\ncomputer vision tasks on videos. Extensive quantitative and perceptual\nexperiments show that our approach obtains superior performance than\nstate-of-the-art methods on blind video temporal consistency. We further extend\nDVP to video propagation and demonstrate its effectiveness in propagating three\ndifferent types of information (color, artistic style, and object\nsegmentation). A progressive propagation strategy with pseudo labels is also\nproposed to enhance DVP's performance on video propagation. Our source codes\nare publicly available at https://github.com/ChenyangLEI/deep-video-prior.", "entities_include_in_text": [], "entities_from_reference": ["Justin Johnson", "Jimmy Ba.", "Yu Zhu", "Hailin Jin", "Alexander Sorkine-Hornung", "Jimei Yang", "Anat Levin", "Roy E Welsch", "Jonas Unger.", "William T Freeman", "Alireza Fathi", "Wenhao Jiang", "Edgar Simo-Serra", "Patchmatch", "Shuai Yang", "Yang", "Dan B Goldman", "Hao Wang", "Wei Liu", "Hanspeter Pfister", "Sanghyun Woo", "Single", "Federico Perazzi", "Vladlen Koltun", "Jian Sun", "Jiawen Chen", "Alexandre Alahi", "Wenxiu Sun", "Changil Kim", "Abhinav Shrivastava", "Ersin", "Brian McWilliams", "Shai", "Abdelaziz Djelouah", "Edgar", "Micha", "Boyan Bonev", "Markus Gross", "Jan Kautz", "Tamar Rott", "Xin Lu", "Erase", "Jampani", "Jumpcut", "Universal", "James", "Tinghui Zhou", "Jonathan Long", "Christopher Schroers", "Zhuwen Li", "Deqing Sun", "Haozhi Huang", "Michael F. Cohen", "Hanspeter Pfister.", "Mengdi Zhang", "Nadav Cohen", "Oliver Wang", "Mohamed Elgharib", "Victor Lempitsky", "Baoyuan Wang", "Tomer Michaeli.", "Minh N Do", "Xiaoou Tang", "Evan Shelhamer", "Peter V. Gehler.", "Xuhua Huang", "Rick Chang", "Zhaowen Wang", "Luc Van Gool", "Andreas Geiger", "Sylvain Paris", "Kavita Bala", "Markus H. Gross.", "Mohamed Hefeeda", "Carl Vondrick", "Ingan", "Kalyan Sunkavalli", "Qiong Yan", "Chenyang Lei", "Fitsum A. Reda", "Paul W Holland", "Yazhou Xing", "Gabriel Eilertsen", "Nenghai Yu", "Fan Zhong", "Occlusionaware", "Zhifeng Li", "Shai Bagon", "Yossi Gandelsman", "Phillip Isola", "Taesung Park", "Bryan Catanzaro.", "Andrew Tao", "Blind", "Kevin J. Shih", "Rafal K Mantiuk", "Light", "Chen Chen", "Laura LealTaix", "Sean Bell", "Alexey Dosovitskiy", "Pattern Anal", "Narendra Ahuja", "Qifeng Chen", "Fully", "Victor Cornill`ere", "Wenhan Luo", "Jordi Pont-Tuset", "Anna Khoreva", "Daniel Cremers", "Matthew Joint", "Colorful", "Edgar Simo-Serra.", "Dani Lischinski", "Jonas Unger", "Yizhou Yu", "Michal Irani", "Rott Shaham", "Matthew Brown.", "Michael J Black", "Peter V. Gehler", "Philipp Fischer", "Satoshi Iizuka", "Jinwei Gu", "Robust", "Deep", "Gharbi", "Andrea Vedaldi", "Markus H. Gross", "Tomer Michaeli", "John Collomosse", "Bernt Schiele. Lucid", "Bernt Schiele", "Victor Cornill", "Daniel Cohen-Or", "Alexander S Ecker", "Tali Dekel", "Xiaodong Yang", "Diederik P Kingma", "Raquel Urtasun.", "Frank Wang", "Sergio Guadarrama", "Trevor Darrell", "Matthew Brown", "Guilin Liu", "Richard Zhang", "Michael", "Shalini De Mello", "Jia-Bin Huang", "Eli Shechtman", "Alan L Yuille", "Yair Weiss", "Chen Fang", "Noah Snavely", "Gang Hua", "Zhicheng Yan", "Assaf Shocher", "Olaf Ronneberger", "Lang", "Matthias Bethge", "Samuel W Hasinoff", "Varun Jampani", "Singan", "Haotian Zhang", "Aysegul Dundar", "Zhu", "Qingnan Fan", "Rodrigo Benenson", "Markus Gross.", "Sergi Caelles", "Nicolas M", "Video", "Mohammad Shoeybi", "Raquel Urtasun", "James Tompkin", "Seon Joo Kim", "Jiaxin Xie", "Nicolas", "Raviteja Vemulapalli", "Guangyu Zhong", "Artistic", "Jimmy Ba", "Dmitry Ulyanov", "James MacQueen.", "Simone Meyer", "Adam Finkelstein", "Dan", "Vladlen Koltun.", "Lin Ma", "Lucid", "Jonathan T Barron", "Li Erran Li", "Lee", "Tom Mertens", "Adam", "Thomas Brox", "Kevin Murphy", "Victor Lempitsky.", "Nicolas Bonneel", "Eddy Ilg", "Lu Yuan", "Raghudeep Gadde", "Wenhan Yang", "Ersin Yumer", "Shai Avidan", "Image", "Xiaolong Zhu", "Baoquan Chen", "Philip Lenz", "Johannes Kopf", "Seoung Wug Oh", "Alexei A Efros", "Jing Liao", "Tunc Aydin", "Automatic", "Mach", "Hiroshi Ishikawa", "Thomas Brox.", "Eugene Hsu", "Wojciech Matusik", "Aljoscha Smolic", "James MacQueen", "Hao Zhang", "Dahun Kim", "Pattern Recognition", "Li Fei-Fei", "Bryan Catanzaro"]}{"title": ["LiteLSTM Architecture for Deep Recurrent Neural Networks"], "authors": ["[arxiv.Result.Author('Nelly Elsayed'), arxiv.Result.Author('Zag ElSayed'), arxiv.Result.Author('Anthony S. Maida')]"], "link": ["http://arxiv.org/pdf/2201.11624v1"], "summary": "Long short-term memory (LSTM) is a robust recurrent neural network\narchitecture for learning spatiotemporal sequential data. However, it requires\nsignificant computational power for learning and implementing from both\nsoftware and hardware aspects. This paper proposes a novel LiteLSTM\narchitecture based on reducing the computation components of the LSTM using the\nweights sharing concept to reduce the overall architecture cost and maintain\nthe architecture performance. The proposed LiteLSTM can be significant for\nlearning big data where time-consumption is crucial such as the security of IoT\ndevices and medical data. Moreover, it helps to reduce the CO2 footprint. The\nproposed model was evaluated and tested empirically on two different datasets\nfrom computer vision and cybersecurity domains.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Zygalakis", "Quantum Science", "Arbitrary Initialization", "Which", "Krishnan", "Lemma 2", "Herrmann", "Ruder", "H1", "Lemma 15", "Navon", "Wh1", "M. J. Multivariate", "Terstiege", "Lemmas", "Lin", "Gidel", "U V", "Ren", "Deep", "Jannai", "Zuliani", "Novikov", "Deep Learning Theory", "Springer", "Yakira", "Cao", "Bengio", "Wang", "Lemma", "Network Figure", "Si S", "A. K.", "Deep Convolutional Neural Networks Wies", "Gissin", "Mulayoff", "B. W. Tensor", "H. Gradient", "Sarussi", "Adlam", "Beylkin", "Harrison", "Pesme", "Joint Conference", "Tang", "Matrix Analysis", "J. D.", "Khrulkov", "Kronecker", "Mathar", "Yao", "Soudry", "Taylor", "Wies", "Tay", "Gross", "Lyu", "Ayache", "Golan", "Deep Convolutional Neural Networks Noticing", "Vidal", "Lee", "N. Kernel", "Pennington", "Lampinen", "Mlynarski", "Luo", "Linear Algebra", "Deep Convolutional Neural Networks Proof", "Ganguli", "Gao", "Perfect P", "Margin", "Fann", "Tarmoun", "Same Class", "Azulay", "Balda", "Analysis", "Garcke", "Tobler", "Kadri", "Arti", "Hazan", "Krizhevsky", "Plaza", "Chou", "Yanai", "Hence", "Montangero", "Shashua", "Merkh", "Levine", "Criminisi", "Maman", "W RH1", "Telgarsky", "Mont", "Elkabetz", "Grasedyck", "Chanan", "Rao", "Bata", "Milanesi", "Linsley", "Kohn", "Weight Decay Ours", "Upper", "V RH1", "Source", "Cohen", "Bartlett", "Schneider", "Eftekhari", "Physics", "Moroshko", "Recht", "Appendix", "Standard", "Soltanolkotabi", "Jagadeesan", "Low", "J. L.", "T. G. Multilinear", "Oymak", "Bah", "Hackbusch", "Hitchcock", "J. Gradient", "Metzler", "Deep Convolutional Neural Networks Furthermore", "Dehghani", "P N2", "Grant", "Implicit Regularization", "Kim", "Chanussot", "Machine Learning Research", "Deep Learning Workshop", "Ergen", "Rauhut", "Deep Convolutional Neural Networks", "Research Institute", "Frobenius", "Bader", "Shamir", "Denote", "Razin", "Yun", "Van Gool", "Optimization", "Deep Convolutional Neural Networks Ji", "Lucchesi", "Trenti", "Shachaf", "Teschl", "Lemma 3", "Li", "Lerer", "Fix T", "Mohlenkamp", "Deep Convolutional Neural Networks Contradictions", "Felser", "J. Graph", "Paszke", "Desmaison", "Zhang", "Trager", "Arora", "Wei", "Sharir", "N V", "Globerson", "Stojevic", "Blanc", "M. J. Numerical", "Numerical", "Deep Convolutional Neural Networks Cohen", "Abnar", "Left", "Pattern Recognition", "Machine Learning", "V RD1", "Delingette", "Saxe", "J. D. Algorithmic", "Neyshabur", "Kressner", "Kolda", "Quantum Information", "Steinlechner", "Gupta", "Gunasekar", "Deferred Proofs", "Hardt", "Pilanci", "Benedetti", "Woodworth", "Vardi", "Nacson", "Da Silva", "Sestini", "Yang", "V RD2", "Qiao", "Oseledets", "Implicit", "Remote Sensing"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Springer Berlin", "Tsou", "Sch", "Blum", "Kerschke", "Laredo", "Filipic", "Zhou", "Nanyang", "Nature PPSN XV", "Rechenberg", "Machinery", "Schwefel", "Campelo", "Swarm", "Verel", "Springer International Publishing", "Batista", "Liefooghe", "Zhao", "Deb", "Deutz", "Guo", "Ochoa", "Paquete", "Jim enez", "Wang", "Whitley", "Aguirre", "Trautmann", "Bossek", "Voigt", "Aranha", "Nature PPSN IV", "Colchester", "Castillo", "Emmerich", "European Journal", "Berlin", "Agarwal", "Springer Berlin Heidelberg", "Tomassini", "Vega", "Louren", "Fonseca", "Doerr", "Naujoks", "Tusar", "Fieldsend", "Alyahya", "Jim", "Suganthan", "Beume", "Applied Soft", "Miettinen", "Li", "G. Ochoa", "Liu", "Zhang", "Meyarivan", "Nature PPSN XVI"]}{"title": ["Model Agnostic Interpretability for Multiple Instance Learning"], "authors": ["[arxiv.Result.Author('Joseph Early'), arxiv.Result.Author('Christine Evers'), arxiv.Result.Author('Sarvapali Ramchurn')]"], "link": ["http://arxiv.org/pdf/2201.11701v1"], "summary": "In Multiple Instance Learning (MIL), models are trained using bags of\ninstances, where only a single label is provided for each bag. A bag label is\noften only determined by a handful of key instances within a bag, making it\ndifficult to interpret what information a classifier is using to make\ndecisions. In this work, we establish the key requirements for interpreting MIL\nmodels. We then go on to develop several model-agnostic approaches that meet\nthese requirements. Our methods are compared against existing inherently\ninterpretable MIL models on several datasets, and achieve an increase in\ninterpretability accuracy of up to 30%. We also examine the ability of the\nmethods to identify interactions between instances and scale to larger\ndatasets, improving their applicability to real-world problems.", "entities_include_in_text": ["Carbonneau\net al., 2018", "Liu et al., 2012", "Gilpin et al., 2018", "Amores, 2013", "Li et al., 2015", "Scott et al.,\n2005; Weidmann et al., 2003", "Tu et al., 2019; Zhou et al., 2009", "Molnar, 2020", "Liu et al., 2012", "Ilse et al., 2018", "Wang et al., 2018), as it produces\ninstance-level predictions as part of its processing. However, these instance-level predictions do\nnot take account of interactions between the instances, so are often inaccurate. A related piece\nof work on MIL interpretability is Tibo et al. (2020", "Wang et al., 2018", "Shapley, 1953", "Dietterich et al., 1997; Andrews et al., 2002", "Sirinukunwattana\net al., 2016) is a collection of microscopy images with annotated nuclei. We follow the same setup as\nIlse et al. (2018", "Everingham et al., 2010", "Garrett, 2021", "as done by Ilse et al. (2018)), however this method then requires\nthe nuclei to be marked for unseen data. This accounts for the difference between our results and\nthe results of Ilse et al. (2018"], "entities_from_reference": ["Plusieurs"]}{"title": ["Constrained Structure Learning for Scene Graph Generation"], "authors": ["[arxiv.Result.Author('Daqi Liu'), arxiv.Result.Author('Miroslaw Bober'), arxiv.Result.Author('Josef Kittler')]"], "link": ["http://arxiv.org/pdf/2201.11697v1"], "summary": "As a structured prediction task, scene graph generation aims to build a\nvisually-grounded scene graph to explicitly model objects and their\nrelationships in an input image. Currently, the mean field variational Bayesian\nframework is the de facto methodology used by the existing methods, in which\nthe unconstrained inference step is often implemented by a message passing\nneural network. However, such formulation fails to explore other inference\nstrategies, and largely ignores the more general constrained optimization\nmodels. In this paper, we present a constrained structure learning method, for\nwhich an explicit constrained variational inference objective is proposed.\nInstead of applying the ubiquitous message-passing strategy, a generic\nconstrained optimization method - entropic mirror descent - is utilized to\nsolve the constrained variational inference step. We validate the proposed\ngeneric model on various popular scene graph generation benchmarks and show\nthat it outperforms the state-of-the-art methods.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Recursive Binding for Similarity-Preserving Hypervector Representations of Sequences"], "authors": ["[arxiv.Result.Author('Dmitri A. Rachkovskij'), arxiv.Result.Author('Denis Kleyko')]"], "link": ["http://arxiv.org/pdf/2201.11691v1"], "summary": "Hyperdimensional computing (HDC), also known as vector symbolic architectures\n(VSA), is a computing framework used within artificial intelligence and\ncognitive computing that operates with distributed vector representations of\nlarge fixed dimensionality. A critical step for designing the HDC/VSA solutions\nis to obtain such representations from the input data. Here, we focus on\nsequences and propose their transformation to distributed representations that\nboth preserve the similarity of identical sequence elements at nearby positions\nand are equivariant to the sequence shift. These properties are enabled by\nforming representations of sequence positions using recursive binding and\nsuperposition operations. The proposed transformation was experimentally\ninvestigated with symbolic strings used for modeling human perception of word\nsimilarity. The obtained results are on a par with more sophisticated\napproaches from the literature. The proposed transformation was designed for\nthe HDC/VSA model known as Fourier Holographic Reduced Representations.\nHowever, it can be adapted to some other HDC/VSA models.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Generative Adversarial Exploration for Reinforcement Learning"], "authors": ["[arxiv.Result.Author('Weijun Hong'), arxiv.Result.Author('Menghui Zhu'), arxiv.Result.Author('Minghuan Liu'), arxiv.Result.Author('Weinan Zhang'), arxiv.Result.Author('Ming Zhou'), arxiv.Result.Author('Yong Yu'), arxiv.Result.Author('Peng Sun')]"], "link": ["http://arxiv.org/pdf/2201.11685v1"], "summary": "Exploration is crucial for training the optimal reinforcement learning (RL)\npolicy, where the key is to discriminate whether a state visiting is novel.\nMost previous work focuses on designing heuristic rules or distance metrics to\ncheck whether a state is novel without considering such a discrimination\nprocess that can be learned. In this paper, we propose a novel method called\ngenerative adversarial exploration (GAEX) to encourage exploration in RL via\nintroducing an intrinsic reward output from a generative adversarial network,\nwhere the generator provides fake samples of states that help discriminator\nidentify those less frequently visited states. Thus the agent is encouraged to\nvisit those states which the discriminator is less confident to judge as\nvisited. GAEX is easy to implement and of high training efficiency. In our\nexperiments, we apply GAEX into DQN and the DQN-GAEX algorithm achieves\nconvincing performance on challenging exploration problems, including the game\nVenture, Montezuma's Revenge and Super Mario Bros, without further fine-tuning\non complicate learning algorithms. To our knowledge, this is the first work to\nemploy GAN in RL exploration problems.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Learning Stance Embeddings from Signed Social Graphs"], "authors": ["[arxiv.Result.Author('John Pougu\u00e9-Biyong'), arxiv.Result.Author('Akshay Gupta'), arxiv.Result.Author('Aria Haghighi'), arxiv.Result.Author('Ahmed El-Kishky')]"], "link": ["http://arxiv.org/pdf/2201.11675v1"], "summary": "A key challenge in social network analysis is understanding the position, or\nstance, of people in the graph on a large set of topics. While past work has\nmodeled (dis)agreement in social networks using signed graphs, these approaches\nhave not modeled agreement patterns across a range of correlated topics. For\ninstance, disagreement on one topic may make disagreement(or agreement) more\nlikely for related topics. We propose the Stance Embeddings Model(SEM), which\njointly learns embeddings for each user and topic in signed social graphs with\ndistinct edge types for each topic. By jointly learning user and topic\nembeddings, SEM is able to perform cold-start topic stance detection,\npredicting the stance of a user on topics for which we have not observed their\nengagement. We demonstrate the effectiveness of SEM using two large-scale\nTwitter signed graph datasets we open-source. One dataset, TwitterSG, labels\n(dis)agreements using engagements between users via tweets to derive\ntopic-informed, signed edges. The other, BirdwatchSG, leverages community\nreports on misinformation and misleading content. On TwitterSG and BirdwatchSG,\nSEM shows a 39% and 26% error reduction respectively against strong baselines.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrence"], "authors": ["[arxiv.Result.Author('Thomas Guyet'), arxiv.Result.Author('Wenbin Zhang'), arxiv.Result.Author('Albert Bifet')]"], "link": ["http://arxiv.org/pdf/2201.11650v1"], "summary": "The need to analyze information from streams arises in a variety of\napplications. One of the fundamental research directions is to mine sequential\npatterns over data streams. Current studies mine series of items based on the\nexistence of the pattern in transactions but pay no attention to the series of\nitemsets and their multiple occurrences. The pattern over a window of itemsets\nstream and their multiple occurrences, however, provides additional capability\nto recognize the essential characteristics of the patterns and the\ninter-relationships among them that are unidentifiable by the existing items\nand existence based studies. In this paper, we study such a new sequential\npattern mining problem and propose a corresponding efficient sequential miner\nwith novel strategies to prune search space efficiently. Experiments on both\nreal and synthetic data show the utility of our approach.", "entities_include_in_text": [], "entities_from_reference": ["Arnaud Soulet", "Bart Goethals", "Data Mining", "Tyler Derr", "Rage", "T. Guyet", "Jeremy Weiss", "Yi Yu", "J. Han", "Knowl", "Chien Lin", "Jerry Chun-Wei Lin", "Vincent S.", "Discov", "Jingjing Li", "Rincy Thomas", "Arnaud Giacometti", "Hui Li", "Ren", "Bijay Prasad Jaysawal", "Farf", "Data Sc", "Ruoyu Wang", "Advanced Applications", "Faht", "B. Mortazavi-Asl", "Jerry C.", "Q. Chen", "Springer", "Data", "Wang", "Won Suk Lee", "Liuhua Zhang", "Vincent S. Tseng", "Chu-Feng Li", "Kea Turner", "Nele Dexters", "Wolfgang Nejdl", "Jiangtao Cui", "Jian Li", "Jeremy", "J. Pei", "Yun", "Daeho Jin", "H. Pinto", "Lazaros Oreopoulos", "Vincent S Tseng", "Mining", "Nathalie Japkowicz", "Uday Kiran", "Zhen Liu", "Xuejiao Tang", "Deyu Tang", "Liming Zhang", "Zhang", "Joris", "Philippe Fournier-Viger", "W. Zhang", "Liang Zhao", "Feat", "Lee", "Morteza Zihayat", "Nuo Wang", "Wenbin", "Mengyu Wang", "Boris Cule", "Jerry Chun-Wei", "Data Mining Workshops", "Jie Zhao", "Wenbin Zhang", "Actes IAF", "Zhibo Zhang", "Xiangliang Zhang", "Jerry C. C. Tseng", "Nikolaj Tatti", "Huang", "Dieter Pfoser", "Jianwu Wang", "Aijun An", "Jia-Yuan Gu", "Quiniou", "Eirini Ntoutsi", "Joong Hyuk Chang", "U. Dayal", "Pat", "Thomas Guyet", "Knowledge Discovery", "Future Generation", "Cognitive", "Fair", "Zhichuan Huang", "Xin Huang", "Philippe", "R. Srikant", "Jian Tang", "J. Wang", "Research", "Mingli Zhang", "Joris JM Gillis", "P. F. Wang", "Yun Sing Koh", "Jeremy C Weiss", "Albert Bifet", "Lstm", "Jianfeng Ma", "Sizhe Peng"]}{"title": ["Deep Video Prior for Video Consistency and Propagation"], "authors": ["[arxiv.Result.Author('Chenyang Lei'), arxiv.Result.Author('Yazhou Xing'), arxiv.Result.Author('Hao Ouyang'), arxiv.Result.Author('Qifeng Chen')]"], "link": ["http://arxiv.org/pdf/2201.11632v1"], "summary": "Applying an image processing algorithm independently to each video frame\noften leads to temporal inconsistency in the resulting video. To address this\nissue, we present a novel and general approach for blind video temporal\nconsistency. Our method is only trained on a pair of original and processed\nvideos directly instead of a large dataset. Unlike most previous methods that\nenforce temporal consistency with optical flow, we show that temporal\nconsistency can be achieved by training a convolutional neural network on a\nvideo with Deep Video Prior (DVP). Moreover, a carefully designed iteratively\nreweighted training strategy is proposed to address the challenging multimodal\ninconsistency problem. We demonstrate the effectiveness of our approach on 7\ncomputer vision tasks on videos. Extensive quantitative and perceptual\nexperiments show that our approach obtains superior performance than\nstate-of-the-art methods on blind video temporal consistency. We further extend\nDVP to video propagation and demonstrate its effectiveness in propagating three\ndifferent types of information (color, artistic style, and object\nsegmentation). A progressive propagation strategy with pseudo labels is also\nproposed to enhance DVP's performance on video propagation. Our source codes\nare publicly available at https://github.com/ChenyangLEI/deep-video-prior.", "entities_include_in_text": [], "entities_from_reference": ["Eddy Ilg", "Fully", "Ingan", "Richard Zhang", "James Tompkin", "Aysegul Dundar", "Hanspeter Pfister", "Justin Johnson", "Erase", "Mohamed Hefeeda", "Jonas Unger", "Rott Shaham", "Lucid", "Yazhou Xing", "Deep", "Zhifeng Li", "Eli Shechtman", "Baoquan Chen", "Nicolas", "Shuai Yang", "Hao Zhang", "Kalyan Sunkavalli", "Gang Hua", "Michael", "Robust", "Nicolas M", "Patchmatch", "Alan L Yuille", "Gharbi", "Raviteja Vemulapalli", "Victor Cornill`ere", "Tamar Rott", "Evan Shelhamer", "Peter V. Gehler.", "Satoshi Iizuka", "Chenyang Lei", "Nenghai Yu", "Singan", "John Collomosse", "Markus Gross.", "Andrea Vedaldi", "Qifeng Chen", "Zhaowen Wang", "Single", "Hiroshi Ishikawa", "Markus Gross", "Edgar Simo-Serra", "James MacQueen", "Carl Vondrick", "Baoyuan Wang", "Johannes Kopf", "Anna Khoreva", "Micha", "Occlusionaware", "Jan Kautz", "Tomer Michaeli", "Wojciech Matusik", "Lee", "Adam", "Phillip Isola", "Zhuwen Li", "Shai Avidan", "Daniel Cohen-Or", "Victor Lempitsky", "Alexei A Efros", "Adam Finkelstein", "Federico Perazzi", "Dan", "Matthias Bethge", "Matthew Brown", "Wenhan Yang", "Anat Levin", "Seon Joo Kim", "Jordi Pont-Tuset", "Sanghyun Woo", "Mengdi Zhang", "Jonathan Long", "Assaf Shocher", "Jumpcut", "Alexander Sorkine-Hornung", "Ersin", "Yu Zhu", "Light", "Colorful", "Dan B Goldman", "Matthew Joint", "Tunc Aydin", "Tali Dekel", "Vladlen Koltun", "Guilin Liu", "Shai Bagon", "Daniel Cremers", "Wenhan Luo", "Michael J Black", "Victor Cornill", "Li Erran Li", "Blind", "Seoung Wug Oh", "Jimmy Ba", "Abdelaziz Djelouah", "Dani Lischinski", "Alexey Dosovitskiy", "Christopher Schroers", "Simone Meyer", "Fan Zhong", "Jonas Unger.", "Lang", "Jing Liao", "Roy E Welsch", "Alexandre Alahi", "Yossi Gandelsman", "Xuhua Huang", "Qiong Yan", "Xiaodong Yang", "Kevin J. Shih", "Xin Lu", "Chen Fang", "James MacQueen.", "Varun Jampani", "Tomer Michaeli.", "Lin Ma", "Yair Weiss", "Kevin Murphy", "Hao Wang", "James", "Victor Lempitsky.", "Narendra Ahuja", "Raquel Urtasun.", "Boyan Bonev", "Haozhi Huang", "Shalini De Mello", "Image", "Edgar", "Sean Bell", "Jimei Yang", "Taesung Park", "Bernt Schiele. Lucid", "Jampani", "Paul W Holland", "Oliver Wang", "Noah Snavely", "Rick Chang", "Jian Sun", "Jiaxin Xie", "Zhicheng Yan", "Qingnan Fan", "Mohamed Elgharib", "Fitsum A. Reda", "Chen Chen", "Mach", "Frank Wang", "Bernt Schiele", "Andreas Geiger", "Xiaoou Tang", "Bryan Catanzaro", "Zhu", "Deqing Sun", "Artistic", "Michael F. Cohen", "Haotian Zhang", "Lu Yuan", "Nicolas Bonneel", "Sylvain Paris", "Mohammad Shoeybi", "Sergio Guadarrama", "Hailin Jin", "Matthew Brown.", "Kavita Bala", "Eugene Hsu", "Shai", "Minh N Do", "Laura LealTaix", "Rodrigo Benenson", "Raquel Urtasun", "Aljoscha Smolic", "Yizhou Yu", "Edgar Simo-Serra.", "Automatic", "Michal Irani", "Gabriel Eilertsen", "Abhinav Shrivastava", "Wenhao Jiang", "Peter V. Gehler", "Bryan Catanzaro.", "Nadav Cohen", "Dmitry Ulyanov", "Dahun Kim", "Trevor Darrell", "Andrew Tao", "Jia-Bin Huang", "Rafal K Mantiuk", "Jonathan T Barron", "Jimmy Ba.", "Tinghui Zhou", "Pattern Recognition", "Luc Van Gool", "Changil Kim", "Philipp Fischer", "Ersin Yumer", "Olaf Ronneberger", "Markus H. Gross", "Pattern Anal", "Xiaolong Zhu", "Video", "Wenxiu Sun", "Alireza Fathi", "Brian McWilliams", "Samuel W Hasinoff", "Tom Mertens", "Jiawen Chen", "William T Freeman", "Universal", "Thomas Brox.", "Sergi Caelles", "Alexander S Ecker", "Wei Liu", "Li Fei-Fei", "Raghudeep Gadde", "Jinwei Gu", "Diederik P Kingma", "Markus H. Gross.", "Yang", "Vladlen Koltun.", "Thomas Brox", "Hanspeter Pfister.", "Philip Lenz", "Guangyu Zhong"]}{"title": ["LiteLSTM Architecture for Deep Recurrent Neural Networks"], "authors": ["[arxiv.Result.Author('Nelly Elsayed'), arxiv.Result.Author('Zag ElSayed'), arxiv.Result.Author('Anthony S. Maida')]"], "link": ["http://arxiv.org/pdf/2201.11624v1"], "summary": "Long short-term memory (LSTM) is a robust recurrent neural network\narchitecture for learning spatiotemporal sequential data. However, it requires\nsignificant computational power for learning and implementing from both\nsoftware and hardware aspects. This paper proposes a novel LiteLSTM\narchitecture based on reducing the computation components of the LSTM using the\nweights sharing concept to reduce the overall architecture cost and maintain\nthe architecture performance. The proposed LiteLSTM can be significant for\nlearning big data where time-consumption is crucial such as the security of IoT\ndevices and medical data. Moreover, it helps to reduce the CO2 footprint. The\nproposed model was evaluated and tested empirically on two different datasets\nfrom computer vision and cybersecurity domains.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}