{"title": ["String diagrams for non-strict monoidal categories"], "authors": ["[arxiv.Result.Author('Paul Wilson'), arxiv.Result.Author('Dan Ghica'), arxiv.Result.Author('Fabio Zanasi')]"], "link": ["http://arxiv.org/pdf/2201.11738v1"], "summary": "Whereas string diagrams for strict monoidal categories are well understood,\nand have found application in several fields of Computer Science, graphical\nformalisms for non-strict monoidal categories are far less studied. In this\npaper, we provide a presentation by generators and relations of string diagrams\nfor non-strict monoidal categories, and show how this construction can handle\napplications in domains such as digital circuits and programming languages. We\nprove the correctness of our construction, which yields a novel proof of Mac\nLane's strictness theorem. This in turn leads to an elementary graphical proof\nof Mac Lane's coherence theorem, and in particular allows for the inductive\nconstruction of the canonical isomorphisms in a monoidal category.", "entities_include_in_text": [], "entities_from_reference": ["Victor Ostrik", "Pawel Sobocinski", "Example", "Lambek", "Edward Grefenstette", "Aleks Kissinger", "Fabio Zanasi", "Mehrnoosh Sadrzadeh", "Ann", "Cambridge University Press", "Mario Alvarez-Picallo", "Bonchi", "Fabio Zanasi.", "Shlomo Gelaki", "Pure Appl", "Sn", "David Walker", "P. I. Etingof", "Annual ACM", "Sriram K. Rajamani", "Bob Coecke", "David Sprunger", "Dan R. Ghica", "Dmitri Nikshych"]}{"title": ["PRNU Based Source Camera Identification for Webcam and Smartphone Videos"], "authors": ["[arxiv.Result.Author('Fernando Mart\u00edn-Rodr\u00edguez'), arxiv.Result.Author('Fernando Isasi-de-Vicente')]"], "link": ["http://arxiv.org/pdf/2201.11737v1"], "summary": "This communication is about an application of image forensics where we use\ncamera sensor fingerprints to identify source camera (SCI: Source Camera\nIdentification) in webcam/smartphone videos. Sensor or camera fingerprints are\nbased on computing the intrinsic noise that is always present in this kind of\nsensors due to manufacturing imperfections. This is an unavoidable\ncharacteristic that links each sensor with its noise pattern. PRNU (Photo\nResponse Non-Uniformity) has become the default technique to compute a camera\nfingerprint. There are many applications nowadays dealing with PRNU patterns\nfor camera identification using still images. In this work we focus on video,\nfirst on webcam video and afterwards on smartphone video. Webcams and\nsmartphones are the most used video cameras nowadays. Three possible methods\nfor SCI are implemented and assessed in this work.", "entities_include_in_text": [], "entities_from_reference": ["San Francisco", "Master Thesis", "Large Scale Test", "M. Goljan", "Eurasip Journal", "Chui", "M. Mohanty", "S. Taspinar", "J. Fridrich", "Hassebrook", "D. Shullani", "H. Ogawa", "Fingerprint Camera Electronic Imaging", "Filler", "Machine Intelligence", "Pattern Analysis", "Shullani", "Robustez", "Imagen Basada", "Fridrich", "Media Forensics", "San Diego", "Applied Optics", "Wiener", "Estudio", "Effect", "Study", "Media Watermarking", "Kumar", "M. Chen"]}{"title": ["Ranking Info Noise Contrastive Estimation: Boosting Contrastive Learning via Ranked Positives"], "authors": ["[arxiv.Result.Author('David T. Hoffmann'), arxiv.Result.Author('Nadine Behrmann'), arxiv.Result.Author('Juergen Gall'), arxiv.Result.Author('Thomas Brox'), arxiv.Result.Author('Mehdi Noroozi')]"], "link": ["http://arxiv.org/pdf/2201.11736v1"], "summary": "This paper introduces Ranking Info Noise Contrastive Estimation (RINCE), a\nnew member in the family of InfoNCE losses that preserves a ranked ordering of\npositive samples. In contrast to the standard InfoNCE loss, which requires a\nstrict binary separation of the training pairs into similar and dissimilar\nsamples, RINCE can exploit information about a similarity ranking for learning\na corresponding embedding space. We show that the proposed loss function learns\nfavorable embeddings compared to the standard InfoNCE whenever at least noisy\nranking information can be obtained or when the definition of positives and\nnegatives is blurry. We demonstrate this for a supervised classification task\nwith additional superclass labels and noisy similarity scores. Furthermore, we\nshow that RINCE can also be applied to unsupervised training with experiments\non unsupervised representation learning from videos. In particular, the\nembedding yields higher classification accuracy, retrieval rates and performs\nbetter in out-of-distribution detection than the standard InfoNCE loss.", "entities_include_in_text": ["Zhao et al. 2021", "Khosla\net al. 2020", "Deselaers and Ferrari 2011", "Feichtenhofer et al. 2021", "Dave et al. 2021", "Khosla et al. 2020", "Liu et al. 2019", "Dosovitskiy et al. 2016", "van den Oord,\nLi, and Vinyals 2018", "Sohn 2016", "Tian, Krishnan, and\nIsola 2020", "Misra and van der Maaten 2020", "He et al. 2020", "van den Oord, Li, and\nVinyals 2018", "Behrmann,\nGall, and Noroozi 2021", "Chen and He 2021; Grill et al. 2020", "Miech et al.\n2020", "Han,\nXie, and Zisserman 2020", "Caron et al. 2020", "Khosla et al.\n2020", "Huynh et al.\n2020", "Romijnders et al. 2021", "Tian et al. 2020", "Neill and Bollegala 2021", "Khosla et al.\n2020", "Huynh et al.\n2020", "Winkens et al. 2020", "Burges et al. 2005; Cakir et al. 2019; Cao et al. 2007;\nLiu 2009", "Weinberger, Blitzer, and Saul 2006", "Sohn 2016", "Tschannen et al. 2020", "Ge 2018", "Zhao et al. 2021", "Khosla et al. 2020", "Miech et al. 2020", "Wang and Liu 2021", "Deselaers and Ferrari 2011", "Krizhevsky, Hinton et al. 2009", "Le and Yang 2015", "Deng et al. 2009", "Tian, Krishnan, and Isola 2020", "Liu et al. 2019", "Weinberger, Blitzer, and Saul\n2006", "Khosla et al. 2020", "Ge 2018", "Cakir et al. 2019", "Szegedy et al. 2016", "Lee and\nCheon 2020", "Lee\nand Cheon 2020", "Sastry and Oore 2020", "Weinberger, Blitzer, and Saul 2006", "Winkens et al. 2020", "Hendrycks et al. 2019; Winkens et al.\n2020", "Lee et al.\n2018; Liang, Li, and Srikant 2018; Winkens et al. 2020", "Winkens et al. 2020", "Winkens et al. 2020", "Liang, Li, and Srikant 2018", "Lee\net al. 2018", "Xian et al. 2018", "Liu et al. 2019", "Xian et al. 2018", "Tschan-\nnen et al. 2020", "Zhuang et al. 2020", "Tokmakov,\nHebert, and Schmid 2020", "Kay et al. 2017", "Soomro, Zamir, and Shah 2012", "Kuehne\net al. 2011", "Li, Li, and Vasconcelos 2018", "Wang and Liu 2021", "Wang and Liu 2021", "Wang\nand Liu 2021)", "Khosla et al. 2020", "Miech et al. 2020; Han, Xie, and Zisserman 2020", "Le and Yang 2015", "Deng et al. 2009", "Tian, Krishnan, and Isola 2020", "Liu et al. 2019", "Liu et al. 2019", "Reimers and Gurevych 2019", "Cer et al. 2017", "Khosla et al. 2020", "Khosla et al. 2020", "Khosla et al. 2020", "Khosla\net al. 2020", "Krizhevsky 2014", "Khosla et al. 2020", "Khosla et al. 2020", "He et al. 2020", "Khosla et al. 2020", "Ge 2018", "Cakir et al. 2019", "Winkens et al. 2020", "Pedregosa et al.\n2011", "Hara, Kataoka, and Satoh 2018", "Kingma and Ba 2015", "He et al. 2020", "Van der Maaten and Hinton 2008", "Wang and Isola 2020", "Wang and Isola 2020", "Wang and Isola 2020"], "entities_from_reference": ["Soomro", "Isola", "Hinton", "Strub", "Hard", "Khademi", "Label", "Akata", "Rank Using Gradient", "Levy", "Cer", "Data", "Sastry", "Deep Neural Embeddings", "Accuracy Rank2", "Avila Pires", "Accuracy R", "Kay", "Liang", "Zhao", "Valko", "Li", "Caron", "Pedregosa", "Lucic", "Again", "Hillier", "Visual Features", "Wojna", "Tokmakov", "Memory", "Kataoka", "Triplet Loss", "Kuehne", "Garrote", "Tschannen", "Tech Report", "Lin", "Joshi", "V100 GPU", "Adam", "Yang", "Lau", "Vanhoucke", "Neill", "Triplet", "Visual Representations", "J. T.", "Renshaw", "Critical", "Oord", "Chen", "False Negative", "Jhuang", "Michel", "Hara", "Smaira", "Brox", "Zisserman", "Lampert", "Deng", "Lfine", "Hebert", "Datasets TinyImageNet", "Tian", "Videos", "Deep Metric Learning", "Duchesnay", "Deep", "Guo", "Numpy", "Shah", "Misra", "Machine Learning", "Satoh", "Kingma", "Mark", "Deep Neural Networks", "Krishnan", "Ferrari", "Pytorch", "Walter", "Hierarchical Triplet", "Discriminative", "Loss Variants", "V100 GPUs", "Lewis", "Xie", "Cakir", "Affects", "Roberta", "Sarna", "Average", "Qin", "Ott", "Gheshlaghi Azar", "Grill", "Rank2", "Fan", "Visual", "Zhuang", "Suleyman", "Yang 2015)", "Which", "Richemond", "Zhang", "Multiview Coding", "Krizhevsky", "Bollegala", "J. R.", "Note", "R. W. H.;", "Fast AP", "Riedmiller", "Roy", "Action Recognition", "Red", "J. O.", "Accuracy", "Weinberger", "Video Representation", "Burges", "Sivic", "Similar", "Video Representations", "Kulis", "Miech", "Stanforth", "Distance Metric Learning", "Model Robustness", "Makes Instance", "Dave", "Hendrycks", "Brucher", "Simonyan", "Large Margin Nearest Neighbor", "Loss Analysis", "Stoyanov", "Diab", "Sohn", "Appendix", "Xian", "Zamir", "Joulin", "Ritter", "Bojanowski", "Carreira", "Fig", "Alayrac", "Loss Objective", "Liu", "Fischer", "Baselines", "Figure K", "Winkens", "Le", "Girshick", "Feichtenhofer", "Dosovitskiy", "Exemplar Convolutional Neural Networks", "Han", "Dense Trajectory Clustering", "Blondel", "Lee", "Hullender", "Schiele", "Van", "Feature Learning", "Szegedy", "Huynh", "Cao", "Momentum Contrast", "Maaten", "L", "Ltriplet", "Wang", "Label Smoothing", "Tab", "Shin", "Houlsby", "Negative Samples", "Gelly", "Viola", "Khosla", "Video"]}{"title": ["IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages"], "authors": ["[arxiv.Result.Author('Emanuele Bugliarello'), arxiv.Result.Author('Fangyu Liu'), arxiv.Result.Author('Jonas Pfeiffer'), arxiv.Result.Author('Siva Reddy'), arxiv.Result.Author('Desmond Elliott'), arxiv.Result.Author('Edoardo Maria Ponti'), arxiv.Result.Author('Ivan Vuli\u0107')]"], "link": ["http://arxiv.org/pdf/2201.11732v1"], "summary": "Reliable evaluation benchmarks designed for replicability and\ncomprehensiveness have driven progress in machine learning. Due to the lack of\na multilingual benchmark, however, vision-and-language research has mostly\nfocused on English language tasks. To fill this gap, we introduce the\nImage-Grounded Language Understanding Evaluation benchmark. IGLUE brings\ntogether - by both aggregating pre-existing datasets and creating new ones -\nvisual question answering, cross-modal retrieval, grounded reasoning, and\ngrounded entailment tasks across 20 diverse languages. Our benchmark enables\nthe evaluation of multilingual multimodal models for transfer learning, not\nonly in a zero-shot setting, but also in newly defined few-shot learning\nsetups. Based on the evaluation of the available state-of-the-art models, we\nfind that translate-test transfer is superior to zero-shot transfer and that\nfew-shot learning is hard to harness for many tasks. Moreover, downstream\nperformance is partially explained by the amount of available unlabelled\ntextual data for pretraining, and only weakly by the typological distance of\ntarget-source languages. We hope to encourage future research efforts in this\narea by releasing the benchmark to the community.", "entities_include_in_text": ["Jauhar et al., 2018; Ponti et al., 2020", "Elliott et al.,\n2016", "Bender, 2011; Ponti et al., 2019;\nLiu et al., 2021", "Srinivasan et al., 2021", "Pfeiffer et al., 2021", "Huang et al., 2021; Lei\net al., 2021", "Liu et al., 2021", "Jain et al., 2021", "Ni et al., 2021; Jain et al., 2021", "Liang et al., 2020", "Ruder et al., 2021", "Lauscher et al., 2020; Zhao et al., 2021", "Ni et al.,\n2021; Zhou et al., 2021; Liu et al., 2021", "Lauscher et al., 2020", "Bernardi et al., 2016; Baltrusaitis et al., 2019", "Kiela et al., 2015; Gella et al., 2017;\nCaglayan et al., 2021", "Ponti et al.,\n2020", "Liu et al., 2021", "Rotman et al., 2018; Wehrmann et al., 2019;\nHuang et al., 2019; Kim et al., 2020; Su et al., 2021", "Ni et al., 2021;\nZhou et al., 2021; Liu et al., 2021", "Chen et al., 2020;\nPfeiffer et al., 2021", "Wang et al., 2018", "Wang et al., 2019", "Wilie et al., 2020", "Park et al., 2021", "Shavrina et al., 2020", "Dumitrescu et al., 2021", "Hu\net al., 2020", "Liang et al., 2020", "Ruder et al., 2021", "Hu et al., 2020;\nLiang et al., 2020; Ruder et al., 2021", "Bowman et al., 2015", "Xie et al., 2019", "Krishna et al., 2017", "Liu et al., 2021", "Suhr et al., 2019", "Young et al., 2014", "Lin et al., 2014", "Yoshikawa\net al., 2017; Nakayama et al., 2020", "van Miltenburg et al., 2017; Frank et al., 2018", "Jia et al., 2021", "van\nMiltenburg et al., 2018", "Lan et al., 2017", "Mishra et al., 2021", "Scaiella et al., 2019", "Lam et al., 2020", "Aggarwal et al., 2021", "Elliott et al., 2016", "Srinivasan\net al., 2021", "measured in number of ar-\nticles as of Jan 2022", "Joshi et al., 2020; Blasi\net al., 2021", "Hu et al., 2020; Liang et al., 2020; Ruder et al.,\n2021", "Zhao et al., 2021", "Bugliarello et al., 2021", "Paszke\net al., 2019", "Devlin et al., 2019", "Ren\net al., 2015", "Sennrich\net al., 2016; Wu et al., 2016", "Vaswani et al., 2017", "Chen et al., 2020) multi-\nlingually by following the base approach of Ni et al.\n(2021", "Devlin et al., 2019", "Conneau et al., 2020", "Bugliarello\net al., 2021", "Chen et al.,\n2020", "Lu et al., 2019", "Su et al., 2020", "He et al., 2016", "Xie et al., 2017", "Krishna et al., 2017;\nAnderson et al., 2018", "Geigle\net al., 2022", "as of January 2022", "Ponti et al., 2020; Ruder et al., 2021", "Lauscher et al., 2020", "LREC 2018", "SIU 2016", "Elliott et al.,\n2016", "Mishra et al.,\n2021", "Unal et al., 2016", "Srinivasan et al., 2021", "Bugliarello et al., 2021", "He et al., 2016", "Xie et al., 2017", "Krishna et al., 2017; Anderson et al., 2018", "Lu\net al., 2020; Bugliarello et al., 2021", "Ni et al., 2021", "Zhou et al., 2021", "Bugliarello\net al., 2021", "Elliott et al., 2016", "Elliott et al., 2016)\n\nand Nakayama et al. (2020"], "entities_from_reference": ["Gomez", "Ethayarajh", "Barrault", "Miyazaki", "Berlin", "Chaudhary", "Goyal", "Asian Low-Resour", "Tejani", "Annual", "Raison", "Miltenburg", "Schluter", "Automatic", "M3P", "Lei", "Dima", "Srinivasan", "Annual Meeting", "Zhao", "Yao", "Hsieh", "Experimental Details", "Scaiella", "Jones", "Goodman", "Uniform", "Test", "Vincentio", "Rebeja", "Lin", "Madison", "Joshi", "Yang", "Italian Journal", "Mach", "Caglayan", "Pattern Recognition", "Sch", "Benchmark", "Pascanu", "Lyu", "Chen", "Gao", "Trawi", "Brox", "Short", "Fang", "Task Papers", "Deng", "Dai", "Lang", "Human Language Technologies", "Kopf", "Citamak", "J. UNITER", "Swahili", "Gimelshein", "El Kholy", "Saha", "Erdem", "Guo", "Toutanova", "Target Language", "I. Composable", "Gamon", "Morency", "Machine Learning", "Punta Cana", "Lang Model", "Lam", "Yoshikawa", "Luo", "Further", "M3Pboth", "Goswami", "Retrieval Performance", "Pfeiffer", "Artzi", "Apr", "Bischof", "Pattern Anal", "Fan", "Metze", "Cotterell", "Michael", "Mortensen", "Amac", "Linguistic Issues", "Berg", "Lauscher", "Sennrich", "Ponti", "Tanti", "Jafaritazehjan", "Bugliarello", "Ahuja", "Killeen", "Mean Recall", "Zhou", "Vuli c", "Bharti", "Chanan", "Hata", "Hendrycks", "Guzm", "Towards", "Online", "A. Minimax", "Bendersky", "Melbourne", "Patrick", "Schuster", "Bernstein", "Dhir", "Lai", "Chang", "K.W. VisualBERT:", "Santiago", "Cho", "Liu", "J. Uc2", "Levin", "Reddy", "Machinery", "Paszke", "Grave", "Marchidan", "Anastasopoulos", "Kiela", "Ahmed", "Bernardi", "Huang", "Schiele", "Max Planck Institute", "Anderson", "Cham", "Gaman", "Jabri", "Huynh", "Yagcioglu", "Santa Fe", "Nakayama", "Firat", "Wang", "Park", "Shin", "Gella", "Gaussian Error Linear Units", "Singh", "Karpathy", "Sacheti", "Hudson", "Leipzig", "Sgaard", "Appendix C", "Mishra", "Polosukhin", "Ilie", "Socher", "Tambi", "Jia", "Jiang", "Levy", "Garrette", "Frank", "Jain", "Krishna", "Liang", "Ionescu", "Li", "Xia", "J. COCO-CN", "Zhu", "Gan", "Dumitrescu", "Baltrusaitis", "Hays", "Ansell", "J. Y.", "Duan", "Parovic", "Tuytelaars", "Shazeer", "Mikhailov", "Hill", "Artemova", "Hutter", "Avram", "Vaswani", "Shavrina", "Copenhagen", "Young", "Agi", "Method M3P", "Lim", "Visual Reasoning", "Evlampiev", "Vision", "Iacobescu", "Barros", "Bai", "Agrawal", "Conneau", "Fox", "Desmaison", "Muscat", "Dryer", "N. Baselines", "Jang", "Wei", "Dollar", "Gatt", "Keller", "Deep", "Kalantidis", "Visual QA", "Rebedea", "Loshchilov", "Anton", "Schick", "Machine Learning Research", "Raman", "Bengio", "Benchmarks Track", "Kadav", "Lorincz", "Shigeto", "Lan", "Dataset Metric", "Devlin", "Xie", "Uszkoreit", "Lerer", "Botha", "Visual Genome", "Ott", "Yatskar", "Hwang", "Barzilay", "Bowman", "Zhang", "Moon", "Steitz", "Qiao", "Birch", "J. O.", "Buehler", "Gross", "Nickel", "Plank", "Shamma", "Kim", "Model Initialisation Visual Tokens Pretrain Data", "Ruder", "Retrieval", "Shareghi", "A. (eds.)", "Clark", "Roth", "Ramanan", "Hauptmann", "Lopes", "Machine Translation", "Zitnick", "Budhiraja", "Iletisim Uygulamalar Kurultay", "Garnett", "Stoyanov", "Bender", "Fung", "Mandarin", "Elliott", "Minnesota", "Kuyu", "Visual Entailment", "Cui", "Morogan", "Wehrmann", "Shutova", "Blasi", "Jauhar", "Le", "Suhr", "Girshick", "Microsoft COCO", "Berzak", "J.", "Due", "Han", "Louisiana", "Faster", "Lee", "Valencia", "Ren", "Model NLI QA Reasoning Retrieval", "Hoang", "Rotman", "Gould", "Yin", "Cao", "Geigle", "Proceedings", "Saenko", "Maire", "Short Papers", "Wilie", "Wallach", "Bradbury", "Tan", "Littell", "Johnson", "Marseille", "Batra", "Soleman", "Poibeau", "Jurafsky", "Okazaki", "Volume", "Fenogenova", "Aralikatte", "Steiner", "Sharma", "Vilbert", "Saito"]}{"title": ["An Algorithmic Framework for Locally Constrained Homomorphisms"], "authors": ["[arxiv.Result.Author('Laurent Bulteau'), arxiv.Result.Author('Konrad K. Dabrowski'), arxiv.Result.Author('Noleen K\u00f6hler'), arxiv.Result.Author('Sebastian Ordyniak'), arxiv.Result.Author('Dani\u00ebl Paulusma')]"], "link": ["http://arxiv.org/pdf/2201.11731v1"], "summary": "A homomorphism $f$ from a guest graph $G$ to a host graph $H$ is locally\nbijective, injective or surjective if for every $u\\in V(G)$, the restriction of\n$f$ to the neighbourhood of $u$ is bijective, injective or surjective,\nrespectively. The corresponding decision problems, LBHOM, LIHOM and LSHOM, are\nwell studied both on general graphs and on special graph classes. Apart from\ncomplexity results when the problems are parameterized by the treewidth and\nmaximum degree of the guest graph, the three problems still lack a thorough\nstudy of their parameterized complexity. This paper fills this gap: we prove a\nnumber of new FPT, W[1]-hard and para-NP-complete results by considering a\nhierarchy of parameters of the guest graph $G$. For our FPT results, we do this\nthrough the development of a new algorithmic framework that involves a general\nILP model. To illustrate the applicability of the new framework, we also use it\nto prove FPT results for the Role Assignment problem, which originates from\nsocial network theory and is closely related to locally surjective\nhomomorphisms.", "entities_include_in_text": [], "entities_from_reference": ["Structures", "Martin Grohe", "Springer", "Berlin", "Petter Kristiansen", "Eva Tardos.", "John R. Gilbert", "Sebastian Ordyniak", "Chandra Chekuri", "Petr Hlineny", "Pal Grnas Drange", "Frank", "Daniel Paulusma. Graph", "Algorithms", "Paths", "Pinar Heggernes", "S. Ordyniak", "Nordic Journal", "Saket Saurabh", "Math", "Moshe Y. Vardi", "Micha Pilipczuk", "Marcin Pilipczuk", "Oxford University Press", "Mathematical Social Sciences", "Jaroslav Nesetril", "Michael R. Fellows", "Marek Tesar. Complexity", "Markus S. Dregi", "Rooij", "Locally Constrained", "Pavol Hell", "Daniel Paulusma.", "Norman J. Biggs", "Jack Edmonds", "Karl P. Reitz. Graph", "Arne Telle.", "Lecture", "Local", "Series B", "Hof", "Daniel Kobler. Algorithms", "Jan Arne Telle", "Stephen P. Borgatti. Role", "Brace", "N. Kohler", "Systems", "Locally", "Nikola Jedlickova", "D. Paulusma", "Christopher Purcell", "Graph Theory", "Andreas Pfandler", "William S. Massey", "Mendez", "Pawe Rzazewski", "Martin Vatshelle", "Jorg Flum", "Daniel Paulusma. Packing", "Pim", "Hans L. Bodlaender", "Fred S. Roberts.", "Artif", "Hjalmtyr Hafsteinsson", "Michael R. Fellows.", "Springer Verlag", "Australasian Journal", "Kohler", "Cambridge University Press", "James Abello", "Karl P. Reitz", "Canadian Journal", "Johan M.", "David S. Johnson", "David S. Johnson.", "Daniel Paulusma", "Daniel Marx", "Hendrik W. Lenstra Jr.", "Norman J. Biggs.", "John Stillwell", "Wieslaw Zielonka", "Fundamenta Informaticae", "Martin Kronegger", "Hendrik W. Lenstra", "Mathematicae Graph Theory", "Jiri Fiala", "Vibha Sahlot", "Johan M. M. van Rooij.", "Attila Por", "Hans L. Bodlaender.", "Hjalmtyr", "Lukasz Kowalik", "Venkatesh Raman", "Pavol Hell.", "Bernard Lidicky", "Andrzej Proskurowski", "Sukanya Pandey", "Graphs", "Pavel Klavik", "Algorithmica", "Eugene C. Freuder", "Eva Tardos", "K. K. Dabrowski", "Jeremie Chalopin", "Phokion G. Kolaitis", "Dana Angluin.", "Algebraic Graph Theory", "Martin G. Everett", "Douglas R. White", "Networks", "Neeldhara Misra", "Marek Tesar. Dichotomy", "Daniel Lokshtanov", "Victor Dalmau", "Finite", "Discrete Applied Mathematics", "Pavel Dvorak", "Jan Bok", "Michael U. Gerber", "Aleksandar Pekec", "Jan Kratochvil", "Parameterized Algorithms", "Machinery", "Li Sheng", "John Stillwell.", "Ravi Kannan. Minkowskis", "World", "Marek Cygan", "Fedor V. Fomin", "David G. Kirkpatrick", "Arne Telle", "Rodney G. Downey", "Social Networks", "M. Puck Rombach.", "Stephen P. Borgatti", "Harcourt", "Ondrej Bilka", "Sebastian Ordyniak.", "Jack Edmonds.", "Science", "Dana Angluin", "Mitre Costa Dourado", "Charles University", "Patrice Ossona", "Andras Frank", "Daniel Kobler", "Jan Arne Telle.", "Dusan Knop", "Fred S. Roberts", "1974. L. Bulteau", "Frances A. Rosamond", "Algebraic Topology", "Parameterized Complexity Theory", "Ton Kloks", "Steven Chaplick", "Michael Randolph Garey", "Karolina Okrasa", "Marek Tesar", "Fast", "William S. Massey.", "Robert Ganian", "Graph", "Marek Tesar.", "Eduard Eiben"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Da Silva", "Springer", "Source", "Cohen", "Steinlechner", "J. L.", "Chou", "Deep Learning Workshop", "Sharir", "Soudry", "Abnar", "Deep Learning Theory", "Yao", "Li", "Upper", "Lemma 15", "Delingette", "Benedetti", "Teschl", "Mathar", "Lemma 3", "Woodworth", "A. K.", "Tarmoun", "Yun", "J. D.", "Gupta", "P N2", "Arbitrary Initialization", "Frobenius", "V RH1", "Lin", "Plaza", "Margin", "Yang", "Recht", "Metzler", "Mlynarski", "Pattern Recognition", "Pennington", "Pilanci", "Lyu", "Maman", "Gao", "Tobler", "Zuliani", "Shachaf", "Globerson", "N V", "Soltanolkotabi", "Felser", "Desmaison", "Stojevic", "Elkabetz", "J. D. Algorithmic", "Rao", "Jagadeesan", "Wei", "Shamir", "Deep", "Lampinen", "Machine Learning", "Hackbusch", "Hitchcock", "J. Gradient", "Machine Learning Research", "Bengio", "Deep Convolutional Neural Networks", "Deep Convolutional Neural Networks Contradictions", "Rauhut", "Luo", "Sestini", "Sarussi", "Khrulkov", "Montangero", "Yanai", "Garcke", "Standard", "Kohn", "Krishnan", "Schneider", "M. J. Numerical", "Lucchesi", "Physics", "Fix T", "Linsley", "Grasedyck", "P", "Neyshabur", "Oseledets", "Mulayoff", "Hence", "Wh1", "Bah", "Bader", "Lerer", "Razin", "Oymak", "Levine", "Gidel", "Trager", "Lemma", "Optimization", "Linear Algebra", "N. Kernel", "Taylor", "Azulay", "Which", "Zhang", "Gunasekar", "Lemmas", "U V", "Krizhevsky", "Adlam", "Qiao", "Blanc", "H. Gradient", "Tang", "Mohlenkamp", "Nacson", "Novikov", "Gross", "Dehghani", "W RH1", "Perfect P", "Research Institute", "V RD1", "Kim", "Milanesi", "Ruder", "Bartlett", "B. W. Tensor", "Moroshko", "Chanan", "Terstiege", "Remote Sensing", "T. G. Multilinear", "Quantum Information", "Wies", "Telgarsky", "Navon", "Hardt", "Implicit Regularization", "Matrix Analysis", "Deferred Proofs", "Balda", "Kolda", "B", "J. Graph", "M. J. Multivariate", "Tay", "Ganguli", "Harrison", "Appendix", "J", "Shashua", "Deep Convolutional Neural Networks Noticing", "Vidal", "Deep Convolutional Neural Networks Ji", "Chanussot", "W", "Kressner", "Network Figure", "V RD2", "Yakira", "Golan", "Van Gool", "Mont", "Kadri", "Left", "Zygalakis", "Paszke", "Deep Convolutional Neural Networks Wies", "Pesme", "Beylkin", "Arora", "Deep Convolutional Neural Networks Furthermore", "Weight Decay Ours", "Fann", "Implicit", "Lemma 2", "Deep Convolutional Neural Networks Proof", "Jannai", "Lee", "Ergen", "Ren", "Analysis", "Kronecker", "Numerical", "Cao", "Denote", "L", "Same Class", "Trenti", "Eftekhari", "Bata", "R", "Saxe", "Wang", "Joint Conference", "Gissin", "Grant", "Merkh", "H1", "Vardi", "Ayache", "Si S", "Hazan", "Criminisi", "Quantum Science", "Low", "Arti", "Deep Convolutional Neural Networks Cohen", "Herrmann"]}{"title": ["Reinforced Cooperative Load Balancing in Data Center"], "authors": ["[arxiv.Result.Author('Zhiyuan Yao'), arxiv.Result.Author('Zihan Ding'), arxiv.Result.Author('Thomas Clausen')]"], "link": ["http://arxiv.org/pdf/2201.11727v1"], "summary": "Network load balancers are central components in modern data centers, that\ncooperatively distribute workloads of high arrival rates across application\nservers, thereby contribute to offering scalable services. The independent and\n\"selfish\" load balancing strategy is not necessarily the globally optimal one.\nThis paper represents the load balancing problem as a cooperative team-game\nwith limited observations over system states, and adopts multi-agent\nreinforcement learning methods to make fair load balancing decisions without\ninducing additional processing latency. On both a simulation and an emulation\nsystem, the proposed method is evaluated against other load balancing\nalgorithms, including state-of-the-art heuristics and learning-based\nstrategies. Experiments under different settings and complexities show the\nadvantageous performance of the proposed method.", "entities_include_in_text": ["Dragoni et al., 2017", "Kumar et al., 2020", "Goren et al., 2020", "Desmouceaux et al., 2018", "Chen et al.,\n2018; Mao et al., 2018; Xu et al., 2019; Sivakumar et al.,\n2019", "Dragoni et al., 2017", "Goren et al., 2020", "Chen et al., 2018; Mao et al., 2018; Wu et al., 2011", "Rashid et al., 2018", "Roy et al.,\n2015", "Roy et al., 2015", "Sen et al., 2013", "Oliehoek and Amato, 2016", "Rashid et al., 2018", "Patel et al., 2013", "Rashid et al., 2018", "Roy et al., 2015", "Sen et al., 2013", "Sivakumar et al., 2019", "Wu et al., 2011", "Xu et al., 2019", "Chen et al., 2018", "Desmouceaux et al., 2018", "Dragoni et al., 2017", "Goren et al., 2020", "Kumar et al., 2020", "Mao et al., 2018", "Oliehoek and Amato, 2016"], "entities_from_reference": ["Alberto Lluch Lafuente", "Yoram Moses", "Springer", "Jinnah Dylan Hosein", "Mao", "Tabish Rashid", "Yoann Desmouceaux", "Justinas Lingys", "Rashid", "Sunghwan", "Pengcheng Zhang", "Randy Kern", "Ananta", "Daniel E Eisenbud", "Mohammad Alizadeh", "Joelle Pineau", "Michael J Freedman", "Parveen Patel", "Fabrizio Montesi", "Sivakumar", "Shay", "Future Generation", "Alexander H Miller", "Guy Goren", "Marios Zikos", "Jasmeet Bagga", "Sebastian Riedel.", "George Porter", "Larisa Safina", "Yang Xu", "Bin Cheyney", "Yoram Moses.", "Carlo Contavalli", "Alberto Lluch", "Jun Wu", "Mike Rabbat", "Shimon Whiteson", "Scalable", "Xin Xu", "Wentao Shang", "Hongzi Mao", "Data Communication", "Jonathan Chao", "Chen", "Tollet", "Dragoni", "Larisa Safina.", "Hongyu Wu", "Siddhartha Sen", "Oliehoek", "Ashkan Aghdai", "Iyswarya Narayanan", "Amato", "Shay Vargaftik", "Cody Smith", "Michael I-C Wang", "Alex C. Snoeren", "Manuel Mazzara", "Eisenbud", "Jun Xu", "Maglev", "Kumar", "Chunming Liu", "Cheng Yi", "Aghdai", "Symposium", "Alex C. Snoeren.", "Christian Schroeder", "Saverio Giallorenzo", "David A Maltz", "Ruslan Mustafin", "Thomas Clausen.", "Shaileshh Bojja Venkatakrishnan", "Mikayel Samvelyan", "Kai Chen", "Sebastian Riedel", "Machine Learning", "David H Dai", "Adithya Kumar", "Wenjun Xu", "Ashwin Murthy", "Christopher Amato", "Qmix", "Charles", "Ardas Cilingiroglu", "Patel", "Malte Schwarzkopf", "Timothy Zhu", "Heinrich K", "Charles H-P", "Frans A Oliehoek", "Eric MannHielscher", "Nicola Dragoni", "Gregory Farquhar", "Hongyi Zeng", "Shuguang Cui", "Li Chen", "Zhi Wang", "David Shue", "Wang", "Arjun Roy", "Thomas Clausen", "Jiaru Lin", "Hemant Kumar", "Pierre Pfister", "Nantas Nardelli", "Zili Meng", "Daniel", "Mark Townsley", "Feng Liu", "Goren", "Yue Xu", "Christopher Amato.", "Albert Greenberg", "David", "Jakob Foerster", "Michael", "Roman Kononov", "Jonathan Chao.", "Deepak Bansal", "Lihua Yuan"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Liefooghe", "Whitley", "Vega", "Meyarivan", "Berlin", "Guo", "Machinery", "Paquete", "Rechenberg", "Suganthan", "Voigt", "Aguirre", "Beume", "Alyahya", "Fonseca", "Zhao", "Louren", "Li", "Miettinen", "Jim enez", "Tusar", "Kerschke", "Trautmann", "Deb", "Zhou", "Springer International Publishing", "Campelo", "Ochoa", "Colchester", "Emmerich", "European Journal", "Blum", "Laredo", "Nature PPSN XVI", "Fieldsend", "Castillo", "Bossek", "Sch", "Doerr", "Swarm", "Jim", "Deutz", "Schwefel", "Wang", "Springer Berlin", "Verel", "Springer Berlin Heidelberg", "Batista", "Liu", "Agarwal", "Filipic", "Naujoks", "Applied Soft", "Nature PPSN XV", "Tsou", "Tomassini", "Aranha", "Zhang", "Nature PPSN IV", "Nanyang", "G. Ochoa"]}{"title": ["Simplicial Convolutional Filters"], "authors": ["[arxiv.Result.Author('Maosheng Yang'), arxiv.Result.Author('Elvin Isufi'), arxiv.Result.Author('Michael T. Schaub'), arxiv.Result.Author('Geert Leus')]"], "link": ["http://arxiv.org/pdf/2201.11720v1"], "summary": "We study linear filters for processing signals supported on abstract\ntopological spaces modeled as simplicial complexes, which may be interpreted as\ngeneralizations of graphs that account for nodes, edges, triangular faces etc.\nTo process such signals, we develop simplicial convolutional filters defined as\nmatrix polynomials of the lower and upper Hodge Laplacians. First, we study the\nproperties of these filters and show that they are linear and shift-invariant,\nas well as permutation and orientation equivariant. These filters can also be\nimplemented in a distributed fashion with a low computational complexity, as\nthey involve only (multiple rounds of) simplicial shifting between upper and\nlower adjacent simplices. Second, focusing on edge-flows, we study the\nfrequency responses of these filters and examine how we can use the\nHodge-decomposition to delineate gradient, curl and harmonic frequencies. We\ndiscuss how these frequencies correspond to the lower- and the upper-adjacent\ncouplings and the kernel of the Hodge Laplacian, respectively, and can be tuned\nindependently by our filter designs. Third, we study different procedures for\ndesigning simplicial convolutional filters and discuss their relative\nadvantages. Finally, we corroborate our simplicial filters in several\napplications: to extract different frequency components of a simplicial signal,\nto denoise edge flows, and to analyze financial markets and traffic networks.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["The Low-Redshift Lyman Continuum Survey I: New, Diverse Local Lyman-Continuum Emitters"], "authors": ["[arxiv.Result.Author('Sophia R. Flury'), arxiv.Result.Author('Anne E. Jaskot'), arxiv.Result.Author('Harry C. Ferguson'), arxiv.Result.Author('Gabor Worseck'), arxiv.Result.Author('Kirill Makan'), arxiv.Result.Author('John Chisholm'), arxiv.Result.Author('Alberto Saldana-Lopez'), arxiv.Result.Author('Daniel Schaerer'), arxiv.Result.Author('Stephan McCandless'), arxiv.Result.Author('Bingjie Wang'), arxiv.Result.Author('N. M. Ford'), arxiv.Result.Author('Timothy Heckman'), arxiv.Result.Author('Zhiyuan Ji'), arxiv.Result.Author('Mauro Giavalisco'), arxiv.Result.Author('Ricardo Amorin'), arxiv.Result.Author('Hakim Atek'), arxiv.Result.Author('Jeremy Blaizot'), arxiv.Result.Author('Sanchayeeta Borthakur'), arxiv.Result.Author('Cody Carr'), arxiv.Result.Author('Marco Castellano'), arxiv.Result.Author('Stefano Cristiani'), arxiv.Result.Author('Stephane de Barros'), arxiv.Result.Author('Mark Dickinson'), arxiv.Result.Author('Steven L. Finkelstein'), arxiv.Result.Author('Brian Fleming'), arxiv.Result.Author('Fabio Fontanot'), arxiv.Result.Author('Thibault Garel'), arxiv.Result.Author('Andrea Grazian'), arxiv.Result.Author('Matthew Hayes'), arxiv.Result.Author('Alaina Henry'), arxiv.Result.Author('Valentin Mauerhofer'), arxiv.Result.Author('Genoveva Micheva'), arxiv.Result.Author('M. S. Oey'), arxiv.Result.Author('Goran Ostlin'), arxiv.Result.Author('Casey Papovich'), arxiv.Result.Author('Laura Pentericci'), arxiv.Result.Author('Swara Ravindranath'), arxiv.Result.Author('Joakim Rosdahl'), arxiv.Result.Author('Michael Rutkowski'), arxiv.Result.Author('Paola Santini'), arxiv.Result.Author('Claudia Scarlata'), arxiv.Result.Author('Harry Teplitz'), arxiv.Result.Author('Trinh Thuan'), arxiv.Result.Author('Maxime Trebitsch'), arxiv.Result.Author('Eros Vanzella'), arxiv.Result.Author('Anne Verhamme'), arxiv.Result.Author('Xinfeng Xu')]"], "link": ["http://arxiv.org/pdf/2201.11716v1"], "summary": "The origins of Lyman continuum (LyC) photons responsible for the reionization\nof the universe are as of yet unknown and highly contested. Detecting LyC\nphotons from the epoch of reionization is not possible due to absorption by the\nintergalactic medium, which has prompted the development of several indirect\ndiagnostics to infer the rate at which galaxies contribute LyC photons to\nreionize the universe by studying lower-redshift analogs. We present the\nLow-redshift Lyman Continuum Survey (LzLCS) comprising measurements made with\nHST/COS for a z=0.2-0.4 sample of 66 galaxies. After careful processing of the\nFUV spectra, we obtain a total of 35 Lyman continuum emitters (LCEs) detected\nwith 97.725% confidence, nearly tripling the number of known local LCEs. We\nestimate escape fractions from the detected LyC flux and upper limits on the\nundetected LyC flux, finding a range of LyC escape fractions up to 50%. Of the\n35 LzLCS LCEs, 12 have LyC escape fractions greater than 5%, more than doubling\nthe number of known local LCEs with cosmologically relevant LyC escape.", "entities_include_in_text": ["e.g., Fan et al. 2006; Yang et al. 2020", "e.g.,\nPaoletti et al. 2020; Planck Collaboration et al.\n2020", "e.g., Mason et al.\n2018; Pahl et al. 2020", "Naidu\net al. 2020", "e.g., Finkelstein\net al. 2019), owing largely to steeper lumi-\nnosity functions than those adopted by Naidu\net al. (2020", "e.g., Trebitsch et al. 2017", "e.g., Finkelstein et al. 2019;\nDayal et al. 2020", "Stei-\ndel et al. 2001", "e.g., Bouwens et al.\n2016; Schaerer et al. 2016", "e.g., Steidel et al. 2018", "Finkelstein et al. 2015, 2019", "Robertson et al. 2015; Naidu et al. 2020", "e.g.,\nVanzella et al. 2012; Mostardi et al. 2015; Siana\net al. 2015", "e.g., Becker et al. 2021", "e.g., Inoue et al. 2014; Steidel et al. 2018", "cf. Chisholm et al. 2017 regarding\nLeitherer et al. 2016", "cf.\nIzotov et al. 2016b regarding FUSE\nobservations by Leitet et al. 2013", "Steidel et al. 2018;\nesc\nVanzella et al. 2018", "Mostardi\nf LyC\net al. 2015; de Barros et al. 2016; Vanzella et al.\n2016; Bian et al. 2017; Micheva et al. 2017;\nFletcher et al. 2019; Rivera-Thorsen et al. 2019;\nJi et al. 2020", "e.g., Sharma et al. 2017; Naidu et al.\nf LyC\nesc\n2020", "e.g., Zackris-\nson et al. 2013, 2017", "SDSS, York\net al. 2000", "GALEX, Martin et al. 2003", "Blanton et al. 2017", "Baldwin et al. 1981", "Green et al. 2012", "cf. Izotov\net al. 2021", "Worseck\n\net al. 2016; Makan et al. 2020", "Izotov\net al. 2021", "Luridiana et al. 2015", "see discussion in Curti et al. 2017", "e.g., Gordon\net al. 2003", "Izotov et al. 2017", "e.g., Guaita\net al. 2015; Wisotzki et al. 2016; Leclercq et al.\n2017; Rasekh et al. 2021", "e.g., Hayes et al. 2013", "Foreman-Mackey et al. 2013", "Fer-\nland et al. 2013", "e.g., Wang et al. 2019", "Leja et al. 2017; Johnson et al. 2019", "e.g., Verhamme et al.\n2015", "e.g., Carr\net al. 2021", "e.g., Giavalisco et al. 1996", "Leitherer et al. 1999, 2014", "Bouwens et al. 2015", "cf. Wang et al. 2019", "Flury et al.\nsubmitted,\nWang et al. 2021", "AstropyCollaboration\net al. 2013, 2018", "Ferland et al. 2013", "Foreman-Mackey et al. 2013", "Worseck et al. 2016; Makan et al. 2020", "Hunter 2007", "van der\nWaltetal.2011", "Lejaetal.2017;\nJohnson et al. 2019", "Luridiana et al.\n2015", "P.Virtanen2020", "Leitherer et al. 1999, 2010, 2014"], "entities_from_reference": ["Plusieurs"]}{"title": ["String diagrams for non-strict monoidal categories"], "authors": ["[arxiv.Result.Author('Paul Wilson'), arxiv.Result.Author('Dan Ghica'), arxiv.Result.Author('Fabio Zanasi')]"], "link": ["http://arxiv.org/pdf/2201.11738v1"], "summary": "Whereas string diagrams for strict monoidal categories are well understood,\nand have found application in several fields of Computer Science, graphical\nformalisms for non-strict monoidal categories are far less studied. In this\npaper, we provide a presentation by generators and relations of string diagrams\nfor non-strict monoidal categories, and show how this construction can handle\napplications in domains such as digital circuits and programming languages. We\nprove the correctness of our construction, which yields a novel proof of Mac\nLane's strictness theorem. This in turn leads to an elementary graphical proof\nof Mac Lane's coherence theorem, and in particular allows for the inductive\nconstruction of the canonical isomorphisms in a monoidal category.", "entities_include_in_text": [], "entities_from_reference": ["Edward Grefenstette", "David Sprunger", "Aleks Kissinger", "Shlomo Gelaki", "Bonchi", "Dan R. Ghica", "Fabio Zanasi", "Victor Ostrik", "Pure Appl", "Bob Coecke", "Dmitri Nikshych", "Mehrnoosh Sadrzadeh", "Cambridge University Press", "Sriram K. Rajamani", "Mario Alvarez-Picallo", "Lambek", "Annual ACM", "P. I. Etingof", "Example", "David Walker", "Ann", "Sn", "Pawel Sobocinski", "Fabio Zanasi."]}{"title": ["PRNU Based Source Camera Identification for Webcam and Smartphone Videos"], "authors": ["[arxiv.Result.Author('Fernando Mart\u00edn-Rodr\u00edguez'), arxiv.Result.Author('Fernando Isasi-de-Vicente')]"], "link": ["http://arxiv.org/pdf/2201.11737v1"], "summary": "This communication is about an application of image forensics where we use\ncamera sensor fingerprints to identify source camera (SCI: Source Camera\nIdentification) in webcam/smartphone videos. Sensor or camera fingerprints are\nbased on computing the intrinsic noise that is always present in this kind of\nsensors due to manufacturing imperfections. This is an unavoidable\ncharacteristic that links each sensor with its noise pattern. PRNU (Photo\nResponse Non-Uniformity) has become the default technique to compute a camera\nfingerprint. There are many applications nowadays dealing with PRNU patterns\nfor camera identification using still images. In this work we focus on video,\nfirst on webcam video and afterwards on smartphone video. Webcams and\nsmartphones are the most used video cameras nowadays. Three possible methods\nfor SCI are implemented and assessed in this work.", "entities_include_in_text": [], "entities_from_reference": ["M. Mohanty", "J. Fridrich", "Shullani", "Robustez", "M. Goljan", "Chui", "Eurasip Journal", "Hassebrook", "Machine Intelligence", "D. Shullani", "H. Ogawa", "Effect", "Imagen Basada", "Wiener", "Pattern Analysis", "San Francisco", "Fridrich", "Media Watermarking", "Filler", "Master Thesis", "S. Taspinar", "Applied Optics", "Kumar", "Media Forensics", "Study", "Estudio", "San Diego", "Fingerprint Camera Electronic Imaging", "Large Scale Test", "M. Chen"]}{"title": ["Ranking Info Noise Contrastive Estimation: Boosting Contrastive Learning via Ranked Positives"], "authors": ["[arxiv.Result.Author('David T. Hoffmann'), arxiv.Result.Author('Nadine Behrmann'), arxiv.Result.Author('Juergen Gall'), arxiv.Result.Author('Thomas Brox'), arxiv.Result.Author('Mehdi Noroozi')]"], "link": ["http://arxiv.org/pdf/2201.11736v1"], "summary": "This paper introduces Ranking Info Noise Contrastive Estimation (RINCE), a\nnew member in the family of InfoNCE losses that preserves a ranked ordering of\npositive samples. In contrast to the standard InfoNCE loss, which requires a\nstrict binary separation of the training pairs into similar and dissimilar\nsamples, RINCE can exploit information about a similarity ranking for learning\na corresponding embedding space. We show that the proposed loss function learns\nfavorable embeddings compared to the standard InfoNCE whenever at least noisy\nranking information can be obtained or when the definition of positives and\nnegatives is blurry. We demonstrate this for a supervised classification task\nwith additional superclass labels and noisy similarity scores. Furthermore, we\nshow that RINCE can also be applied to unsupervised training with experiments\non unsupervised representation learning from videos. In particular, the\nembedding yields higher classification accuracy, retrieval rates and performs\nbetter in out-of-distribution detection than the standard InfoNCE loss.", "entities_include_in_text": ["Zhao et al. 2021", "Khosla\net al. 2020", "Deselaers and Ferrari 2011", "Feichtenhofer et al. 2021", "Dave et al. 2021", "Khosla et al. 2020", "Liu et al. 2019", "Dosovitskiy et al. 2016", "van den Oord,\nLi, and Vinyals 2018", "Sohn 2016", "Tian, Krishnan, and\nIsola 2020", "Misra and van der Maaten 2020", "He et al. 2020", "van den Oord, Li, and\nVinyals 2018", "Behrmann,\nGall, and Noroozi 2021", "Chen and He 2021; Grill et al. 2020", "Miech et al.\n2020", "Han,\nXie, and Zisserman 2020", "Caron et al. 2020", "Khosla et al.\n2020", "Huynh et al.\n2020", "Romijnders et al. 2021", "Tian et al. 2020", "Neill and Bollegala 2021", "Khosla et al.\n2020", "Huynh et al.\n2020", "Winkens et al. 2020", "Burges et al. 2005; Cakir et al. 2019; Cao et al. 2007;\nLiu 2009", "Weinberger, Blitzer, and Saul 2006", "Sohn 2016", "Tschannen et al. 2020", "Ge 2018", "Zhao et al. 2021", "Khosla et al. 2020", "Miech et al. 2020", "Wang and Liu 2021", "Deselaers and Ferrari 2011", "Krizhevsky, Hinton et al. 2009", "Le and Yang 2015", "Deng et al. 2009", "Tian, Krishnan, and Isola 2020", "Liu et al. 2019", "Weinberger, Blitzer, and Saul\n2006", "Khosla et al. 2020", "Ge 2018", "Cakir et al. 2019", "Szegedy et al. 2016", "Lee and\nCheon 2020", "Lee\nand Cheon 2020", "Sastry and Oore 2020", "Weinberger, Blitzer, and Saul 2006", "Winkens et al. 2020", "Hendrycks et al. 2019; Winkens et al.\n2020", "Lee et al.\n2018; Liang, Li, and Srikant 2018; Winkens et al. 2020", "Winkens et al. 2020", "Winkens et al. 2020", "Liang, Li, and Srikant 2018", "Lee\net al. 2018", "Xian et al. 2018", "Liu et al. 2019", "Xian et al. 2018", "Tschan-\nnen et al. 2020", "Zhuang et al. 2020", "Tokmakov,\nHebert, and Schmid 2020", "Kay et al. 2017", "Soomro, Zamir, and Shah 2012", "Kuehne\net al. 2011", "Li, Li, and Vasconcelos 2018", "Wang and Liu 2021", "Wang and Liu 2021", "Wang\nand Liu 2021)", "Khosla et al. 2020", "Miech et al. 2020; Han, Xie, and Zisserman 2020", "Le and Yang 2015", "Deng et al. 2009", "Tian, Krishnan, and Isola 2020", "Liu et al. 2019", "Liu et al. 2019", "Reimers and Gurevych 2019", "Cer et al. 2017", "Khosla et al. 2020", "Khosla et al. 2020", "Khosla et al. 2020", "Khosla\net al. 2020", "Krizhevsky 2014", "Khosla et al. 2020", "Khosla et al. 2020", "He et al. 2020", "Khosla et al. 2020", "Ge 2018", "Cakir et al. 2019", "Winkens et al. 2020", "Pedregosa et al.\n2011", "Hara, Kataoka, and Satoh 2018", "Kingma and Ba 2015", "He et al. 2020", "Van der Maaten and Hinton 2008", "Wang and Isola 2020", "Wang and Isola 2020", "Wang and Isola 2020"], "entities_from_reference": ["Roberta", "Garrote", "Guo", "Rank2", "Cakir", "V100 GPU", "Valko", "Satoh", "Similar", "Videos", "Fan", "Dense Trajectory Clustering", "Average", "Note", "Video Representations", "Large Margin Nearest Neighbor", "Qin", "Alayrac", "J. O.", "Video Representation", "Neill", "Sastry", "Negative Samples", "Feature Learning", "L", "Fast AP", "Accuracy Rank2", "Fischer", "Kingma", "Liang", "Datasets TinyImageNet", "Miech", "Again", "Tab", "Shin", "Label Smoothing", "Krishnan", "Affects", "Riedmiller", "Jhuang", "Brucher", "Roy", "Van", "Hierarchical Triplet", "Lee", "Diab", "Brox", "Hara", "Deep", "Red", "Winkens", "Soomro", "Hinton", "Richemond", "Viola", "Label", "Suleyman", "Action Recognition", "Sohn", "Zhang", "Accuracy", "Exemplar Convolutional Neural Networks", "Liu", "Lin", "Szegedy", "Chen", "Fig", "Zhao", "Ferrari", "Weinberger", "Triplet", "Dosovitskiy", "Gelly", "J. T.", "False Negative", "Cer", "Loss Objective", "Hullender", "Figure K", "Zisserman", "Akata", "Video", "Caron", "Makes Instance", "Zhuang", "Avila Pires", "Mark", "Lucic", "Oord", "Lfine", "Bollegala", "Bojanowski", "Gheshlaghi Azar", "Ltriplet", "Han", "Renshaw", "Li", "Sivic", "Visual Features", "Walter", "Hillier", "Xian", "Ott", "Memory", "Khosla", "R. W. H.;", "Model Robustness", "Duchesnay", "Momentum Contrast", "Discriminative", "Kay", "Tschannen", "Accuracy R", "Multiview Coding", "Hebert", "Burges", "Zamir", "Kulis", "Yang 2015)", "Carreira", "Pytorch", "Deep Neural Embeddings", "Michel", "Wang", "Huynh", "Yang", "Loss Analysis", "Cao", "Joshi", "Loss Variants", "Grill", "Vanhoucke", "Pedregosa", "Schiele", "Kataoka", "Sarna", "Houlsby", "Krizhevsky", "Joulin", "Deng", "Stoyanov", "Deep Neural Networks", "Tech Report", "Machine Learning", "Triplet Loss", "Smaira", "Feichtenhofer", "Distance Metric Learning", "Hendrycks", "Critical", "Lampert", "Deep Metric Learning", "J. R.", "Blondel", "Tian", "Simonyan", "Maaten", "Le", "Data", "Kuehne", "Visual", "Isola", "Numpy", "Khademi", "Rank Using Gradient", "Xie", "Appendix", "Levy", "Dave", "Stanforth", "Strub", "Ritter", "Hard", "Lau", "Misra", "Tokmakov", "Visual Representations", "Wojna", "Lewis", "Adam", "Which", "Baselines", "Shah", "V100 GPUs", "Girshick"]}{"title": ["IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages"], "authors": ["[arxiv.Result.Author('Emanuele Bugliarello'), arxiv.Result.Author('Fangyu Liu'), arxiv.Result.Author('Jonas Pfeiffer'), arxiv.Result.Author('Siva Reddy'), arxiv.Result.Author('Desmond Elliott'), arxiv.Result.Author('Edoardo Maria Ponti'), arxiv.Result.Author('Ivan Vuli\u0107')]"], "link": ["http://arxiv.org/pdf/2201.11732v1"], "summary": "Reliable evaluation benchmarks designed for replicability and\ncomprehensiveness have driven progress in machine learning. Due to the lack of\na multilingual benchmark, however, vision-and-language research has mostly\nfocused on English language tasks. To fill this gap, we introduce the\nImage-Grounded Language Understanding Evaluation benchmark. IGLUE brings\ntogether - by both aggregating pre-existing datasets and creating new ones -\nvisual question answering, cross-modal retrieval, grounded reasoning, and\ngrounded entailment tasks across 20 diverse languages. Our benchmark enables\nthe evaluation of multilingual multimodal models for transfer learning, not\nonly in a zero-shot setting, but also in newly defined few-shot learning\nsetups. Based on the evaluation of the available state-of-the-art models, we\nfind that translate-test transfer is superior to zero-shot transfer and that\nfew-shot learning is hard to harness for many tasks. Moreover, downstream\nperformance is partially explained by the amount of available unlabelled\ntextual data for pretraining, and only weakly by the typological distance of\ntarget-source languages. We hope to encourage future research efforts in this\narea by releasing the benchmark to the community.", "entities_include_in_text": ["Jauhar et al., 2018; Ponti et al., 2020", "Elliott et al.,\n2016", "Bender, 2011; Ponti et al., 2019;\nLiu et al., 2021", "Srinivasan et al., 2021", "Pfeiffer et al., 2021", "Huang et al., 2021; Lei\net al., 2021", "Liu et al., 2021", "Jain et al., 2021", "Ni et al., 2021; Jain et al., 2021", "Liang et al., 2020", "Ruder et al., 2021", "Lauscher et al., 2020; Zhao et al., 2021", "Ni et al.,\n2021; Zhou et al., 2021; Liu et al., 2021", "Lauscher et al., 2020", "Bernardi et al., 2016; Baltrusaitis et al., 2019", "Kiela et al., 2015; Gella et al., 2017;\nCaglayan et al., 2021", "Ponti et al.,\n2020", "Liu et al., 2021", "Rotman et al., 2018; Wehrmann et al., 2019;\nHuang et al., 2019; Kim et al., 2020; Su et al., 2021", "Ni et al., 2021;\nZhou et al., 2021; Liu et al., 2021", "Chen et al., 2020;\nPfeiffer et al., 2021", "Wang et al., 2018", "Wang et al., 2019", "Wilie et al., 2020", "Park et al., 2021", "Shavrina et al., 2020", "Dumitrescu et al., 2021", "Hu\net al., 2020", "Liang et al., 2020", "Ruder et al., 2021", "Hu et al., 2020;\nLiang et al., 2020; Ruder et al., 2021", "Bowman et al., 2015", "Xie et al., 2019", "Krishna et al., 2017", "Liu et al., 2021", "Suhr et al., 2019", "Young et al., 2014", "Lin et al., 2014", "Yoshikawa\net al., 2017; Nakayama et al., 2020", "van Miltenburg et al., 2017; Frank et al., 2018", "Jia et al., 2021", "van\nMiltenburg et al., 2018", "Lan et al., 2017", "Mishra et al., 2021", "Scaiella et al., 2019", "Lam et al., 2020", "Aggarwal et al., 2021", "Elliott et al., 2016", "Srinivasan\net al., 2021", "measured in number of ar-\nticles as of Jan 2022", "Joshi et al., 2020; Blasi\net al., 2021", "Hu et al., 2020; Liang et al., 2020; Ruder et al.,\n2021", "Zhao et al., 2021", "Bugliarello et al., 2021", "Paszke\net al., 2019", "Devlin et al., 2019", "Ren\net al., 2015", "Sennrich\net al., 2016; Wu et al., 2016", "Vaswani et al., 2017", "Chen et al., 2020) multi-\nlingually by following the base approach of Ni et al.\n(2021", "Devlin et al., 2019", "Conneau et al., 2020", "Bugliarello\net al., 2021", "Chen et al.,\n2020", "Lu et al., 2019", "Su et al., 2020", "He et al., 2016", "Xie et al., 2017", "Krishna et al., 2017;\nAnderson et al., 2018", "Geigle\net al., 2022", "as of January 2022", "Ponti et al., 2020; Ruder et al., 2021", "Lauscher et al., 2020", "LREC 2018", "SIU 2016", "Elliott et al.,\n2016", "Mishra et al.,\n2021", "Unal et al., 2016", "Srinivasan et al., 2021", "Bugliarello et al., 2021", "He et al., 2016", "Xie et al., 2017", "Krishna et al., 2017; Anderson et al., 2018", "Lu\net al., 2020; Bugliarello et al., 2021", "Ni et al., 2021", "Zhou et al., 2021", "Bugliarello\net al., 2021", "Elliott et al., 2016", "Elliott et al., 2016)\n\nand Nakayama et al. (2020"], "entities_from_reference": ["Italian Journal", "Levin", "Guo", "Anton", "Cotterell", "Santa Fe", "Lim", "Visual Entailment", "Qiao", "Pattern Recognition", "Bender", "Machine Translation", "Killeen", "J. O.", "Test", "Ren", "I. Composable", "Morogan", "Jauhar", "Further", "Minnesota", "Gould", "Santiago", "Liang", "Artemova", "Shareghi", "Chanan", "Shin", "Botha", "Trawi", "Rebeja", "Anderson", "Valencia", "Gross", "Short Papers", "Lee", "Task Papers", "Brox", "Saha", "Schuster", "Deep", "Uniform", "Lerer", "Vilbert", "Morency", "Tanti", "Fenogenova", "Ionescu", "Benchmarks Track", "Mishra", "J. Uc2", "Vincentio", "Fung", "Shutova", "Batra", "Bendersky", "Caglayan", "Grave", "Dryer", "Littell", "Chen", "Shazeer", "Zhao", "Annual Meeting", "Jang", "Visual QA", "Desmaison", "Madison", "Sennrich", "Bowman", "Amac", "Lang Model", "Experimental Details", "Dataset Metric", "Microsoft COCO", "Retrieval", "Short", "Shamma", "Citamak", "N. Baselines", "Erdem", "Zhou", "Han", "Hsieh", "Li", "Gatt", "Ott", "Okazaki", "Young", "Ruder", "Evlampiev", "Cho", "Human Language Technologies", "Mikhailov", "Conneau", "Saenko", "Poibeau", "Lei", "M3Pboth", "Yang", "Huynh", "Wehrmann", "Agi", "Parovic", "Joshi", "Dai", "Kopf", "Lauscher", "Marseille", "Max Planck Institute", "Gaman", "Schiele", "Birch", "Tejani", "Schick", "Bai", "Michael", "Garrette", "Vaswani", "Target Language", "Gaussian Error Linear Units", "Gimelshein", "Paszke", "Mandarin", "Faster", "Artzi", "Srinivasan", "Louisiana", "Dhir", "Lang", "Sharma", "Frank", "Jain", "Pascanu", "Socher", "Jabri", "Elliott", "Buehler", "Bernstein", "Gella", "Proceedings", "Barrault", "Levy", "Scaiella", "Kadav", "Berlin", "Avram", "Geigle", "Plank", "Duan", "Tan", "Method M3P", "Vision", "Jiang", "Keller", "Due", "Kuyu", "Girshick", "Yin", "Berg", "Hauptmann", "Tambi", "Pfeiffer", "Fan", "Appendix C", "Clark", "Dima", "Jurafsky", "J.", "A. (eds.)", "Dollar", "Budhiraja", "Iletisim Uygulamalar Kurultay", "Rotman", "Barzilay", "Singh", "Online", "Garnett", "Shigeto", "Cui", "Bischof", "Hutter", "Raman", "Machinery", "Apr", "Yoshikawa", "Bernardi", "Lam", "Visual Reasoning", "Lopes", "Baltrusaitis", "Melbourne", "Punta Cana", "Lai", "Devlin", "Roth", "Goodman", "M3P", "Uszkoreit", "Mean Recall", "Zitnick", "Muscat", "Goswami", "Hata", "Jia", "Yatskar", "Gamon", "Jafaritazehjan", "Bharti", "Luo", "Zhang", "Krishna", "Fang", "A. Minimax", "Liu", "Reddy", "Aralikatte", "Steiner", "Lin", "Metze", "Retrieval Performance", "Machine Learning Research", "Shavrina", "Mach", "Karpathy", "Nickel", "K.W. VisualBERT:", "Ilie", "Ahuja", "Sch", "Lan", "Kiela", "Lyu", "Dumitrescu", "Kalantidis", "Ahmed", "J. COCO-CN", "Chaudhary", "Raison", "Pattern Anal", "Sgaard", "Yao", "Gao", "Steitz", "Yagcioglu", "Firat", "Nakayama", "Bengio", "Iacobescu", "Model Initialisation Visual Tokens Pretrain Data", "Agrawal", "Bugliarello", "Suhr", "Xia", "Wang", "Gan", "Polosukhin", "Fox", "Vuli c", "Linguistic Issues", "Johnson", "Blasi", "Schluter", "Cao", "J. Y.", "Kim", "Benchmark", "Jones", "Toutanova", "El Kholy", "Gomez", "Park", "Cham", "Lorincz", "Towards", "Goyal", "Loshchilov", "Maire", "Soleman", "Berzak", "Huang", "Deng", "Hwang", "Stoyanov", "Rebedea", "Visual Genome", "Miltenburg", "J. UNITER", "Bradbury", "Machine Learning", "Miyazaki", "Wei", "Marchidan", "Hendrycks", "Sacheti", "Automatic", "Le", "Barros", "Mortensen", "Hill", "Xie", "Model NLI QA Reasoning Retrieval", "Copenhagen", "Asian Low-Resour", "Wallach", "Guzm", "Ethayarajh", "Leipzig", "Volume", "Hoang", "Hudson", "Chang", "Annual", "Saito", "Hays", "Tuytelaars", "Ponti", "Patrick", "Ramanan", "Swahili", "Anastasopoulos", "Ansell", "Wilie", "Zhu", "Moon"]}{"title": ["An Algorithmic Framework for Locally Constrained Homomorphisms"], "authors": ["[arxiv.Result.Author('Laurent Bulteau'), arxiv.Result.Author('Konrad K. Dabrowski'), arxiv.Result.Author('Noleen K\u00f6hler'), arxiv.Result.Author('Sebastian Ordyniak'), arxiv.Result.Author('Dani\u00ebl Paulusma')]"], "link": ["http://arxiv.org/pdf/2201.11731v1"], "summary": "A homomorphism $f$ from a guest graph $G$ to a host graph $H$ is locally\nbijective, injective or surjective if for every $u\\in V(G)$, the restriction of\n$f$ to the neighbourhood of $u$ is bijective, injective or surjective,\nrespectively. The corresponding decision problems, LBHOM, LIHOM and LSHOM, are\nwell studied both on general graphs and on special graph classes. Apart from\ncomplexity results when the problems are parameterized by the treewidth and\nmaximum degree of the guest graph, the three problems still lack a thorough\nstudy of their parameterized complexity. This paper fills this gap: we prove a\nnumber of new FPT, W[1]-hard and para-NP-complete results by considering a\nhierarchy of parameters of the guest graph $G$. For our FPT results, we do this\nthrough the development of a new algorithmic framework that involves a general\nILP model. To illustrate the applicability of the new framework, we also use it\nto prove FPT results for the Role Assignment problem, which originates from\nsocial network theory and is closely related to locally surjective\nhomomorphisms.", "entities_include_in_text": [], "entities_from_reference": ["Science", "Ton Kloks", "Mathematicae Graph Theory", "Algebraic Graph Theory", "Eduard Eiben", "John Stillwell.", "Eva Tardos", "Parameterized Algorithms", "Algebraic Topology", "Daniel Paulusma", "Karl P. Reitz", "Pavol Hell.", "Hjalmtyr Hafsteinsson", "Attila Por", "Michael U. Gerber", "Dana Angluin", "M. Puck Rombach.", "Springer", "Fundamenta Informaticae", "Martin Vatshelle", "Networks", "Eugene C. Freuder", "David G. Kirkpatrick", "Algorithmica", "Machinery", "David S. Johnson", "Mathematical Social Sciences", "Stephen P. Borgatti", "Karolina Okrasa", "Jeremie Chalopin", "Saket Saurabh", "Graphs", "K. K. Dabrowski", "Micha Pilipczuk", "Andreas Pfandler", "David S. Johnson.", "Arne Telle", "Aleksandar Pekec", "Structures", "Andrzej Proskurowski", "Oxford University Press", "Parameterized Complexity Theory", "Mendez", "Daniel Lokshtanov", "Michael R. Fellows", "Marek Tesar", "Graph Theory", "Jan Arne Telle.", "Math", "Vibha Sahlot", "World", "Markus S. Dregi", "Social Networks", "Hans L. Bodlaender", "Norman J. Biggs", "Fedor V. Fomin", "William S. Massey", "Pavel Klavik", "Pawe Rzazewski", "Pinar Heggernes", "Dana Angluin.", "Lukasz Kowalik", "Mitre Costa Dourado", "Springer Verlag", "Artif", "Ondrej Bilka", "Jan Arne Telle", "Frances A. Rosamond", "Eva Tardos.", "Neeldhara Misra", "Li Sheng", "Sukanya Pandey", "Fred S. Roberts.", "Hof", "Norman J. Biggs.", "Petr Hlineny", "William S. Massey.", "Cambridge University Press", "Martin Grohe", "N. Kohler", "S. Ordyniak", "Daniel Paulusma.", "Nikola Jedlickova", "Finite", "1974. L. Bulteau", "Harcourt", "Johan M.", "Australasian Journal", "Local", "Discrete Applied Mathematics", "Jorg Flum", "Hjalmtyr", "Graph", "Michael R. Fellows.", "Daniel Paulusma. Packing", "Andras Frank", "Marek Cygan", "Fred S. Roberts", "Daniel Paulusma. Graph", "Pim", "Marek Tesar.", "Nordic Journal", "Petter Kristiansen", "Sebastian Ordyniak", "Karl P. Reitz. Graph", "Venkatesh Raman", "Kohler", "Marcin Pilipczuk", "Johan M. M. van Rooij.", "Stephen P. Borgatti. Role", "Pavol Hell", "Pavel Dvorak", "D. Paulusma", "Hendrik W. Lenstra Jr.", "Arne Telle.", "Systems", "Moshe Y. Vardi", "Victor Dalmau", "Martin Kronegger", "John R. Gilbert", "Wieslaw Zielonka", "Jan Kratochvil", "Ravi Kannan. Minkowskis", "Steven Chaplick", "Jack Edmonds.", "Series B", "Locally Constrained", "Algorithms", "Jaroslav Nesetril", "Jack Edmonds", "Rodney G. Downey", "James Abello", "John Stillwell", "Pal Grnas Drange", "Fast", "Chandra Chekuri", "Jan Bok", "Dusan Knop", "Marek Tesar. Dichotomy", "Frank", "Hans L. Bodlaender.", "Phokion G. Kolaitis", "Marek Tesar. Complexity", "Rooij", "Brace", "Hendrik W. Lenstra", "Douglas R. White", "Bernard Lidicky", "Christopher Purcell", "Charles University", "Canadian Journal", "Daniel Marx", "Jiri Fiala", "Berlin", "Locally", "Daniel Kobler", "Sebastian Ordyniak.", "Lecture", "Daniel Kobler. Algorithms", "Paths", "Patrice Ossona", "Robert Ganian", "Martin G. Everett", "Michael Randolph Garey"]}{"title": ["Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks"], "authors": ["[arxiv.Result.Author('Noam Razin'), arxiv.Result.Author('Asaf Maman'), arxiv.Result.Author('Nadav Cohen')]"], "link": ["http://arxiv.org/pdf/2201.11729v1"], "summary": "In the pursuit of explaining implicit regularization in deep learning,\nprominent focus was given to matrix and tensor factorizations, which correspond\nto simplified neural networks. It was shown that these models exhibit implicit\nregularization towards low matrix and tensor ranks, respectively. Drawing\ncloser to practical deep learning, the current paper theoretically analyzes the\nimplicit regularization in hierarchical tensor factorization, a model\nequivalent to certain deep convolutional neural networks. Through a dynamical\nsystems lens, we overcome challenges associated with hierarchy, and establish\nimplicit regularization towards low hierarchical tensor rank. This translates\nto an implicit regularization towards locality for the associated convolutional\nnetworks. Inspired by our theory, we design explicit regularization\ndiscouraging locality, and demonstrate its ability to improve performance of\nmodern convolutional networks on non-local tasks, in defiance of conventional\nwisdom by which architectural changes are needed. Our work highlights the\npotential of enhancing neural networks via theoretical analysis of their\nimplicit regularization.", "entities_include_in_text": ["Zhang et al., 2017", "see, e.g., Neyshabur (2017)", "see Gunasekar et al. (2017)", "Hitch-\ncock, 1927", "Grasedyck, 2010; Grasedyck et al., 2013", "see, e.g., Wang et al. (2016); Linsley et al. (2018); Mly-\nnarski et al. (2019); Hong et al. (2020); Kim et al. (2020)", "Arora et al., 2018", "see,\ne.g., Saxe et al. (2014); Arora et al. (2018); Bartlett et al.\n(2018); Bah et al. (2019", "cf. Arora et al.\n(2019)", "Razin et al., 2021", "cf. Razin et al. (2021)", "Razin et al., 2021", "cf. Grasedyck et al.\n(2013)", "Gunasekar\net al., 2017; Soudry et al., 2018; Li et al., 2018; Woodworth\net al., 2020; Lyu et al., 2021", "Har-\nrison et al., 2003; Hackbusch, 2006; Beylkin et al., 2009", "He\net al., 2016", "Krizhevsky,\n2009", "Linsley et al., 2018;\nKim et al., 2020; Tay et al., 2021", "Linsley et al., 2018", "Gunasekar et al., 2018;\nJagadeesan et al., 2021; Kohn et al., 2021", "Razin et al.,\n2021; Ge et al., 2021", "Paszke et al.,\n2017", "Paszke\net al., 2017"], "entities_from_reference": ["Elkabetz", "J. D. Algorithmic", "Montangero", "Recht", "Mathar", "Wh1", "Optimization", "H1", "Soltanolkotabi", "Khrulkov", "Sarussi", "Deep Learning Workshop", "J. Gradient", "Qiao", "Pattern Recognition", "Bata", "Zuliani", "Standard", "Benedetti", "R", "Ren", "Research Institute", "Linear Algebra", "Springer", "Navon", "Blanc", "Quantum Science", "L", "H. Gradient", "Fann", "Arti", "M. J. Numerical", "Dehghani", "Gidel", "Harrison", "Grant", "Terstiege", "Kadri", "Globerson", "Ergen", "Mulayoff", "Hence", "Chanan", "Numerical", "Deep Convolutional Neural Networks", "Deep Convolutional Neural Networks Ji", "Felser", "Bartlett", "W RH1", "Balda", "Krishnan", "Van Gool", "Herrmann", "Trager", "Deep Convolutional Neural Networks Wies", "Vardi", "Lemmas", "Garcke", "Gross", "Lee", "Gupta", "Deep", "Plaza", "Lampinen", "Razin", "Lerer", "Frobenius", "V RH1", "Pesme", "Deep Convolutional Neural Networks Cohen", "P N2", "Mont", "Wies", "Delingette", "Luo", "Zhang", "Physics", "Mlynarski", "Merkh", "Pilanci", "Woodworth", "Yakira", "Tang", "Tarmoun", "J. Graph", "Saxe", "Lemma 2", "Lin", "Machine Learning Research", "Milanesi", "Denote", "Analysis", "Remote Sensing", "Same Class", "Kressner", "Lemma", "Criminisi", "N. Kernel", "Vidal", "Desmaison", "Oseledets", "Deep Convolutional Neural Networks Contradictions", "Moroshko", "Yun", "Margin", "Matrix Analysis", "Lyu", "Implicit Regularization", "Shachaf", "Shashua", "Perfect P", "Sharir", "Teschl", "Left", "Hardt", "Weight Decay Ours", "Li", "Yao", "Gao", "Upper", "Jagadeesan", "Si S", "Kolda", "Taylor", "Bengio", "Soudry", "Deferred Proofs", "Ruder", "Mohlenkamp", "Eftekhari", "Quantum Information", "Network Figure", "Trenti", "Telgarsky", "Wang", "Gissin", "Yang", "Tay", "M. J. Multivariate", "Sestini", "Tobler", "Cao", "Pennington", "U V", "Kim", "Kohn", "Implicit", "Joint Conference", "Golan", "V RD2", "Hitchcock", "Krizhevsky", "Arora", "P", "Levine", "Yanai", "Linsley", "Machine Learning", "Paszke", "Maman", "Novikov", "Zygalakis", "Bader", "Jannai", "Wei", "Low", "Kronecker", "T. G. Multilinear", "Grasedyck", "Neyshabur", "A. K.", "Nacson", "J. D.", "Hazan", "Azulay", "Adlam", "Deep Convolutional Neural Networks Noticing", "Arbitrary Initialization", "J", "Deep Convolutional Neural Networks Proof", "Shamir", "W", "Metzler", "Stojevic", "Gunasekar", "Beylkin", "Ayache", "Appendix", "J. L.", "V RD1", "Source", "Schneider", "Abnar", "N V", "Lemma 3", "Lemma 15", "B. W. Tensor", "Deep Convolutional Neural Networks Furthermore", "Deep Learning Theory", "Lucchesi", "Bah", "Cohen", "Chou", "B", "Ganguli", "Chanussot", "Oymak", "Hackbusch", "Rao", "Rauhut", "Which", "Steinlechner", "Da Silva", "Fix T"]}{"title": ["Reinforced Cooperative Load Balancing in Data Center"], "authors": ["[arxiv.Result.Author('Zhiyuan Yao'), arxiv.Result.Author('Zihan Ding'), arxiv.Result.Author('Thomas Clausen')]"], "link": ["http://arxiv.org/pdf/2201.11727v1"], "summary": "Network load balancers are central components in modern data centers, that\ncooperatively distribute workloads of high arrival rates across application\nservers, thereby contribute to offering scalable services. The independent and\n\"selfish\" load balancing strategy is not necessarily the globally optimal one.\nThis paper represents the load balancing problem as a cooperative team-game\nwith limited observations over system states, and adopts multi-agent\nreinforcement learning methods to make fair load balancing decisions without\ninducing additional processing latency. On both a simulation and an emulation\nsystem, the proposed method is evaluated against other load balancing\nalgorithms, including state-of-the-art heuristics and learning-based\nstrategies. Experiments under different settings and complexities show the\nadvantageous performance of the proposed method.", "entities_include_in_text": ["Dragoni et al., 2017", "Kumar et al., 2020", "Goren et al., 2020", "Desmouceaux et al., 2018", "Chen et al.,\n2018; Mao et al., 2018; Xu et al., 2019; Sivakumar et al.,\n2019", "Dragoni et al., 2017", "Goren et al., 2020", "Chen et al., 2018; Mao et al., 2018; Wu et al., 2011", "Rashid et al., 2018", "Roy et al.,\n2015", "Roy et al., 2015", "Sen et al., 2013", "Oliehoek and Amato, 2016", "Rashid et al., 2018", "Patel et al., 2013", "Rashid et al., 2018", "Roy et al., 2015", "Sen et al., 2013", "Sivakumar et al., 2019", "Wu et al., 2011", "Xu et al., 2019", "Chen et al., 2018", "Desmouceaux et al., 2018", "Dragoni et al., 2017", "Goren et al., 2020", "Kumar et al., 2020", "Mao et al., 2018", "Oliehoek and Amato, 2016"], "entities_from_reference": ["Shaileshh Bojja Venkatakrishnan", "Future Generation", "Gregory Farquhar", "Joelle Pineau", "Iyswarya Narayanan", "Michael J Freedman", "Heinrich K", "Carlo Contavalli", "Mikayel Samvelyan", "Mohammad Alizadeh", "Cheng Yi", "Jakob Foerster", "Yoram Moses.", "Ruslan Mustafin", "Albert Greenberg", "Arjun Roy", "Jun Xu", "David H Dai", "Zili Meng", "Nantas Nardelli", "Xin Xu", "Shuguang Cui", "Mao", "Ardas Cilingiroglu", "Bin Cheyney", "Daniel", "Christopher Amato.", "Wang", "Springer", "Tabish Rashid", "Jun Wu", "Kai Chen", "Eisenbud", "Shay", "Data Communication", "Sebastian Riedel.", "Christopher Amato", "Sunghwan", "Randy Kern", "Sivakumar", "Thomas Clausen.", "Thomas Clausen", "Fabrizio Montesi", "Michael", "Yue Xu", "Symposium", "Parveen Patel", "Hongyi Zeng", "Alberto Lluch", "Siddhartha Sen", "Pierre Pfister", "Ananta", "Cody Smith", "Charles", "Jonathan Chao", "Ashkan Aghdai", "Patel", "Jiaru Lin", "Mark Townsley", "Machine Learning", "Aghdai", "George Porter", "Jinnah Dylan Hosein", "Scalable", "Sebastian Riedel", "Christian Schroeder", "Nicola Dragoni", "Wenjun Xu", "Justinas Lingys", "Deepak Bansal", "Tollet", "Guy Goren", "Zhi Wang", "Chen", "David A Maltz", "Yoann Desmouceaux", "Hemant Kumar", "Alexander H Miller", "Rashid", "Yoram Moses", "Ashwin Murthy", "Manuel Mazzara", "Frans A Oliehoek", "Marios Zikos", "Alex C. Snoeren.", "Lihua Yuan", "Amato", "Jasmeet Bagga", "Larisa Safina.", "Daniel E Eisenbud", "Oliehoek", "Shimon Whiteson", "Eric MannHielscher", "Alberto Lluch Lafuente", "Hongyu Wu", "Saverio Giallorenzo", "Larisa Safina", "David", "Yang Xu", "Alex C. Snoeren", "Chunming Liu", "Shay Vargaftik", "Hongzi Mao", "Michael I-C Wang", "Feng Liu", "Malte Schwarzkopf", "Roman Kononov", "Jonathan Chao.", "Maglev", "Li Chen", "Goren", "Wentao Shang", "Pengcheng Zhang", "Charles H-P", "Adithya Kumar", "Timothy Zhu", "David Shue", "Kumar", "Dragoni", "Mike Rabbat", "Qmix"]}{"title": ["Search Trajectories Networks of Multiobjective Evolutionary Algorithms"], "authors": ["[arxiv.Result.Author('Yuri Lavinas'), arxiv.Result.Author('Claus Aranha'), arxiv.Result.Author('Gabriela Ochoa')]"], "link": ["http://arxiv.org/pdf/2201.11726v1"], "summary": "Understanding the search dynamics of multiobjective evolutionary algorithms\n(MOEAs) is still an open problem. This paper extends a recent network-based\ntool, search trajectory networks (STNs), to model the behavior of MOEAs. Our\napproach uses the idea of decomposition, where a multiobjective problem is\ntransformed into several single-objective problems. We show that STNs can be\nused to model and distinguish the search behavior of two popular multiobjective\nalgorithms, MOEA/D and NSGA-II, using 10 continuous benchmark problems with 2\nand 3 objectives. Our findings suggest that we can improve our understanding of\nMOEAs using STNs for algorithm analysis.", "entities_include_in_text": ["Apr 2015"], "entities_from_reference": ["Swarm", "Batista", "Blum", "Deutz", "Guo", "G. Ochoa", "Bossek", "Liefooghe", "Laredo", "Zhang", "Schwefel", "Paquete", "Trautmann", "Fonseca", "European Journal", "Nature PPSN XVI", "Filipic", "Verel", "Liu", "Voigt", "Doerr", "Zhao", "Wang", "Suganthan", "Whitley", "Beume", "Springer International Publishing", "Miettinen", "Berlin", "Springer Berlin", "Naujoks", "Louren", "Machinery", "Nature PPSN IV", "Nature PPSN XV", "Sch", "Tsou", "Tomassini", "Emmerich", "Tusar", "Jim", "Ochoa", "Aguirre", "Nanyang", "Campelo", "Aranha", "Meyarivan", "Alyahya", "Deb", "Applied Soft", "Jim enez", "Agarwal", "Fieldsend", "Kerschke", "Castillo", "Zhou", "Colchester", "Rechenberg", "Springer Berlin Heidelberg", "Li", "Vega"]}{"title": ["Simplicial Convolutional Filters"], "authors": ["[arxiv.Result.Author('Maosheng Yang'), arxiv.Result.Author('Elvin Isufi'), arxiv.Result.Author('Michael T. Schaub'), arxiv.Result.Author('Geert Leus')]"], "link": ["http://arxiv.org/pdf/2201.11720v1"], "summary": "We study linear filters for processing signals supported on abstract\ntopological spaces modeled as simplicial complexes, which may be interpreted as\ngeneralizations of graphs that account for nodes, edges, triangular faces etc.\nTo process such signals, we develop simplicial convolutional filters defined as\nmatrix polynomials of the lower and upper Hodge Laplacians. First, we study the\nproperties of these filters and show that they are linear and shift-invariant,\nas well as permutation and orientation equivariant. These filters can also be\nimplemented in a distributed fashion with a low computational complexity, as\nthey involve only (multiple rounds of) simplicial shifting between upper and\nlower adjacent simplices. Second, focusing on edge-flows, we study the\nfrequency responses of these filters and examine how we can use the\nHodge-decomposition to delineate gradient, curl and harmonic frequencies. We\ndiscuss how these frequencies correspond to the lower- and the upper-adjacent\ncouplings and the kernel of the Hodge Laplacian, respectively, and can be tuned\nindependently by our filter designs. Third, we study different procedures for\ndesigning simplicial convolutional filters and discuss their relative\nadvantages. Finally, we corroborate our simplicial filters in several\napplications: to extract different frequency components of a simplicial signal,\nto denoise edge flows, and to analyze financial markets and traffic networks.", "entities_include_in_text": [], "entities_from_reference": ["Plusieurs"]}{"title": ["The Low-Redshift Lyman Continuum Survey I: New, Diverse Local Lyman-Continuum Emitters"], "authors": ["[arxiv.Result.Author('Sophia R. Flury'), arxiv.Result.Author('Anne E. Jaskot'), arxiv.Result.Author('Harry C. Ferguson'), arxiv.Result.Author('Gabor Worseck'), arxiv.Result.Author('Kirill Makan'), arxiv.Result.Author('John Chisholm'), arxiv.Result.Author('Alberto Saldana-Lopez'), arxiv.Result.Author('Daniel Schaerer'), arxiv.Result.Author('Stephan McCandless'), arxiv.Result.Author('Bingjie Wang'), arxiv.Result.Author('N. M. Ford'), arxiv.Result.Author('Timothy Heckman'), arxiv.Result.Author('Zhiyuan Ji'), arxiv.Result.Author('Mauro Giavalisco'), arxiv.Result.Author('Ricardo Amorin'), arxiv.Result.Author('Hakim Atek'), arxiv.Result.Author('Jeremy Blaizot'), arxiv.Result.Author('Sanchayeeta Borthakur'), arxiv.Result.Author('Cody Carr'), arxiv.Result.Author('Marco Castellano'), arxiv.Result.Author('Stefano Cristiani'), arxiv.Result.Author('Stephane de Barros'), arxiv.Result.Author('Mark Dickinson'), arxiv.Result.Author('Steven L. Finkelstein'), arxiv.Result.Author('Brian Fleming'), arxiv.Result.Author('Fabio Fontanot'), arxiv.Result.Author('Thibault Garel'), arxiv.Result.Author('Andrea Grazian'), arxiv.Result.Author('Matthew Hayes'), arxiv.Result.Author('Alaina Henry'), arxiv.Result.Author('Valentin Mauerhofer'), arxiv.Result.Author('Genoveva Micheva'), arxiv.Result.Author('M. S. Oey'), arxiv.Result.Author('Goran Ostlin'), arxiv.Result.Author('Casey Papovich'), arxiv.Result.Author('Laura Pentericci'), arxiv.Result.Author('Swara Ravindranath'), arxiv.Result.Author('Joakim Rosdahl'), arxiv.Result.Author('Michael Rutkowski'), arxiv.Result.Author('Paola Santini'), arxiv.Result.Author('Claudia Scarlata'), arxiv.Result.Author('Harry Teplitz'), arxiv.Result.Author('Trinh Thuan'), arxiv.Result.Author('Maxime Trebitsch'), arxiv.Result.Author('Eros Vanzella'), arxiv.Result.Author('Anne Verhamme'), arxiv.Result.Author('Xinfeng Xu')]"], "link": ["http://arxiv.org/pdf/2201.11716v1"], "summary": "The origins of Lyman continuum (LyC) photons responsible for the reionization\nof the universe are as of yet unknown and highly contested. Detecting LyC\nphotons from the epoch of reionization is not possible due to absorption by the\nintergalactic medium, which has prompted the development of several indirect\ndiagnostics to infer the rate at which galaxies contribute LyC photons to\nreionize the universe by studying lower-redshift analogs. We present the\nLow-redshift Lyman Continuum Survey (LzLCS) comprising measurements made with\nHST/COS for a z=0.2-0.4 sample of 66 galaxies. After careful processing of the\nFUV spectra, we obtain a total of 35 Lyman continuum emitters (LCEs) detected\nwith 97.725% confidence, nearly tripling the number of known local LCEs. We\nestimate escape fractions from the detected LyC flux and upper limits on the\nundetected LyC flux, finding a range of LyC escape fractions up to 50%. Of the\n35 LzLCS LCEs, 12 have LyC escape fractions greater than 5%, more than doubling\nthe number of known local LCEs with cosmologically relevant LyC escape.", "entities_include_in_text": ["e.g., Fan et al. 2006; Yang et al. 2020", "e.g.,\nPaoletti et al. 2020; Planck Collaboration et al.\n2020", "e.g., Mason et al.\n2018; Pahl et al. 2020", "Naidu\net al. 2020", "e.g., Finkelstein\net al. 2019), owing largely to steeper lumi-\nnosity functions than those adopted by Naidu\net al. (2020", "e.g., Trebitsch et al. 2017", "e.g., Finkelstein et al. 2019;\nDayal et al. 2020", "Stei-\ndel et al. 2001", "e.g., Bouwens et al.\n2016; Schaerer et al. 2016", "e.g., Steidel et al. 2018", "Finkelstein et al. 2015, 2019", "Robertson et al. 2015; Naidu et al. 2020", "e.g.,\nVanzella et al. 2012; Mostardi et al. 2015; Siana\net al. 2015", "e.g., Becker et al. 2021", "e.g., Inoue et al. 2014; Steidel et al. 2018", "cf. Chisholm et al. 2017 regarding\nLeitherer et al. 2016", "cf.\nIzotov et al. 2016b regarding FUSE\nobservations by Leitet et al. 2013", "Steidel et al. 2018;\nesc\nVanzella et al. 2018", "Mostardi\nf LyC\net al. 2015; de Barros et al. 2016; Vanzella et al.\n2016; Bian et al. 2017; Micheva et al. 2017;\nFletcher et al. 2019; Rivera-Thorsen et al. 2019;\nJi et al. 2020", "e.g., Sharma et al. 2017; Naidu et al.\nf LyC\nesc\n2020", "e.g., Zackris-\nson et al. 2013, 2017", "SDSS, York\net al. 2000", "GALEX, Martin et al. 2003", "Blanton et al. 2017", "Baldwin et al. 1981", "Green et al. 2012", "cf. Izotov\net al. 2021", "Worseck\n\net al. 2016; Makan et al. 2020", "Izotov\net al. 2021", "Luridiana et al. 2015", "see discussion in Curti et al. 2017", "e.g., Gordon\net al. 2003", "Izotov et al. 2017", "e.g., Guaita\net al. 2015; Wisotzki et al. 2016; Leclercq et al.\n2017; Rasekh et al. 2021", "e.g., Hayes et al. 2013", "Foreman-Mackey et al. 2013", "Fer-\nland et al. 2013", "e.g., Wang et al. 2019", "Leja et al. 2017; Johnson et al. 2019", "e.g., Verhamme et al.\n2015", "e.g., Carr\net al. 2021", "e.g., Giavalisco et al. 1996", "Leitherer et al. 1999, 2014", "Bouwens et al. 2015", "cf. Wang et al. 2019", "Flury et al.\nsubmitted,\nWang et al. 2021", "AstropyCollaboration\net al. 2013, 2018", "Ferland et al. 2013", "Foreman-Mackey et al. 2013", "Worseck et al. 2016; Makan et al. 2020", "Hunter 2007", "van der\nWaltetal.2011", "Lejaetal.2017;\nJohnson et al. 2019", "Luridiana et al.\n2015", "P.Virtanen2020", "Leitherer et al. 1999, 2010, 2014"], "entities_from_reference": ["Plusieurs"]}