{
    "title": [
        "SafePicking: Learning Safe Object Extraction via Object-Level Mapping"
    ],
    "authors": [
        "[arxiv.Result.Author('Kentaro Wada'), arxiv.Result.Author('Stephen James'), arxiv.Result.Author('Andrew J. Davison')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05832v1"
    ],
    "summary": "Robots need object-level scene understanding to manipulate objects while\nreasoning about contact, support, and occlusion among objects. Given a pile of\nobjects, object recognition and reconstruction can identify the boundary of\nobject instances, giving important cues as to how the objects form and support\nthe pile. In this work, we present a system, SafePicking, that integrates\nobject-level mapping and learning-based motion planning to generate a motion\nthat safely extracts occluded target objects from a pile. Planning is done by\nlearning a deep Q-network that receives observations of predicted poses and a\ndepth-based heightmap to output a motion trajectory, trained to maximize a\nsafety metric reward. Our results show that the observation fusion of poses and\ndepth-sensing gives both better performance and robustness to the model. We\nevaluate our methods using the YCB objects in both simulation and the real\nworld, achieving safe object extraction from piles.",
    "entities_include_in_text": [],
    "entities_from_reference": [
        "Bowen Baker",
        "Ingmar Kanitscheider",
        "Todor Markov",
        "Yi Wu",
        "Glenn Powell",
        "Bob McGrew",
        "Igor Mordatch",
        "Brockman",
        "Vicki Cheung",
        "Ludwig Pettersson",
        "Jonas Schneider",
        "John Schulman",
        "Jie Tang",
        "Wojciech Zaremba",
        "Openai",
        "P Srinivasa S.",
        "Model",
        "Advanced Robotics",
        "Rui Chen",
        "Zhiqiang Sui",
        "Zhefan Ye",
        "Yanqi Liu",
        "Odest Chadwicke Jenkins",
        "Grip",
        "Sachin Chitta",
        "Ioan Sucan",
        "Steve Cousins",
        "Moveit",
        "Erwin Coumans",
        "Yunfei Bai",
        "Coline Manon Devin",
        "Eric Jang",
        "Sergey Levine",
        "Grasp2Vec",
        "Robot Learning",
        "Rosen Diankov",
        "James Kuffner",
        "Robotics Institute",
        "Fang",
        "Stefan Hinterstoisser",
        "Silvio Savarese",
        "Russ Tedrake",
        "Mask",
        "Armin Hornung",
        "Kai M. Wurm",
        "Maren Bennewitz",
        "Cyrill Stachniss",
        "Wolfram Burgard",
        "Autonomous Robots",
        "Stephen James",
        "Kentaro Wada",
        "Tristan Laidlow",
        "Andrew J Davison",
        "Dmitry Kalashnikov",
        "Alex Irpan",
        "Peter Pastor",
        "Julian Ibarz",
        "Alexander Herzog",
        "Deirdre Quillen",
        "Ethan Holly",
        "Mrinal Kalakrishnan",
        "Vincent Vanhoucke",
        "Robot",
        "Leonid Keselman",
        "John Iselin Woodfill",
        "Anders",
        "Achintya Bhowmik",
        "Pattern Recognition Workshops",
        "Jimmy Ba",
        "Adam",
        "Andrey Kurenkov",
        "James J Kuffner",
        "Steven M LaValle",
        "Joseph Taglic",
        "Rohun Kulkarni",
        "Marcus Dominguez-Kuhne",
        "Animesh Garg",
        "Roberto Mart",
        "Chelsea Finn",
        "Trevor Darrell",
        "Pieter Abbeel",
        "Machine Learning Research",
        "Alex Krizhevsky",
        "Robotics Research",
        "Lucas Manuelli",
        "Wei Gao",
        "Peter Florence",
        "Volodymyr Mnih",
        "Koray Kavukcuoglu",
        "David Silver",
        "Andrei A Rusu",
        "Joel Veness",
        "Marc G Bellemare",
        "Alex Graves",
        "Martin Riedmiller",
        "Andreas K Fidjeland",
        "Georg Ostrovski",
        "Nature",
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga",
        "Lerrel Pinto",
        "Abhinav Gupta",
        "Quigley",
        "Ken Conley",
        "Brian Gerkey",
        "Josh Faust",
        "Tully Foote",
        "Jeremy Leibs",
        "Rob Wheeler",
        "Andrew Y Ng",
        "Ros",
        "Anton Milan",
        "Christian Lenz",
        "Aura Munoz",
        "Arul Selvam Periyasamy",
        "Michael Schreiber",
        "Sebastian Sch",
        "Sven Behnke",
        "Nimbro",
        "Stefan Stevsi",
        "Sammy Christen",
        "Otmar Hilliges",
        "Haonan Chang",
        "Jonathan Tremblay",
        "Balakumar Sundaralingam",
        "Yu Xiang",
        "Dieter Fox",
        "Stan Birchfield",
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan N Gomez",
        "Kaiser",
        "Illia Polosukhin",
        "Edgar Sucar",
        "Daniel Lenton",
        "Andrew J. Davison",
        "Pattern Recognition",
        "Xiang",
        "Narayanan",
        "Fox",
        "Kevin Zakka",
        "Andy Zeng",
        "Johnny Lee",
        "Shuran Song",
        "Alberto Rodriguez",
        "Thomas Funkhouser",
        "Tossingbot",
        "Stefan Welker",
        "Elliott Donlon",
        "Francois R Hogan",
        "Maria Bauza",
        "Daolin Ma",
        "Orion Taylor",
        "Melody Liu",
        "Eudald Romo",
        "Robotic",
        "Daniel Suo",
        "Ed Walker",
        "Jianxiong Xiao"
    ]
}{
    "title": [
        "Meta-learning with GANs for anomaly detection, with deployment in high-speed rail inspection system"
    ],
    "authors": [
        "[arxiv.Result.Author('Haoyang Cao'), arxiv.Result.Author('Xin Guo'), arxiv.Result.Author('Guan Wang')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05795v1"
    ],
    "summary": "Anomaly detection has been an active research area with a wide range of\npotential applications. Key challenges for anomaly detection in the AI era with\nbig data include lack of prior knowledge of potential anomaly types, highly\ncomplex and noisy background in input data, scarce abnormal samples, and\nimbalanced training dataset. In this work, we propose a meta-learning framework\nfor anomaly detection to deal with these issues. Within this framework, we\nincorporate the idea of generative adversarial networks (GANs) with appropriate\nchoices of loss functions including structural similarity index measure (SSIM).\nExperiments with limited labeled data for high-speed rail inspection\ndemonstrate that our meta-learning framework is sharp and robust in identifying\nanomalies. Our framework has been deployed in five high-speed railways of China\nsince 2021: it has reduced more than 99.7% workload and saved 96.7% inspection\ntime.",
    "entities_include_in_text": [],
    "entities_from_reference": [
        "Martin Arjovsky",
        "Soumith Chintala",
        "Bottou",
        "Machine Learning",
        "Haoyang Cao",
        "Xin Guo",
        "Cambridge University Press",
        "Arindam Banerjee",
        "Vipin Kumar",
        "Anomaly",
        "Heng Liu",
        "Fei Gao",
        "Zhuo Chen",
        "Dan Chianucci",
        "Andreas Savakis",
        "Emily L Denton",
        "Arthur Szlam",
        "Rob Fergus",
        "Deep",
        "Zhiguo Jiang",
        "Fengying Xie",
        "Ping Yang",
        "Jun Shi",
        "Automatic",
        "Chelsea Finn",
        "Aravind Rajeswaran",
        "Sham Kakade",
        "Sergey Levine",
        "Online",
        "Kelvin Xu",
        "Viveka Kulharia",
        "Amitabha Mukerjee",
        "Vinay Namboodiri",
        "Mohit Bansal",
        "Contextual RNN-GANs",
        "Vishal M Patel",
        "Rama Chellappa",
        "Image Processing",
        "Gibert",
        "Robust",
        "Ian J. Goodfellow",
        "Jean Pouget-Abadie",
        "Mehdi Mirza",
        "Bing Xu",
        "David Warde-Farley",
        "Sherjil Ozair",
        "Aaron Courville",
        "Yoshua Bengio",
        "Johnny Hong",
        "Tianyi Lin",
        "Nan Yang",
        "Relaxed Wasserstein",
        "Geoffrey Hinton",
        "Li Deng",
        "Dong Yu",
        "George E Dahl",
        "Mohamed",
        "Navdeep Jaitly",
        "Andrew Senior",
        "Vincent Vanhoucke",
        "Patrick Nguyen",
        "Tara N Sainath",
        "Geoffrey E Hinton",
        "Ruslan R Salakhutdinov",
        "Timothy Hospedales",
        "Antreas Antoniou",
        "Paul Micaelli",
        "Amos Storkey",
        "Gaoqiang Kang",
        "Shibin Gao",
        "Dongkai Zhang",
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Pereira",
        "Jia-Bin Huang",
        "Zhe Hu",
        "Narendra Ahuja",
        "Pattern Recognition",
        "Yann LeCun",
        "Patrick Haffner",
        "Object",
        "Chuan Li",
        "Michael Wand",
        "Springer",
        "Frank Yu",
        "Mahesh Kumar Krishna Reddy",
        "Yang Wang",
        "Pauline Luc",
        "Camille Couprie",
        "Jakob Verbeek",
        "Dominik Mautz",
        "Christian B",
        "Data Mining Workshops",
        "Alireza Makhzani",
        "Jonathon Shlens",
        "Ian Goodfellow",
        "Sebastian Nowozin",
        "Botond Cseke",
        "Ryota Tomioka",
        "Pathak",
        "Philipp Krahenbuhl",
        "Jeff Donahue",
        "Trevor Darrell",
        "Alexei A Efros",
        "Xuebin Qin",
        "Zichen Zhang",
        "Chenyang Huang",
        "Chao Gao",
        "Masood Dehghan",
        "Martin Jagersand",
        "Alec Radford",
        "Luke Metz",
        "Scott Reed",
        "Zeynep Akata",
        "Xinchen Yan",
        "Lajanugen Logeswaran",
        "Bernt Schiele",
        "Honglak Lee",
        "Philipp Fischer",
        "Thomas Brox",
        "Jakub Sygnowski",
        "Oriol Vinyals",
        "Razvan Pascanu",
        "Simon Osindero",
        "Raia Hadsell",
        "Adam Santoro",
        "Sergey Bartunov",
        "Matthew Botvinick",
        "Daan Wierstra",
        "Timothy Lillicrap",
        "Thomas Schlegl",
        "Philipp Seeb",
        "Sebastian M Waldstein",
        "Georg Langs",
        "Ursula Schmidt-Erfurth",
        "Fast",
        "Medical",
        "Nitish Srivastava",
        "Ruslan Salakhutdinov",
        "Dropout",
        "Machine Learning Research",
        "Michael Steinbach",
        "Carl Vondrick",
        "Hamed Pirsiavash",
        "Antonio Torralba",
        "Jacob Walker",
        "Carl Doersch",
        "Abhinav Gupta",
        "Martial Hebert",
        "Wang",
        "Alan C Bovik",
        "Hamid R Sheikh",
        "Eero P Simoncelli",
        "Image",
        "Yang",
        "Chao Ma",
        "Vitjan Zavrtanik",
        "Matej Kristan",
        "Danijel Skocaj",
        "Zhang",
        "Fei Ye",
        "Bingnan Wang",
        "Thomas G. Habetler"
    ]
}{
    "title": [
        "PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?"
    ],
    "authors": [
        "[arxiv.Result.Author('Arnaud Huaulm\u00e9'), arxiv.Result.Author('Kanako Harada'), arxiv.Result.Author('Quang-Minh Nguyen'), arxiv.Result.Author('Bogyu Park'), arxiv.Result.Author('Seungbum Hong'), arxiv.Result.Author('Min-Kook Choi'), arxiv.Result.Author('Michael Peven'), arxiv.Result.Author('Yunshuang Li'), arxiv.Result.Author('Yonghao Long'), arxiv.Result.Author('Qi Dou'), arxiv.Result.Author('Satyadwyoom Kumar'), arxiv.Result.Author('Seenivasan Lalithkumar'), arxiv.Result.Author('Ren Hongliang'), arxiv.Result.Author('Hiroki Matsuzaki'), arxiv.Result.Author('Yuto Ishikawa'), arxiv.Result.Author('Yuriko Harai'), arxiv.Result.Author('Satoshi Kondo'), arxiv.Result.Author('Mamoru Mitsuishi'), arxiv.Result.Author('Pierre Jannin')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05821v1"
    ],
    "summary": "This paper presents the design and results of the \"PEg TRAnsfert Workflow\nrecognition\" (PETRAW) challenge whose objective was to develop surgical\nworkflow recognition methods based on one or several modalities, among video,\nkinematic, and segmentation data, in order to study their added value. The\nPETRAW challenge provided a data set of 150 peg transfer sequences performed on\na virtual simulator. This data set was composed of videos, kinematics, semantic\nsegmentation, and workflow annotations which described the sequences at three\ndifferent granularity levels: phase, step, and activity. Five tasks were\nproposed to the participants: three of them were related to the recognition of\nall granularities with one of the available modalities, while the others\naddressed the recognition with a combination of modalities. Average\napplication-dependent balanced accuracy (AD-Accuracy) was used as evaluation\nmetric to take unbalanced classes into account and because it is more\nclinically relevant than a frame-by-frame score. Seven teams participated in at\nleast one task and four of them in all tasks. Best results are obtained with\nthe use of the video and the kinematics data with an AD-Accuracy between 93%\nand 90% for the four teams who participated in all tasks. The improvement\nbetween video/kinematic-based methods and the uni-modality ones was significant\nfor all of the teams. However, the difference in testing execution time between\nthe video/kinematic-based and the kinematic-based methods has to be taken into\nconsideration. Is it relevant to spend 20 to 200 times more computing time for\nless than 3% of improvement? The PETRAW data set is publicly available at\nwww.synapse.org/PETRAW to encourage further research in surgical workflow\nrecognition.",
    "entities_include_in_text": [],
    "entities_from_reference": [
        "Lecture Notes",
        "Verlag",
        "Pierre Jannin",
        "D Bouget",
        "G Forestier",
        "C Penet",
        "N Zemiti",
        "P Poignet",
        "P Jannin",
        "Kanako Harada",
        "Mamoru Mitsuishi",
        "Germain Forestier",
        "Laurent Riffaud",
        "Francois Petitjean",
        "Pierre Louis Henaux",
        "J Kim",
        "Lee",
        "Warren S. Sandberg",
        "Bethany Daily",
        "Marie Egan",
        "James E. Stahl",
        "Julian M. Goldman",
        "Richard",
        "Wiklund",
        "David Rattner",
        "Anesthesiology",
        "Beenish Bhatia",
        "Tim Oates",
        "Peter Hu",
        "Gwenole Quellec",
        "Mathieu Lamard",
        "Guy Cazuguel",
        "Arnaud Huaulme",
        "Fabian Reche",
        "Jean-Luc Faucheron",
        "Alexandre Moreau-Gaudry",
        "Sandrine Voros",
        "Offline",
        "F Despinoy",
        "K Harada",
        "M Mitsuishi",
        "Automatic",
        "Nicolas Padoy",
        "Tobias Blum",
        "Seyed Ahmad",
        "Seyed Ahmad Ahmadi",
        "Hubertus Feussner",
        "Marie Odile",
        "Berger",
        "Nassir Navab",
        "Medical",
        "Andru P. Twinanda",
        "Sherif Shehata",
        "Didier Mutter",
        "Jacques Marescaux",
        "Michel De Mathelin",
        "P P Jonker",
        "D Vieira",
        "B Lo",
        "Yang",
        "Medical Image Computing",
        "David Bouget",
        "Sarikaya",
        "Gesture Recognition",
        "Optical Flow",
        "Isabel Funke",
        "Sebastian Bodenstedt",
        "Florian Oehme",
        "Felix",
        "Jurgen Weitz",
        "Stefanie Speidel",
        "Robert DiPietro",
        "Gregory D. Hager",
        "Automated Surgical Activity",
        "One Labeled Sequence",
        "Duygu Sarikaya",
        "Kevin Le Mut",
        "Fabien Despinoy",
        "Yonghao Long",
        "Qi Dou",
        "Wenjun Lin",
        "Satoshi Kondo",
        "Laura Bravo-Sanchez",
        "Pablo Arbelaez",
        "Wolfgang Reiter",
        "Manoru Mitsuishi",
        "Bo Lu",
        "Mathias Unberath",
        "Heng",
        "Kinematics Embeddings",
        "Yidan Qin",
        "Max Allan",
        "Yisong Yue",
        "Joel W. Burdick",
        "Mahdi Azizian",
        "Robust Surgical",
        "Heredia Perez",
        "Haptic Assistance",
        "Robotic Surgical Simulation",
        "Annual Congress",
        "X Morandi",
        "Lena Maier-Hein",
        "Matthias Eisenmann",
        "Annika Reinke",
        "Sinan Onogur",
        "Marko Stankovic",
        "Patrick Scholz",
        "Hrvoje Bogunovic",
        "Andrew P Bradley",
        "Aaron Carass",
        "Carolin Feldmann",
        "Alejandro F Frangi",
        "Peter M Full",
        "Bram",
        "Ginneken",
        "Allan Hanbury",
        "Katrin Honauer",
        "Michal Kozubek",
        "Bennett A Landman",
        "Keno Marz",
        "Oskar Maier",
        "Klaus Maier-Hein",
        "Bjoern H Menze",
        "Henning Muller",
        "Peter F Neher",
        "Wiro Niessen",
        "Nasir Rajpoot",
        "Gregory C Sharp",
        "Korsuk Sirinukunwattana",
        "Christian Stock",
        "Danail Stoyanov",
        "Abdel Aziz Taha",
        "Fons",
        "Wang",
        "Guoyan Zheng",
        "Annette",
        "Bennett A. Landman",
        "Laura Aguilera Saiz",
        "Jorge Cardoso",
        "Scientific Reports",
        "Liang Chieh Chen",
        "Yukun Zhu",
        "George Papandreou",
        "Florian Schroff",
        "Hartwig Adam",
        "Kensho Hara",
        "Hirokatsu Kataoka",
        "Yutaka Satoh",
        "Pattern Recognition",
        "Mike Schuster",
        "Kuldip K Paliwal",
        "Haoqi Fan",
        "Jitendra Malik",
        "Xinlei Chen",
        "Simple Siamese",
        "Jingru Tan",
        "Xin Lu",
        "Gang Zhang",
        "Quanquan Li",
        "Equalization Loss",
        "Andrew Zhai",
        "Hao Yu Wu",
        "Deep Metric Learning",
        "Robert Dipietro",
        "Colin Lea",
        "Anand Malpani",
        "Narges Ahmidi",
        "Swaroop Vedula",
        "Gyusung I. Lee",
        "Mija R Lee",
        "Gregory D Hager",
        "Xiaojie Gao",
        "Jin",
        "Pheng Ann Heng",
        "Hybrid Embedding",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun",
        "Deep",
        "Jurgen Schmidhuber",
        "Neural Computation",
        "Depthwise Separable Convolutions",
        "Liyuan Liu",
        "Haoming Jiang",
        "Weizhu Chen",
        "Xiaodong Liu",
        "Jianfeng Gao",
        "Jiawei Han",
        "Guolin Ke",
        "Qi Meng",
        "Thomas Finley",
        "Taifeng Wang",
        "Wei Chen",
        "Weidong Ma",
        "Qiwei Ye",
        "Mark Everingham",
        "Luc Van Gool",
        "Christopher",
        "Williams",
        "John Winn",
        "Andrew Zisserman",
        "Quoc V. Le",
        "Model",
        "Machine Learning",
        "Shotaro Sano",
        "Toshihiko Yanase",
        "Takeru Ohta",
        "Masanori Koyama",
        "Optuna",
        "Data Mining",
        "Philipp Fischer",
        "Thomas Brox",
        "Shijie Li",
        "Yazan Abu Farha",
        "Yun Liu",
        "Juergen Gall",
        "Network",
        "Action Segmentation",
        "Karen Simonyan",
        "Deep Convolutional Networks",
        "Towards",
        "David Patterson",
        "Joseph Gonzalez",
        "Quoc Le",
        "Chen Liang",
        "Daniel Rothchild",
        "David So",
        "Maud Texier",
        "Jeff Dean",
        "Large Neural Network Training",
        "Emma Strubell",
        "Ananya Ganesh",
        "Andrew Mccallum",
        "Energy",
        "Policy Considerations",
        "Deep Learning",
        "Huaulme",
        "Harada",
        "Jannin",
        "Nguyen",
        "Park",
        "Peven",
        "S Lalithkumar",
        "Hongliang",
        "Ishikawa",
        "Kondo",
        "Phase Transfer Left",
        "Idle Test",
        "Step",
        "Step Block",
        "Verb Left Catch Drop Extract Hold Insert Touch Idle Test",
        "Verb Left",
        "Catch Drop Extract Hold Insert Touch Idle Test",
        "Verb Right",
        "Eight",
        "Hutom Table",
        "Hutom"
    ]
}{
    "title": [
        "End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking"
    ],
    "authors": [
        "[arxiv.Result.Author('Arpit Bansal'), arxiv.Result.Author('Avi Schwarzschild'), arxiv.Result.Author('Eitan Borgnia'), arxiv.Result.Author('Zeyad Emam'), arxiv.Result.Author('Furong Huang'), arxiv.Result.Author('Micah Goldblum'), arxiv.Result.Author('Tom Goldstein')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05826v1"
    ],
    "summary": "Machine learning systems perform well on pattern matching tasks, but their\nability to perform algorithmic or logical reasoning is not well understood. One\nimportant reasoning capability is logical extrapolation, in which models\ntrained only on small/simple reasoning problems can synthesize complex\nalgorithms that scale up to large/complex problems at test time. Logical\nextrapolation can be achieved through recurrent systems, which can be iterated\nmany times to solve difficult reasoning problems. We observe that this approach\nfails to scale to highly complex problems because behavior degenerates when\nmany iterations are applied -- an issue we refer to as \"overthinking.\" We\npropose a recall architecture that keeps an explicit copy of the problem\ninstance in memory so that it cannot be forgotten. We also employ a progressive\ntraining routine that prevents the model from learning behaviors that are\nspecific to iteration number and instead pushes it to learn behaviors that can\nbe repeated indefinitely. These innovations prevent the overthinking problem,\nand enable recurrent systems to solve extremely hard logical extrapolation\ntasks, some requiring over 100K convolutional layers, without overthinking.",
    "entities_include_in_text": [
        "Selsam\net al., 2018",
        "Selsam et al.,\n2018",
        "Schmidhuber, 2012",
        "Graves, 2016",
        "Dehghani et al., 2018; Press et al., 2021",
        "Ciccone et al., 2018",
        "He et al., 2016",
        "Srivastava et al.,\n2015; He et al., 2016; Huang et al., 2017",
        "Jaeger, 2002",
        "Deng\net al., 2009)",
        "He et al., 2016"
    ],
    "entities_from_reference": [
        "Ciccone",
        "Gallieri",
        "Masci",
        "Osendorfer",
        "Gomez",
        "Dehghani",
        "Gouws",
        "Vinyals",
        "Uszkoreit",
        "Kaiser",
        "Deng",
        "Socher",
        "Li",
        "Eyzaguirre",
        "Soto",
        "Pattern Recognition",
        "Liepins",
        "Ladner",
        "Fischer",
        "Parallel",
        "Nuamah",
        "Palm",
        "Winther",
        "Systems",
        "Smith",
        "Lewis",
        "J.",
        "Schwarzschild",
        "Gupta",
        "Emam",
        "Huang",
        "Goldstein",
        "Vishkin",
        "Selsam",
        "Lamm",
        "Bunz",
        "Liang",
        "Moura",
        "Dill",
        "Srivastava",
        "Wayne",
        "Danihelka",
        "Zhang",
        "Ren",
        "Deep",
        "Liu",
        "Van Der Maaten",
        "Weinberger",
        "Jaeger",
        "Kingma",
        "J. Adam",
        "Algorithm Synthesis",
        "Appendix",
        "Note",
        "Dataset Width",
        "Bottom Accuracy",
        "Adam",
        "Task Optimizer Learning Rate Decay Schedule Decay Factor",
        "Clip Bound",
        "Chess Puzzles Adam Adam Adam",
        "Strings Tested",
        "Peak Acc",
        "Model Peak Iter",
        "Figure",
        "Results Tables",
        "Valid Acc",
        "Model Train Acc",
        "Zeros",
        "Chess",
        "Hard",
        "Easy One",
        "Model Clean Noise Zeros Swapped DT DT"
    ]
}{
    "title": [
        "A Newton-type algorithm for federated learning based on incremental Hessian eigenvector sharing"
    ],
    "authors": [
        "[arxiv.Result.Author('Nicol\u00f2 Dal Fabbro'), arxiv.Result.Author('Subhrakanti Dey'), arxiv.Result.Author('Michele Rossi'), arxiv.Result.Author('Luca Schenato')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05800v1"
    ],
    "summary": "There is a growing interest in the decentralized optimization framework that\ngoes under the name of Federated Learning (FL). In particular, much attention\nis being turned to FL scenarios where the network is strongly heterogeneous in\nterms of communication resources (e.g., bandwidth) and data distribution. In\nthese cases, communication between local machines (agents) and the central\nserver (Master) is a main consideration. In this work, we present an original\ncommunication-constrained Newton-type (NT) algorithm designed to accelerate FL\nin such heterogeneous scenarios. The algorithm is by design robust to non\ni.i.d. data distributions, handles heterogeneity of agents' communication\nresources (CRs), only requires sporadic Hessian computations, and achieves\nsuper-linear convergence. This is possible thanks to an incremental strategy,\nbased on a singular value decomposition (SVD) of the local Hessian matrices,\nwhich exploits (possibly) outdated second-order information. The proposed\nsolution is thoroughly validated on real datasets by assessing (i) the number\nof communication rounds required for convergence, (ii) the overall amount of\ndata transmitted and (iii) the number of local Hessian computations required.\nFor all these metrics, the proposed approach shows superior performance against\nstate-of-the art techniques like GIANT and FedNL.",
    "entities_include_in_text": [
        "Shi et al., 2020",
        "Pham et al., 2020",
        "Rieke et al., 2020; Huang et al., 2020",
        "Hard et al.,\n2018",
        "McMahan\net al., 2017",
        "Kairouz et al., 2021; Zhu et al.,\n2021; Smith et al., 2017; Zhao et al., 2018",
        "Shi et al., 2020; T. Dinh et al., 2022; Nguyen et al., 2021; Chen et al., 2020",
        "Liu et al., 2020",
        "Gupta et al., 2021; Safaryan et al., 2021",
        "Karimireddy et al., 2020",
        "Wang et al., 2018",
        "Gupta et al., 2021",
        "Shamir et al., 2014",
        "Reddi et al.,\n2016",
        "Zhang and Lin, 2015",
        "Crane and Roosta, 2019). These algo-\nrithms, however, were all designed for i.i.d. data distributions. The work in T. Dinh et al.\n(2022",
        "Safaryan et al., 2021), proposed algorithms based on matrix compression that\nexploit theory developed in Islamov et al. (2021",
        "Qian et al., 2021), proposing vari-\nants of FedNL exploiting change of basis in the space of matrices to improve the quality\nof the compressed Hessian. However, these approaches do not consider heterogeneity in\nthe CRs, and require the computation of the local Hessian at each iteration. Another NT\napproach has been recently proposed in Liu et al. (2021",
        "Liu and Nocedal, 1989",
        "Safaryan et al., 2021",
        "Lyapunov, 1992",
        "see Czornik\net al., 2012",
        "using the notation of Erdogdu and Montanari (2015)",
        "Bertin-Mahieux et al., 2011",
        "Fernandes et al., 2015",
        "Xiao et al., 2017",
        "Cohen et al., 2017",
        "Chang and Lin, 2011",
        "Bertin-Mahieux et al., 2011",
        "see Kairouz et al. (2021)",
        "Fernandes et al., 2015",
        "Xiao et al., 2017",
        "Cohen et al., 2017",
        "Sheikh et al., 2020",
        "Chang and Lin, 2011",
        "Pase et al., 2021; Wadu et al., 2020; Chen et al., 2020",
        "in Pase et al. (2021",
        "AGD, with the same implementation of Wang et al. (2018)",
        "Wang et al., 2018",
        "T. Dinh et al., 2022",
        "Wang\net al., 2018",
        "see Safaryan et al., 2021",
        "ISMIR 2011"
    ],
    "entities_from_reference": [
        "Mohammad",
        "Mohammadi Amiri",
        "Deniz G",
        "Thierry Bertin-Mahieux",
        "Daniel",
        "Ellis",
        "Brian Whitman",
        "Paul Lamere",
        "Music Information Retrieval",
        "Stephen Boyd",
        "Lieven Vandenberghe",
        "Cambridge",
        "Software",
        "Mingzhe Chen",
        "Zhaohui Yang",
        "Walid Saad",
        "Changchuan Yin",
        "H Vincent Poor",
        "Shuguang Cui",
        "Tianyi Chen",
        "Georgios Giannakis",
        "Tao Sun",
        "Wotao Yin",
        "Gregory Cohen",
        "Saeed Afshar",
        "Jonathan Tapson",
        "Andr",
        "Emnist",
        "Rixon Crane",
        "Fred Roosta",
        "Adam Czornik",
        "Aleksander Nawrat",
        "Michal Niezabitowski",
        "Aneta Szyda",
        "Micha",
        "Derezi",
        "Michael W. Mahoney",
        "Red Hook",
        "Casey Graff",
        "Murat A Erdogdu",
        "Andrea Montanari",
        "Kelwin Fernandes",
        "Pedro Vinagre",
        "Paulo Cortez",
        "Springer",
        "Dey",
        "Rossi",
        "Avishek Ghosh",
        "Rajiv Khanna",
        "Kannan Ramchandran",
        "Michael W Mahoney",
        "Andrew Hard",
        "Kanishka Rao",
        "Rajiv Mathews",
        "Swaroop Ramaswamy",
        "Beaufays",
        "Sean Augenstein",
        "Hubert Eichner",
        "Chlo",
        "Kiddon",
        "Daniel Ramage",
        "Li Huang",
        "Yifeng Yin",
        "Zeng Fu",
        "Shifa Zhang",
        "Hao Deng",
        "Dianbo Liu",
        "Rustem Islamov",
        "Xun Qian",
        "Peter Richt",
        "Machine Learning",
        "Eunjeong Jeong",
        "Seungeun Oh",
        "Hyesung Kim",
        "Jihong Park",
        "Mehdi Bennis",
        "Peter Kairouz",
        "Brendan McMahan",
        "Sai Praneeth Karimireddy",
        "Satyen Kale",
        "Mehryar Mohri",
        "Sashank Reddi",
        "Sebastian Stich",
        "Ananda Theertha Suresh",
        "Tian Li",
        "Anit Kumar Sahu",
        "Ameet Talwalkar",
        "Manzil Zaheer",
        "Maziar Sanjabi",
        "Systems",
        "Dong C Liu",
        "Jorge Nocedal",
        "Yaqiong Liu",
        "Mugen Peng",
        "Guochu Shou",
        "Yudong Chen",
        "Siyu Chen",
        "Toward Edge",
        "Yuanshao Zhu",
        "Network Science",
        "Aleksandr Mikhailovich Lyapunov",
        "Eider Moore",
        "Hampson",
        "Dung Nguyen",
        "Amir R. Balef",
        "Canh T. Dinh",
        "Nguyen H. Tran",
        "Duy T. Ngo",
        "Tuan Anh Le",
        "Phuong L. Vo",
        "Francesco Pase",
        "Marco Giordani",
        "Michele Zorzi",
        "Fang Fang",
        "Vu Nguyen Ha",
        "Jalil Piran",
        "Mai Les",
        "Bao Le",
        "Zhiguo Ding",
        "Beyond",
        "Technology Integration",
        "Mher Safaryan",
        "Sashank J Reddi",
        "Jakub Konecn",
        "Barnab",
        "Alex Smola",
        "Nicola Rieke",
        "Jonny Hancox",
        "Wenqi Li",
        "Fausto Milletari",
        "Holger R Roth",
        "Shadi Albarqouni",
        "Spyridon Bakas",
        "Mathieu N Galtier",
        "Bennett A Landman",
        "Klaus Maier-Hein",
        "Ohad Shamir",
        "Nati Srebro",
        "Tong Zhang",
        "Ruksar Sheikh",
        "Mayank Patel",
        "Amit Sinhal",
        "Harish Sharma",
        "Mahesh Bundele",
        "Nilanjan Dey",
        "Marcin Paprzycki",
        "Springer Singapore",
        "Shi",
        "Kai Yang",
        "Tao Jiang",
        "Jun Zhang",
        "Khaled B. Letaief",
        "Virginia Smith",
        "Tuan Dung Nguyen",
        "Wei Bao",
        "Amir Rezaei Balef",
        "Bing B Zhou",
        "Albert Zomaya",
        "Madhusanka Manimel Wadu",
        "Sumudu Samarakoon",
        "Shusen Wang",
        "Farbod Roosta-Khorasani",
        "Peng Xu",
        "Han Xiao",
        "Kashif Rasul",
        "Hao Yu",
        "Parallel",
        "Yuchen Zhang",
        "Xiao Lin",
        "Disco",
        "Yue Zhao",
        "Meng Li",
        "Liangzhen Lai",
        "Naveen Suda",
        "Damon Civin",
        "Vikas Chandra",
        "Fed",
        "Hangyu Zhu",
        "Jinjin Xu",
        "Shiqing Liu",
        "Yaochu Jin"
    ]
}{
    "title": [
        "Investigating Power laws in Deep Representation Learning"
    ],
    "authors": [
        "[arxiv.Result.Author('Arna Ghosh'), arxiv.Result.Author('Arnab Kumar Mondal'), arxiv.Result.Author('Kumar Krishna Agrawal'), arxiv.Result.Author('Blake Richards')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05808v1"
    ],
    "summary": "Representation learning that leverages large-scale labelled datasets, is\ncentral to recent progress in machine learning. Access to task relevant labels\nat scale is often scarce or expensive, motivating the need to learn from\nunlabelled datasets with self-supervised learning (SSL). Such large unlabelled\ndatasets (with data augmentations) often provide a good coverage of the\nunderlying input distribution. However evaluating the representations learned\nby SSL algorithms still requires task-specific labelled samples in the training\npipeline. Additionally, the generalization of task-specific encoding is often\nsensitive to potential distribution shift. Inspired by recent advances in\ntheoretical machine learning and vision neuroscience, we observe that the\neigenspectrum of the empirical feature covariance matrix often follows a power\nlaw. For visual representations, we estimate the coefficient of the power law,\n$\\alpha$, across three key attributes which influence representation learning:\nlearning objective (supervised, SimCLR, Barlow Twins and BYOL), network\narchitecture (VGG, ResNet and Vision Transformer), and tasks (object and scene\nrecognition). We observe that under mild conditions, proximity of $\\alpha$ to\n1, is strongly correlated to the downstream generalization performance.\nFurthermore, $\\alpha \\approx 1$ is a strong indicator of robustness to label\nnoise during fine-tuning. Notably, $\\alpha$ is computable from the\nrepresentations without knowledge of any labels, thereby offering a framework\nto evaluate the quality of representations in unlabelled datasets.",
    "entities_include_in_text": [
        "Stringer et al., 2019",
        "Chen et al., 2020; Tian\net al., 2020; Zbontar et al., 2021",
        "Stringer et al., 2019",
        "Kong et al., 2022",
        "Nassar\net al., 2020",
        "Nguyen et al., 2020; Raghu et al., 2021",
        "Kornblith et al., 2019",
        "Martin et al., 2021",
        "Bartlett et al., 2020",
        "Lee et al., 2020",
        "Tripuraneni\net al., 2021",
        "Advani et al., 2020",
        "Arora et al., 2019",
        "He et al., 2016",
        "Raghu et al., 2021",
        "Dosovitskiy et al., 2020",
        "Raghu et al., 2021",
        "Chen et al.,\n2020; Grill et al., 2020",
        "Barlow et al., 1961",
        "Zbontar et al., 2021",
        "Bartlett et al., 2020",
        "Stringer et al., 2019",
        "Stringer et al., 2019",
        "Bartlett et al., 2020",
        "Advani et al., 2020",
        "Shah et al., 2018",
        "Bartlett et al., 2020",
        "Bartlett et al., 2020",
        "Bartlett et al., 2020",
        "Bartlett et al., 2020",
        "Deng et al., 2009",
        "Paszke et al., 2019",
        "Wightman,\n2019",
        "Chung et al., 2018",
        "He et al., 2016",
        "Dosovitskiy et al.,\n2020",
        "Deng et al., 2009",
        "He et al., 2016",
        "Chen et al., 2020",
        "Grill et al., 2020",
        "Zbontar et al., 2021",
        "Deng et al., 2009",
        "Nguyen et al., 2020",
        "Raghu\net al., 2021",
        "Raghu et al., 2021",
        "Shah\net al., 2018"
    ],
    "entities_from_reference": [
        "Saxe",
        "Networks",
        "Arora",
        "Li",
        "Wang",
        "Machine Learning",
        "Barlow",
        "Bartlett",
        "Tsigler",
        "Bubeck",
        "Chen",
        "Chung",
        "Lee",
        "Physical Review X",
        "Deng",
        "Socher",
        "Pattern Recognition",
        "Dosovitskiy",
        "Kolesnikov",
        "Zhai",
        "Dehghani",
        "Minderer",
        "Heigold",
        "Gelly",
        "Grill",
        "Strub",
        "Richemond",
        "Doersch",
        "Pires",
        "Guo",
        "Azar",
        "Zhang",
        "Ren",
        "Deep",
        "Kong",
        "Margalit",
        "Gardner",
        "J. L.",
        "Stringer",
        "Steinmetz",
        "Carandini",
        "Nature",
        "Ganguli",
        "Tripuraneni",
        "Adlam",
        "Pennington",
        "J. Covariate",
        "Wightman",
        "Zbontar",
        "Misra",
        "Deny",
        "Zeiler",
        "Springer",
        "Schoenholz",
        "Novak",
        "J. Finite",
        "Martin",
        "Peng",
        "Mahoney",
        "Nassar",
        "Sokol",
        "Chang",
        "Nguyen",
        "Raghu",
        "Oliva",
        "Paszke",
        "Gross",
        "Lerer",
        "Bradbury",
        "Chanan",
        "Killeen",
        "Lin",
        "Gimelshein",
        "Desmaison",
        "Kopf",
        "Yang",
        "Raison",
        "Tejani",
        "Steiner",
        "Fang",
        "Bai",
        "Fox",
        "Garnett",
        "Quattoni",
        "Shah",
        "Simonyan",
        "Zisserman",
        "Lemma",
        "X T",
        "Tconvergence",
        "Lemma A.1",
        "U T",
        "U U"
    ]
}{
    "title": [
        "Answer Set Planning: A Survey"
    ],
    "authors": [
        "[arxiv.Result.Author('Tran Cao Son'), arxiv.Result.Author('Enrico Pontelli'), arxiv.Result.Author('Marcello Balduccini'), arxiv.Result.Author('Torsten Schaub')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05793v1"
    ],
    "summary": "Answer Set Planning refers to the use of Answer Set Programming (ASP) to\ncompute plans, i.e., solutions to planning problems, that transform a given\nstate of the world to another state. The development of efficient and scalable\nanswer set solvers has provided a significant boost to the development of\nASP-based planning systems. This paper surveys the progress made during the\nlast two and a half decades in the area of answer set planning, from its\nfoundations to its use in challenging planning domains. The survey explores the\nadvantages and disadvantages of answer set planning. It also discusses typical\napplications of answer set planning and presents a set of challenges for future\nresearch.",
    "entities_include_in_text": [
        "Allen et al. 1991; Allen et al. 1990",
        "Son and Pontelli 2006",
        "Son et al. 2006",
        "Son\net al. 2006",
        "Balduccini and Gelfond 2003",
        "Son et al. 2016",
        "Son and Pontelli\n2006",
        "Jiang et al. 2019",
        "Eiter et al. 1997; Alviano et al. 2017; Alviano\net al. 2013",
        "Gebser et al. 2007; Gebser et al. 2019",
        "Lierler and Maratea\n2004",
        "Gelfond and Lifschitz 1998",
        "Lobo et al. 1997; Son and Baral 2001",
        "Giunchiglia et al.\n1997",
        "Simons et al. 2002",
        "Gelfond and Lifschitz 1998",
        "Korf 1985",
        "Fikes and Nilsson 1971",
        "Ghallab et al. 1998",
        "Thiebaux et al. 2003",
        "see, a survey by Hendler et al. (1990)",
        "a.k.a. partial order planning, see, e.g. a survey by Weld (1994)",
        "Sacerdoti 1974)",
        "Kambhampati et al. 1997",
        "Hoffmann and Nebel 2001",
        "Bonet and\nGeffner 2001",
        "Long et al. 2000;\nBacchus 2001; Gerevini et al. 2004",
        "Helmert\n2006; Richter and Helmert 2009; Helmert et al. 2011",
        "Kautz et al. 1996",
        "Chen et al. 2009; Dimopoulos et al. 1997; Rintanen et al. 2006; Robinson et al.\n2009; Rintanen 2012",
        "Kautz and\nWalser 1999; Do and Kambhampati 2003; Sideris and Dimopoulos 2010; Dovier et al. 2009). As\nwe have mentioned in the introduction, the success of SAT-base planning is likely the source of\ninspiration for the use of logic programming with answer sets semantics for planning. Indeed,\nthere are several similarities between a SAT-based encoding of a planning program proposed\nby Kautz and Selman (1992",
        "Missiaen et al. 1995). The\nunderlying algorithm of this system is a specialized version of the abductive reasoning procedure\nfor event calculus. An interesting feature of this system is that it allows for the user to specify the\nsearch strategy and heuristics at the domain level, allowing for domain dependent information to\nbe exploited in the search for a solution. Other proof procedures for event calculus planning can\nbe founded in the work by Endriss et al. (2004), Mueller (2006), and Shanahan (2000) and (1997",
        "see, e.g., the work by Baral et al. (2000), Eiter et al. (2000), Haslum and Jonsson (2000), or\nTurner (2002)",
        "see, e.g.,\nthe paper by Tran et al. (2013",
        "Bonet and Geffner 2000",
        "Smith and Weld\n1998",
        "Cimatti and Roveri 2000",
        "Hoffmann and Brafman 2006",
        "Cimatti et al. 2004",
        "Bryce et al. 2006",
        "Palacios and Geffner 2007;\nPalacios and Geffner 2009",
        "Albore et al. 2011",
        "Nguyen et al. 2011",
        "To et al. 2009",
        "Nguyen et al. 2012",
        "Grastien and Scala 2020",
        "Tran et al.\n2013",
        "Bryant 1992",
        "Bryce et al. 2006",
        "Tran et al. 2013",
        "Tran et al. 2013",
        "To et al. 2009",
        "Castellini et al. 2003; Palacios\nand Geffner 2005; Rintanen 1999",
        "Castellini et al. 2003",
        "From the work by Tu et al. (2007)",
        "Warren 1976; Peot and Smith 1992; Pryor\nand Collins 1996; Levesque 1996; Lobo et al. 1997; Son and Baral 2001; Turner 2002",
        "Cimatti and Roveri 2000",
        "Castellini et al. 2003",
        "Brafman and Hoffmann 2004",
        "Cimatti et al. 2004",
        "Palacios and Geffner 2007",
        "Bryce et al.\n2006), has been presented in the papers by Tu et al. (2007) and (2011",
        "Turner 2002",
        "Pryor and Collins 1996",
        "Peot and Smith 1992",
        "Golden et al. 1996",
        "Golden 1998",
        "Weld et al. 1998",
        "Bryce et al. 2006",
        "Blum and Furst 1997) to deal with sensing actions. The main difference between SGP and POND\nis that the former searches solutions within the planning graph, whereas the latter uses it as a\nmeans of computing the heuristic function.\n\nCoPlaS, developed by Lobo (1998), is a regression Prolog-based planner that uses a high-level\naction description language, similar to the language BK described in this section, to represent\nand reason about effects of actions, including sensing actions. Van Nieuwenborgh et al. (2007",
        "Aminof et al. 2020; Camacho et al. 2019; Camacho et al. 2018; Treszkai and Belle\n2020",
        "e.g., the work by Warren (1976)",
        "see, e.g., the book by\nBellman (1957)",
        "Son and Pontelli 2006",
        "e.g., Son\nand Pontelli (2006",
        "Brewka 2002",
        "Gerevini and Long 2005",
        "Sohrabi et al. 2009",
        "Coles and Coles 2011",
        "Das\net al. 2019). CHOPLAN, developed by Bidoux et al. (2019",
        "Scala et al. 2016",
        "From the paper by Balduccini and Gelfond (2003)",
        "e.g., by Feldman et al. (2020)). In a recent work by Wotawa (2020",
        "Morris et al. 2016",
        "Wurman et al. 2008",
        "Veloso et al. 2015",
        "Silver 2005",
        "e.g., the systems discussed in the papers by Le\nand Pontelli (2005) and Schneidenbach et al. (2009)",
        "e.g., the system\ndescribed in the paper by Son et al. (2009)",
        "e.g., the system described by Son\net al. (2014)",
        "Son et al. 2009",
        "Gebser\net al. 2018). An environment for experimenting with MAPF has been developed by Gebser\net al. (2018). A preliminary implementation of a MAPF solver on distributed platform can\nbe found in the paper by Pianpak et al. (2019",
        "Gmytrasiewicz and Doshi 2005;\nRathnasabapathy et al. 2006; Poupart and Boutilier 2003; Sonu and Doshi 2015",
        "Goldenberg et al. 2014; Wagner and Choset 2015; Sharon et al. 2015; Boyarski et al.\n2015; Cohen et al. 2016; Wang and Botea 2011; Luna and Bekris 2011; de Wilde et al. 2014),\ncan compute optimal, boundedly-suboptimal, or suboptimal solutions of MAPF. Erdem et al.\n(2013), Yu and LaValle (2016), and Surynek et al. (2016",
        "From the paper by Balduccini (2011)",
        "see, e.g., the discussion by Son and\nPontelli (2007)",
        "see, e.g.,\nthe papers by Bonatti et al. (2008) and Marple and Gupta (2013)",
        "Ostrowski and\nSchaub 2012; Banbara et al. 2017",
        "Bartholomew and Lee 2013",
        "Gebser et al.\n2016",
        "Abels et al. 2019",
        "Balduccini and Lierler 2013",
        "Balduccini 2011",
        "Balduccini 2011",
        "Balduccini and Lierler 2013; Balduccini and Lierler 2017",
        "Balduccini 2011",
        "Aker\net al. 2011",
        "Abels et al. 2019; Dodaro et al. 2019; Gebser et al. 2018",
        "e.g., as\ndone by Gebser et al. (2013",
        "e.g., value iteration algorithm by\nBellman (1957), topological value iteration by Dai et al. (2011",
        "Bonet and Geffner 2003",
        "Aucher and Bolander 2013;\nBolander et al. 2015; Charrier et al. 2016",
        "Burigana\net al. 2020; Fabiano et al. 2020; Le et al. 2018; Muise et al. 2015; Kominis and Geffner 2015;\nKominis and Geffner 2017; Wan et al. 2015). With the exception of the planner developed by\nBurigana et al. (2020), which employs answer set programming, the majority of the proposed\nsystems are heuristic search based planners. Some EMP planners, such as those proposed by\nMuise et al. (2015), Kominis and Geffner (2015) and (2017",
        "Fagin et al. 1995; Van Ditmarsch et al.\n2007)",
        "Gebser et al. 2019)) could provide a good platform for epistemic planning.\nPreliminary encouraging results on the use of answer set programming in this context have been\nrecently presented by Burigana et al. (2020"
    ],
    "entities_from_reference": [
        "Logic Programming",
        "Nonmonotonic Reasoning",
        "Lierler",
        "Eds",
        "Causal",
        "J. Delgrande",
        "ALBORE",
        "Helmert",
        "Morgan Kaufmann",
        "Annual Conference",
        "J. Lafferty",
        "Williams",
        "Son",
        "Schaub ALVIANO",
        "Ed",
        "Answer Set",
        "Lee",
        "Logic",
        "Online Supplement",
        "Clingcon",
        "J. Minker",
        "Kluwer Academic Publishers",
        "Dordrecht",
        "Artificial Intelligence",
        "Morgan Kaufmann Publishers",
        "Sutton",
        "Set Planning",
        "SKOPKOV A",
        "Fast",
        "Epistemic",
        "Yang",
        "Fox",
        "J. Rintanen",
        "J. Beck",
        "J. Koehler",
        "Schaub BREWKA",
        "Finite LTL",
        "J. Benton",
        "Lazy",
        "Tech",
        "Technical Report",
        "Cedex",
        "Knowledge",
        "Push",
        "John Wiley",
        "L UHNE",
        "Steel",
        "Will Show Them",
        "Dov Gabbay",
        "Barringer",
        "Woods",
        "Vol",
        "College Publications",
        "Sapa",
        "J.",
        "Dynamic",
        "Pereira",
        "J. Dix",
        "Schaub Logic",
        "J. Alferes",
        "Abductive",
        "J. Hoffmann",
        "FOX",
        "Potassco User Guide",
        "Schloss",
        "Informatik",
        "Hill",
        "Fifth",
        "Brescia",
        "Domain Definition Language",
        "Yale Center",
        "Morgan GHALLAB",
        "Cambridge University Kaufmann Publishers",
        "Enhanced",
        "William Kaufmann",
        "Schaub HASLUM",
        "Landmarks",
        "HENDLER",
        "Sanner",
        "HUANG",
        "JIANG",
        "Task",
        "J. Doyle",
        "Shapiro",
        "J. Hendler",
        "Bandit",
        "Machine Learning",
        "J. F",
        "Beliefs",
        "Brafman",
        "J. Frank",
        "Mausam",
        "Artificial Intelli KOWALSKI",
        "J. Cunha",
        "Automated Planning",
        "Answer",
        "Schreye",
        "K OHLER",
        "Van Ditmarsch",
        "J. Lang",
        "Schaub LUNA",
        "Optimal",
        "J. Thangarajah",
        "Albert",
        "MCCAIN",
        "MILLER",
        "Burgard",
        "J. Silva",
        "Hoek",
        "Fundamenta Informaticae",
        "Schaub RATHNASABAPATHY",
        "Human",
        "Fallah Seghrouchni",
        "Numeric",
        "Blue Gene",
        "Message Passing Interface",
        "J. Westerholm",
        "SHANI",
        "Cambridge University",
        "J. Mostow",
        "Rich",
        "J. Mylopoulos",
        "Terracina",
        "Schaub STERN",
        "Robots",
        "Dresden University",
        "Dynamic Epistemic Logic",
        "Springer Verlag",
        "Tempe",
        "Springer",
        "Artificial Morgan",
        "Claypool Publishers",
        "Schaub WOTAWA",
        "Applied Intelligent Systems",
        "Hybrid",
        "ZHU"
    ]
}{
    "title": [
        "CLIPasso: Semantically-Aware Object Sketching"
    ],
    "authors": [
        "[arxiv.Result.Author('Yael Vinker'), arxiv.Result.Author('Ehsan Pajouheshgar'), arxiv.Result.Author('Jessica Y. Bo'), arxiv.Result.Author('Roman Christian Bachmann'), arxiv.Result.Author('Amit Haim Bermano'), arxiv.Result.Author('Daniel Cohen-Or'), arxiv.Result.Author('Amir Zamir'), arxiv.Result.Author('Ariel Shamir')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05822v1"
    ],
    "summary": "Abstraction is at the heart of sketching due to the simple and minimal nature\nof line drawings. Abstraction entails identifying the essential visual\nproperties of an object or scene, which requires semantic understanding and\nprior knowledge of high-level concepts. Abstract depictions are therefore\nchallenging for artists, and even more so for machines. We present an object\nsketching method that can achieve different levels of abstraction, guided by\ngeometric and semantic simplifications. While sketch generation methods often\nrely on explicit sketch datasets for training, we utilize the remarkable\nability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic\nconcepts from sketches and images alike. We define a sketch as a set of\nB\\'ezier curves and use a differentiable rasterizer to optimize the parameters\nof the curves directly with respect to a CLIP-based perceptual loss. The\nabstraction degree is controlled by varying the number of strokes. The\ngenerated sketches demonstrate multiple levels of abstraction while maintaining\nrecognizability, underlying structure, and essential visual components of the\nsubject drawn.",
    "entities_include_in_text": [
        "Proceedings of ACM SIGGRAPH 2021"
    ],
    "entities_from_reference": [
        "Pinz",
        "Kampelm",
        "Pablo Arbel",
        "Michael Maire",
        "Jitendra Malik",
        "Pattern Analysis",
        "Machine Intelligence",
        "Pierre B",
        "Aaron Hertzmann",
        "Line",
        "Itamar Berger",
        "Ariel Shamir",
        "Moshe Mahler",
        "Elizabeth Carter",
        "Jessica Hodgins",
        "Style",
        "Ayan Kumar Bhunia",
        "Ayan Das",
        "Umar Riaz Muhammad",
        "Yongxin Yang",
        "Timothy M. Hospedales",
        "Tao Xiang",
        "Yulia Gryaditskaya",
        "Pixelor",
        "John Canny",
        "Rebecca Chamberlain",
        "Johan Wagemans",
        "Hila Chefer",
        "Shir Gur",
        "Generic",
        "Hong Chen",
        "Eighth",
        "Chen",
        "Shikui Tu",
        "Yuqi Yi",
        "Lei Xu",
        "Judith E. Fan",
        "Daniel L.",
        "Nicholas B. TurkBrowne",
        "Lisa B. Soros",
        "Olaf Witkowski",
        "Clipdraw",
        "Yaroslav Ganin",
        "Tejas D. Kulkarni",
        "Igor Babuschkin",
        "Oriol Vinyals",
        "Qi Liu",
        "Qi Xu",
        "Limin Wang",
        "Jianzhuang Image",
        "Pattern Recognition",
        "Gabriel Goh",
        "Nick Cammarata",
        "Chelsea Voss",
        "Shan Carter",
        "Michael Petrov",
        "Ludwig Schubert",
        "Alec Radford",
        "Chris Olah",
        "Distill",
        "Mark Sypesteyn",
        "Jan Willem Hoftijzer",
        "Sylvia C. Pont",
        "Adrien Bousseau",
        "David Ha",
        "Douglas Eck",
        "Hertzmann",
        "Phillip Isola",
        "Zhu",
        "Tinghui Zhou",
        "Alexei",
        "Efros",
        "Moritz Kampelm",
        "Axel Pinz",
        "Alexander Kolesnikov",
        "Alexey Dosovitskiy",
        "Dirk Weissenborn",
        "Georg Heigold",
        "Jakob Uszkoreit",
        "Lucas Beyer",
        "Matthias Minderer",
        "Mostafa Dehghani",
        "Neil Houlsby",
        "Sylvain Gelly",
        "Thomas Unterthiner",
        "Xiaohua Zhai",
        "Zhe Lin",
        "Radomir Mech",
        "Ersin Yumer",
        "Deva Ramanan",
        "Michal Luk",
        "Gharbi Micha",
        "Jonathan",
        "Graph",
        "Shaogang Gong",
        "Hangyu Lin",
        "Yanwei Fu",
        "Yu-Gang Jiang",
        "John F. J. Mellor",
        "Eunbyung Park",
        "Tejas Kulkarni",
        "Dan Rosenbaum",
        "Andy Ballard",
        "Theophane Weber",
        "Daniela Mihai",
        "Jonathon S. Hare",
        "Haoran Mo",
        "Edgar Simo-Serra",
        "Chengying Gao",
        "Ruomei Wang",
        "Adam Paszke",
        "Sam Gross",
        "Francisco Massa",
        "Adam Lerer",
        "James Bradbury",
        "Gregory Chanan",
        "Trevor Killeen",
        "Zeming Lin",
        "Natalia Gimelshein",
        "Luca Antiga",
        "Alban Desmaison",
        "Andreas Kopf",
        "Edward Yang",
        "Zachary DeVito",
        "Martin Raison",
        "Alykhan Tejani",
        "Sasank Chilamkurthy",
        "Benoit Steiner",
        "Lu Fang",
        "Junjie Bai",
        "Soumith Chintala",
        "Fox",
        "Garnett",
        "Yonggang Qi",
        "Guoyao Su",
        "Pinaki Nath Chowdhury",
        "Mingkang Li",
        "Xuebin Qin",
        "Zichen Vincent Zhang",
        "Chenyang Huang",
        "Masood Dehghan",
        "Osmar R. Za",
        "Martin J",
        "Pattern Recognit.",
        "Jong Wook Kim",
        "Chris Hallacy",
        "Aditya Ramesh",
        "Sandhini Agarwal",
        "Girish Sastry",
        "Amanda Askell",
        "Pamela Mishkin",
        "Jack Clark",
        "Gretchen Krueger",
        "Ilya Sutskever",
        "Leo Sampaio Ferraz Ribeiro",
        "Tu Bui",
        "John P. Collomosse",
        "Moacir Antonelli Ponti",
        "Paul L. Rosin",
        "David Mould",
        "Chuan Li",
        "Hua Li",
        "Michael Wand",
        "Wang",
        "Holger Winnem",
        "Patsorn Sangkloy",
        "Nathan Burnell",
        "Cusuh Ham",
        "James Hays",
        "Jifei Song",
        "Kaiyue Pang",
        "Timothy Hospedales",
        "Yingtao Tian",
        "Modern",
        "V Varshaneya",
        "Sangeetha Balasubramanian",
        "Vineeth N. Balasubramanian",
        "Graphics",
        "Image Processing",
        "Andrew Tao",
        "Jan Kautz",
        "Bryan Catanzaro",
        "Jan Eric Kyprianidis",
        "Sven C. Olsen",
        "Xdog",
        "Peng Xu",
        "Qiyue Yin",
        "Liang Wang",
        "Richard Zhang",
        "Alexei A. Efros",
        "Eli Shechtman",
        "Oliver Wang",
        "Yf Jiang",
        "Huang",
        "Chen Fang",
        "Zhaowen Wang",
        "Jimei Yang",
        "Byungmoon Kim",
        "Zhili Chen",
        "Jonathan Brandt",
        "Object Sketching",
        "Jessica Y. Bo1 Roman Christian Bachmann1 Amit Haim Bermano2",
        "Daniel",
        "Amir Zamir1 Ariel Shamir3",
        "Implementation Details",
        "Background C. User Study",
        "Initialization Ablation",
        "CLIP Attention",
        "Loss Ablation",
        "Architecture Analysis",
        "Loss Term Weights",
        "Loss Functions",
        "Adam",
        "Tesla V100 GPU",
        "Background",
        "Generally",
        "Input",
        "Li",
        "None",
        "Semantic",
        "Sample",
        "Input Saliency Points Sampled Initial Strokes Output Input",
        "Seed",
        "Saliency Points Sampled Initial Strokes Output Input Saliency Points Sampled Initial Strokes Output",
        "CLIP",
        "Input Layer1 Layer2 Layer3 Layer4 Layer5 Fully",
        "Lgeometric",
        "Input Layer1 Layer2 Layer3 Layer4 Layer5 Layer6 B",
        "Layer7 Layer8 Layer9 Layer10 Layer11 Layer12 Fully Connected B",
        "Input Ls Lg",
        "Lsemantic",
        "Input XDoG L2",
        "Results",
        "Input Text Image Text",
        "Image Sketch Style Ours",
        "Ours8 Ours4"
    ]
}{
    "title": [
        "The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis"
    ],
    "authors": [
        "[arxiv.Result.Author('Andrea Poltronieri'), arxiv.Result.Author('Aldo Gangemi')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05817v1"
    ],
    "summary": "The use of Semantic Technologies - in particular the Semantic Web - has\nrevealed to be a great tool for describing the cultural heritage domain and\nartistic practices. However, the panorama of ontologies for musicological\napplications seems to be limited and restricted to specific applications. In\nthis research, we propose HaMSE, an ontology capable of describing musical\nfeatures that can assist musicological research. More specifically, HaMSE\nproposes to address sues that have been affecting musicological research for\ndecades: the representation of music and the relationship between quantitative\nand qualitative data. To do this, HaMSE allows the alignment between different\nmusic representation systems and describes a set of musicological features that\ncan allow the music analysis at different granularity levels.",
    "entities_include_in_text": [
        "ISMIR 2010",
        "ISMIR 2015",
        "SciPy 2015",
        "XIV CIM 2003",
        "ISMIR\n2007"
    ],
    "entities_from_reference": [
        "Christian Bizer",
        "Tom Heath",
        "Tim Berners-Lee",
        "Valentina Presutti",
        "Enrico Daga",
        "Aldo Gangemi",
        "Knowledge Engineering",
        "Berlin",
        "Heidelberg",
        "Springer Berlin Heidelberg",
        "Samira",
        "Christophe Guillotel",
        "Faycal Hamdi",
        "Philippe Rigaux",
        "Nicolas Travers",
        "Machinery",
        "Eric Clarke",
        "Nicholas Cook",
        "Aims",
        "Music",
        "Cook",
        "Music Information Retrieval",
        "Michael Cuthbert",
        "Christopher Ariza",
        "Music21",
        "Music Information Retrieval Conference",
        "Roger B. Dannenberg",
        "Michael Good",
        "Musicxml",
        "Walter B. Hewlett",
        "Eleanor Selfridge-Field",
        "Retrieval",
        "Michael Gruninger",
        "Mark Fox",
        "Workshop",
        "Basic Ontological Issues",
        "Nicholas Harley",
        "Geraint Wiggins",
        "Mitch Harris",
        "Alan Smaill",
        "Christopher Harte",
        "Mark S",
        "Samer Abdallah",
        "Symbolic",
        "Henkjan Honing",
        "Dutch Journal",
        "Music Theory",
        "David Huron",
        "Ernest Bloch Lectures",
        "Music J.",
        "Jim Jones",
        "Diego",
        "Siqueira Braga",
        "Kleber Tertuliano",
        "Tomi Kauppinen",
        "Musicowl",
        "Marc Leman",
        "Peter Lang",
        "Albrecht Schneider",
        "Origin",
        "Gestalt",
        "Fred Lerdahl",
        "Ray S Jackendoff",
        "Pasquale Lisena",
        "Raphael Troncy",
        "Brian McFee",
        "Colin Raffel",
        "Dawen Liang",
        "Daniel Ellis",
        "Matt Mcvicar",
        "Eric Battenberg",
        "Oriol Nieto",
        "Albert Merono-Penuela",
        "Rinke Hoekstra",
        "Peter Bloem",
        "Reinier",
        "Valk",
        "Bas Stringer",
        "Berit Janssen",
        "Victor",
        "Boer",
        "Alo Allik",
        "Stefan Schlobach",
        "Kevin Page",
        "Miriam Fernandez",
        "Valentina Tamma",
        "Freddy Lecue",
        "Philippe Cudre-Mauroux",
        "Juan Sequeda",
        "Christoph Lange",
        "Jeff Heflin",
        "Cham",
        "Springer International Publishing",
        "Gabriel Meseguer-Brocal",
        "Geoffroy Peeters",
        "Guillaume Pellerin",
        "Michel Buffa",
        "Elena Cabrio",
        "Catherine Faron Zucker",
        "Alain Giboin",
        "Isabelle Mirbel",
        "Romain Hennequin",
        "Manuel Moussallam",
        "Francesco Piccoli",
        "Thomas Fillon",
        "Song Database Project",
        "Audio",
        "Client Applications",
        "Queen Mary University",
        "Erica Mugglestone",
        "Guido Adler",
        "Guido",
        "Meinard Muller",
        "Jan Nieuwenhuizen",
        "Lilypond",
        "Juan Bello",
        "Nicola Orio",
        "Antonio Roda",
        "Renato Panda",
        "Ricardo Malheiro",
        "Rui Pedro Paiva",
        "Musical",
        "Richard Parncutt",
        "Systematic",
        "Alberto Pinto",
        "Reinier Leuken",
        "Frans Wiering",
        "Remco Veltkamp",
        "Raimond",
        "Mark Sandler",
        "Frederick Giasson",
        "Sabbir M. Rashid",
        "David De Roure",
        "Deborah L.",
        "Perry Roland",
        "Joseph Rothstein",
        "James Russell",
        "Peter",
        "Fryske Akademy",
        "Chris Walshaw",
        "Modern Methods",
        "Musicology",
        "Realities",
        "Eduardo Miranda"
    ]
}{
    "title": [
        "Multi-Modal Knowledge Graph Construction and Application: A Survey"
    ],
    "authors": [
        "[arxiv.Result.Author('Xiangru Zhu'), arxiv.Result.Author('Zhixu Li'), arxiv.Result.Author('Xiaodan Wang'), arxiv.Result.Author('Xueyao Jiang'), arxiv.Result.Author('Penglei Sun'), arxiv.Result.Author('Xuwu Wang'), arxiv.Result.Author('Yanghua Xiao'), arxiv.Result.Author('Nicholas Jing Yuan')]"
    ],
    "link": [
        "http://arxiv.org/pdf/2202.05786v1"
    ],
    "summary": "Recent years have witnessed the resurgence of knowledge engineering which is\nfeatured by the fast growth of knowledge graphs. However, most of existing\nknowledge graphs are represented with pure symbols, which hurts the machine's\ncapability to understand the real world. The multi-modalization of knowledge\ngraphs is an inevitable key step towards the realization of human-level machine\nintelligence. The results of this endeavor are Multi-modal Knowledge Graphs\n(MMKGs). In this survey on MMKGs constructed by texts and images, we first give\ndefinitions of MMKGs, followed with the preliminaries on multi-modal tasks and\ntechniques. We then systematically review the challenges, progresses and\nopportunities on the construction and application of MMKGs respectively, with\ndetailed analyses of the strength and weakness of different solutions. We\nfinalize this survey with open research problems relevant to MMKGs.",
    "entities_include_in_text": [],
    "entities_from_reference": [
        "J. Cabral",
        "Singh",
        "Miller",
        "Wordnet",
        "Babelnet",
        "J. Lehmann",
        "Springer",
        "Yago",
        "Wikidata",
        "J. Liang",
        "Liang",
        "Applied Intelligent Systems",
        "Wang",
        "Zhu",
        "Probase",
        "Physica D",
        "Symbol",
        "Steels",
        "Symbols",
        "Koller",
        "Knowledge",
        "Tang",
        "Zhang",
        "Counterfactual",
        "Pattern Recognition",
        "Zhao",
        "Neil",
        "Gaia",
        "Resin",
        "Human Language",
        "Niepert",
        "Mmkg",
        "Richpedia",
        "Big Data Research",
        "Alberts",
        "Huang",
        "Visualsem",
        "Baraldi",
        "Yang",
        "J. Yang",
        "Berg",
        "Mattnet",
        "J. Lu",
        "Zitnick",
        "Vqa",
        "Hengel",
        "Fvqa",
        "Picard",
        "J. Yan",
        "Camp",
        "Deep",
        "Karpathy",
        "Kiros",
        "Lin",
        "J. Hays",
        "Ramanan",
        "Microsoft",
        "J. Wang",
        "Data Mining",
        "Show",
        "J. Ba",
        "Multimodal",
        "Anderson",
        "Buehler",
        "Johnson",
        "Uniter",
        "Fang",
        "Jiang",
        "Kim",
        "Son",
        "Vilt",
        "J. Liu",
        "Unimo",
        "J. Tang",
        "Lxmert",
        "Mogadala",
        "Marino",
        "Okvqa",
        "J. Fu",
        "J. Johnson",
        "J. Kravitz",
        "J. Gao",
        "J. Zhang",
        "J. C. Caicedo",
        "J. Hockenmaier",
        "Kuznetsova",
        "J. Uijlings",
        "Krasin",
        "J. PontTuset",
        "Kolesnikov",
        "Deng",
        "Structured",
        "Radford",
        "J. W. Kim",
        "J. Clark",
        "Clipscore",
        "Caron",
        "J. Mairal",
        "Babytalk",
        "Keller",
        "Image",
        "Malik",
        "Cohen",
        "Thomson",
        "Bernstein",
        "Chua",
        "Scene",
        "Lee",
        "J. Huang",
        "J. Shi",
        "Graphical",
        "Hake",
        "J. Ellis",
        "Joint",
        "Recognize",
        "J. G. Ellis",
        "Abstract",
        "Imagenet",
        "Ieee",
        "J. Deng",
        "J. Ping",
        "Multimedia Tools",
        "Van Leuken",
        "Olivares",
        "Towards",
        "Pang",
        "Pattern Recognition Workshops",
        "J. Chen",
        "Advanced Applications",
        "Hudson",
        "Gqa",
        "Kvqa",
        "Explicit",
        "Torralba",
        "Freeman",
        "Nuswide",
        "Lew",
        "Darrell",
        "Tran",
        "Transform",
        "J. Devlin",
        "Human Language Technologies",
        "Harper",
        "Uyar",
        "Online Information Review",
        "J. Wan",
        "Knowledge Management",
        "J. Weston",
        "Bordes",
        "J. Feng",
        "Rettinger",
        "J. Jia",
        "Wilcke",
        "Boer",
        "Veer",
        "Mmea",
        "Kblrn",
        "Krisp",
        "Richardson",
        "Clark",
        "Shang",
        "Systems",
        "Video Technology",
        "Garrett",
        "J. Luo",
        "Chen",
        "Hsu",
        "Bobadilla"
    ]
}