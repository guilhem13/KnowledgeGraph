{"title": ["MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition"], "authors": ["[arxiv.Result.Author('Chao-Yuan Wu'), arxiv.Result.Author('Yanghao Li'), arxiv.Result.Author('Karttikeya Mangalam'), arxiv.Result.Author('Haoqi Fan'), arxiv.Result.Author('Bo Xiong'), arxiv.Result.Author('Jitendra Malik'), arxiv.Result.Author('Christoph Feichtenhofer')]"], "link": ["http://arxiv.org/pdf/2201.08383v1"], "summary": "While today's video recognition systems parse snapshots or short clips\naccurately, they cannot connect the dots and reason across a longer range of\ntime yet. Most existing video architectures can only process <5 seconds of a\nvideo without hitting the computation or memory bottlenecks.\n  In this paper, we propose a new strategy to overcome this challenge. Instead\nof trying to process more frames at once like most existing methods, we propose\nto process videos in an online fashion and cache \"memory\" at each iteration.\nThrough the memory, the model can reference prior context for long-term\nmodeling, with only a marginal cost. Based on this idea, we build MeMViT, a\nMemory-augmented Multiscale Vision Transformer, that has a temporal support 30x\nlonger than existing models with only 4.5% more compute; traditional methods\nneed >3,000% more compute to do the same. On a wide range of settings, the\nincreased temporal support enabled by MeMViT brings large gains in recognition\naccuracy consistently. MeMViT obtains state-of-the-art results on the AVA,\nEPIC-Kitchens-100 action classification, and action anticipation datasets. Code\nand models will be made publicly available.", "entities_include_in_text": null, "entities": {"persons": ["Sami Abu-El-Haija", "Nisarg Kothari", "Joonseok Lee", "Paul Natsev", "George Toderici", "Balakrishnan Varadarajan", "Anurag Arnab", "Mostafa Dehghani", "Georg Heigold", "Chen Sun", "Mario Luci", "Gedas Bertasius", "Heng Wang", "Lorenzo Torresani", "Joao Carreira", "Eric Noland", "Andras Banki-Horvath", "Chloe Hillier", "Andrew Zisserman", "Carreira", "Viorica Patraucean", "Laurent Mazare", "Simon Osindero", "Shoufa Chen", "Peize Sun", "Enze Xie", "Chongjian Ge", "Jiannan Wu", "Lan Ma", "Jiajun Shen", "Luo", "Watch", "Yihong Chen", "Yue Cao", "Han Hu", "Liwei Wang", "Memory", "Zhengsu Chen", "Lingxi Xie", "Jianwei Niu", "Xuefeng Liu", "Longhui Wei", "Qi Tian", "Chi Zhang", "Yichen Wei", "Jiang", "Sparse", "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V Le", "Ruslan Salakhutdinov", "Navneet Dalal", "Bill Triggs", "Dima Damen", "Hazel Doughty", "Giovanni Maria Farinella", "Sanja Fidler", "Antonino Furnari", "Evangelos Kazakos", "Davide Moltisanti", "Jonathan Munro", "Toby Perrett", "Will Price", "Michael Wray", "Jia Deng", "Wei Dong", "Richard Socher", "Kai Li", "Li Fei-Fei", "Piotr Doll", "Vincent Rabaud", "Garrison Cottrell", "Serge Belongie", "Behavior", "Visual Surveillance", "Jeff Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Trevor Darrell", "Xiaoyi Dong", "Jianmin Bao", "Dongdong Chen", "Weiming Zhang", "Nenghai Yu", "Lu Yuan", "Dong Chen", "Cswin", "Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Matthias Minderer", "Sylvain Gelly", "Alexei A Efros", "Alexander C Berg", "Greg Mori", "Haoqi Fan", "Yanghao Li", "Bo Xiong", "Christoph Feichtenhofer", "Karttikeya Mangalam", "Zhicheng Yan", "Jitendra Malik", "Multiscale", "Sebastiano Battiato", "Giovanni Farinella", "Rohit Girdhar", "Carl Doersch", "Video", "Kristen Grauman", "Anticipative Video Transformer", "Deva Ramanan", "Abhinav Gupta", "Josef Sivic", "Bryan Russell", "Ross Girshick", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Jia", "Benjamin Graham", "Alaaeldin El-Nouby", "Hugo Touvron", "Pierre Stock", "Armand Joulin", "Herve Jegou", "Matthijs Douze", "Chunhui Gu", "David A. Ross", "Carl Vondrick", "Caroline Pantofaru", "Li", "Sudheendra Vijayanarasimhan", "Susanna Ricco", "Rahul Sukthankar", "Cordelia Schmid", "Efstratios Gavves", "Boyuan Jiang", "Weihao Gan", "Wei Wu", "Junjie Yan", "Will Kay", "Karen Simonyan", "Brian Zhang", "Fabio Viola", "Tim Green", "Trevor Back", "Alexander Klaser", "Marcin Marszaek", "Dan Kondratyuk", "Liangzhe Yuan", "Li Zhang", "Matthew Brown", "Bruno Korbar", "Du Tran", "Scsampler", "Ivan Laptev", "Marcin Marszalek", "Benjamin Rozenfeld", "Sangmin Lee", "Hak Gu Kim", "Dae Hwi Choi", "Kim", "Yong Man Ro", "Sangho Lee", "Jinyoung Sung", "Youngjae Yu", "Gunhee Kim", "Dong Li", "Zhaofan Qiu", "Qi Dai", "Ting Yao", "Tao Mei", "Tushar Nagarajan", "Improved", "Zhenyang Li", "Kirill Gavrilyuk", "Mihir Jain", "Image Understanding", "Chuang Gan", "Song Han", "Bharath Hariharan", "Feature", "Mason Liu", "Yutong Lin", "Yixuan Wei", "Zheng Zhang", "Stephen Lin", "Swin", "Ilya Loshchilov", "Frank Hutter", "Daniel Neimark", "Omri Bar", "Maya Zohar", "Dotan AsarXiv", "Joe", "Matthew Hausknecht", "Oriol Vinyals", "Rajat Monga", "Beyond", "Siyu Chen", "Mike Zheng Shou", "Yu Liu", "Jing Shao", "Hongsheng Li", "Mandela Patrick", "Dylan Campbell", "Yuki M Asano", "Ishan Misra Florian Metze", "Andrea Vedaldi", "Jo Henriques", "Xiaojiang Peng", "Yu Qiao", "Qiang Peng", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Jack W Rae", "Anna Potapenko", "Timothy P Lillicrap", "Ali Razavi", "Jian Sun", "Faster", "Fadime Sener", "Dibyadip Chatterjee", "Angela Yao", "Peter Shaw", "Jakob Uszkoreit", "Ashish Vaswani", "Edouard Grave", "Piotr Bojanowski", "Adaptive", "Da Ju", "Spencer Poff", "Stephen Roller", "Arthur Szlam", "Jason Weston", "Angela Fan", "Kui Jia", "Kevin Chen", "Bertram E Shi", "Silvio Savarese", "Jingru Tan", "Changbao Wang", "Buyu Li", "Quanquan Li", "Wanli Ouyang", "Gang Zhang", "Hanming Deng", "Lewei Lu", "Jifeng Dai", "Jiajun Tang", "Jin Xia", "Xinzhi Mu", "Bo Pang", "Cewu Lu", "Graham W Taylor", "Rob Fergus", "Yann LeCun", "Christoph Bregler", "Matthieu Cord", "Francisco Massa", "Alexandre Sablayrolles", "Gabriel Synnaeve", "Herv", "Lubomir Bourdev", "Manohar Paluri", "Matt Feiszli", "Noam Shazeer", "Niki Parmar", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin", "Alexander Kl", "Dense", "Muhammad Muneeb Ullah", "Limin Wang", "Xiaoou Tang", "Yuanjun Xiong", "Zhe Wang", "Dahua Lin", "Luc Val Gool", "Wenhai Wang", "Xiang Li", "Kaitao Song", "Ding Liang", "Tong Lu", "Ping Luo", "Pyramid", "Xiaolong Wang", "Xiaohan Wang", "Linchao Zhu", "Yi Yang", "Philipp Kr", "Philipp Krahenbuhl", "Towards", "Manzil Zaheer", "Hexiang Hu", "Alexander J Smola", "Zhuowen Tu", "Jonathan Huang", "Kevin Murphy", "Yunpeng Chen", "Tao Wang", "Weihao Yu", "Yujun Shi", "Francis EH Tay", "Jiashi Feng", "Shuicheng Yan", "Bolei Zhou", "Alex Andonian", "Aude Oliva", "Antonio TorIn ECCV", "Xizhou Zhu", "Yujie Wang", "Kamaljeet Singh", "Thomas Brox"], "organizations": ["Sudheendra Vijayanarasimhan", "Cordelia Schmid", "ICCV", "ECCV", "CVPR", "ACM", "ACL", "PAMI", "International Workshop", "Performance Evaluation", "Kate Saenko", "ICLR", "ECCV Workshops", "Priya Goyal", "ConvNets", "Noureldien Hussein", "Arnold", "MengMeng Wang", "Yandong Li", "Mingxing Tan", "Yanghao Li", "Cees", "VideoLSTM", "Computer Vision", "Menglong Zhu", "detecIn Proc", "Siddhant", "TecharXiv", "ICML", "IJCV", "R Manmatha"], "locations": [], "genpurp": []}}{"title": ["Learning Pixel Trajectories with Multiscale Contrastive Random Walks"], "authors": ["[arxiv.Result.Author('Zhangxing Bian'), arxiv.Result.Author('Allan Jabri'), arxiv.Result.Author('Alexei A. Efros'), arxiv.Result.Author('Andrew Owens')]"], "link": ["http://arxiv.org/pdf/2201.08379v1"], "summary": "A range of video modeling tasks, from optical flow to multiple object\ntracking, share the same fundamental challenge: establishing space-time\ncorrespondence. Yet, approaches that dominate each space differ. We take a step\ntowards bridging this gap by extending the recent contrastive random walk\nformulation to much denser, pixel-level space-time graphs. The main\ncontribution is introducing hierarchy into the search problem by computing the\ntransition matrix between two frames in a coarse-to-fine manner, forming a\nmultiscale contrastive random walk when extended in time. This establishes a\nunified technique for self-supervised learning of optical flow, keypoint\ntracking, and video object segmentation. Experiments demonstrate that, for each\nof these tasks, the unified model achieves performance competitive with strong\nself-supervised approaches specific to that task. Project site:\nhttps://jasonbian97.github.io/flowwalk", "entities_include_in_text": null, "entities": {"persons": ["Robert Anderson", "David Gallup", "Jonathan T Barron", "Janne Kontkanen", "Noah Snavely", "Carlos Hern", "Sameer Agarwal", "Steven M Seitz", "Jump", "Simon Baker", "Iain Matthews", "Daniel Scharstein", "Stefan Roth", "Michael J Black", "Richard Szeliski", "Paul Anandan", "Thomas Brox", "Christoph Bregler", "Jitendra Malik", "Large", "Andr", "Bruhn", "Nils Papenberg", "Joachim Weickert", "Object", "Springer", "Brain Schunck", "Zhaoyang Huang", "Xiaokun Pan", "Runsen Xu", "Kachun Cheung", "Guofeng Zhang", "Hongsheng Li", "Mirrorflow", "Eddy Ilg", "Nikolaus Mayer", "Tonmoy Saikia", "Margret Keuper", "Alexey Dosovitskiy", "Allan Jabri", "Andrew Owens", "Alexei A Efros", "Max Jaderberg", "Karen Simonyan", "Andrew Zisserman", "Koray Kavukcuoglu", "Joel Janai", "Fatma G", "Anurag Ranjan", "Michael Black", "Andreas Geiger", "Michael J", "Black", "Fatma Guney", "Jonas Wulff", "Slow", "Pattern Recognition", "Hueihan Jhuang", "Juergen Gall", "Silvia Zuffi", "Cordelia Schmid", "Rico Jonschkowski", "Austin Stone", "Ariel Gordon", "Kurt Konolige", "Anelia Angelova", "Ryan Kennedy", "Camillo J Taylor", "Optical", "Diederik P Kingma", "Jimmy Ba", "Adam", "Zihang Lai", "Erika Lu", "Weidi Xie", "Mast", "Cheng Lei", "Li", "Sifei Liu", "Shalini De Mello", "Xiaolong Wang", "Jan Kautz", "Yunpeng Li", "Daniel P Huttenlocher", "Massachusetts Institute", "Liang Liu", "Jiangning Zhang", "Yong Liu", "Yabiao Wang", "Tai", "Donghao Luo", "Chengjie Wang", "Jilin Li", "Feiyue Huang", "Pengpeng Liu", "Irwin King", "Michael R Lyu", "Jia Xu", "Ddflow", "Michael R. Lyu", "Michael Lyu", "Selflow", "Bruce D Lucas", "Takeo Kanade", "Chuan Wang", "Shuaicheng Liu", "Haoqiang Fan", "Jue Wang", "Jian Sun", "Upflow", "Simon Meister", "Junhwa Hur", "Unflow", "Geoffrey Hinton", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "J. Pont-Tuset", "Van Gool", "Jordi Pont-Tuset", "Federico Perazzi", "Sergi Caelles", "Pablo Arbel", "Alexander Sorkine-Hornung", "Luc Van Gool", "Jerome Revaud", "Philippe Weinzaepfel", "Zaid Harchaoui", "Epicflow", "Dan Rosenbaum", "Daniel Zoran", "Yair Weiss", "Victor Lempitsky", "Carsten Rother", "Visual Motion Analysis", "Michael Rubinstein", "Ce Liu", "William T Freeman", "Towards", "Peter Sand", "Seth Teller", "Particle", "Alexander Shekhovtsov", "Ivan Kovtun", "Hlav", "Image Understanding", "Leslie N Smith", "Nicholay Topin", "Machine Learning", "Daniel Maurer", "Alper Ayvaci", "Smurf", "Erik Sudderth", "Layered", "Daniel Vlasic", "Charles Herrmann", "Varun Jampani", "Michael Krainin", "Huiwen Chang", "Ramin Zabih", "Autoflow", "Xiaodong Yang", "Narayanan Sundaram", "Kurt Keutzer", "Dense", "Zhenyu Jiang", "Zhenda Xie", "Yue Cao", "Zheng Zhang", "Philip HS Torr", "Han Hu", "Jia Deng", "Raft", "Sebastian Volz", "Andres Bruhn", "Levi Valgaerts", "Henning Zimmer", "Carl Vondrick", "Abhinav Shrivastava", "Alireza Fathi", "Sergio Guadarrama", "Kevin Murphy", "Wang", "Heng Wang", "Alexander Kl", "Chao Ma", "Wengang Zhou", "Wei Liu", "Houqiang Li", "Yang Wang", "Yi Yang", "Wei Xu", "Zhongdao Wang", "Hengshuang Zhao", "Philip Torr", "Luca Bertinetto", "Deepflow", "Jiarui Xu", "Li Xu", "Jianing Chen", "Jiaya Jia", "Linjie Yang", "Yuchen Fan", "Dingcheng Yue", "Yuchen Liang", "Jianchao Yang", "Thomas Huang", "Zhichao Yin", "Geonet", "Jason J. Yu", "Adam W. Harley", "Konstantinos G. Derpanis", "Bouguet", "Pyramidal", "Microprocessor", "Research Labs", "Yiran Zhong", "Pan Ji", "Jianyuan Wang", "Yuchao Dai", "Hongdong Li", "Xiaojin Zhu", "Zoubin Ghahramani", "Zitnick", "Nebojsa Jojic", "Yuliang Zou", "Zelun Luo", "Huang", "Hyperparameter Learning", "Temperature Video", "Window Size", "Values", "Chairs", "Sintel D. Additional Qualitative"], "organizations": ["ACM Transactions", "TOG", "International Journal", "Computer Vision", "JP Lewis", "IJCV", "Parametric", "Computer", "Berthold Horn", "Artificial Intelligence", "Yan Xu", "IEEE International Conference", "IEEE", "NeurIPS", "ECCV", "IEEE Conference", "International Workshop", "Energy Minimization Methods", "International Conference", "PhD", "distillaIn Proceedings", "AAAI Conference", "Artificial", "AAAI", "IJCAI", "Roland Memisevic", "Cordelia Schmid", "Geometrical Approaches", "ICCV", "International Society", "Optics", "Photonics", "multiIn Proframe", "Yansong Tang", "Information Science", "International", "Shengjin Wang", "Xiaolong Wang", "ECCV 2016 Workshops", "Part", "Jean", "Intel Corporation", "ICCV05", "Random Walk", "KITTI", "RGB", "Smoothness", "PyTorch", "Adam", "ARflow", "CensusCensus"], "locations": [], "genpurp": []}}{"title": ["Omnivore: A Single Model for Many Visual Modalities"], "authors": ["[arxiv.Result.Author('Rohit Girdhar'), arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Nikhila Ravi'), arxiv.Result.Author('Laurens van der Maaten'), arxiv.Result.Author('Armand Joulin'), arxiv.Result.Author('Ishan Misra')]"], "link": ["http://arxiv.org/pdf/2201.08377v1"], "summary": "Prior work has studied different visual modalities in isolation and developed\nseparate architectures for recognition of images, videos, and 3D data. Instead,\nin this paper, we propose a single model which excels at classifying images,\nvideos, and single-view 3D data using exactly the same model parameters. Our\n'Omnivore' model leverages the flexibility of transformer-based architectures\nand is trained jointly on classification tasks from different modalities.\nOmnivore is simple to train, uses off-the-shelf standard datasets, and performs\nat-par or better than modality-specific models of the same size. A single\nOmnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN\nRGB-D. After finetuning, our models outperform prior work on a variety of\nvision tasks and generalize across modalities. Omnivore's shared visual\nrepresentation naturally enables cross-modal recognition without access to\ncorrespondences between modalities. We hope our results motivate researchers to\nmodel visual modalities together.", "entities_include_in_text": null, "entities": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Higher Symmetries of 5d Orbifold SCFTs"], "authors": ["[arxiv.Result.Author('Michele Del Zotto'), arxiv.Result.Author('Jonathan J. Heckman'), arxiv.Result.Author('Shani Nadir Meynet'), arxiv.Result.Author('Robert Moscrop'), arxiv.Result.Author('Hao Y. Zhang')]"], "link": ["http://arxiv.org/pdf/2201.08372v1"], "summary": "We determine the higher symmetries of 5d SCFTs engineered from M-theory on a\n$\\mathbb{C}^3 / \\Gamma$ background for $\\Gamma$ a finite subgroup of $SU(3)$.\nThis resolves a longstanding question as to how to extract this data when the\nresulting singularity is non-toric (when $\\Gamma$ is non-abelian) and/or not\nisolated (when the action of $\\Gamma$ has fixed loci). The BPS states of the\ntheory are encoded in a 1D quiver quantum mechanics gauge theory which\ndetermines the possible 1-form and 2-form symmetries. We also show that this\nsame data can also be extracted by a direct computation of the corresponding\ndefect group associated with the orbifold singularity. Both methods agree, and\nthese computations do not rely on the existence of a resolution of the\nsingularity. We also observe that when the geometry faithfully captures the\nglobal 0-form symmetry, the abelianization of $\\Gamma$ detects a 2-group\nstructure (when present). As such, this establishes that all of this data is\nindeed intrinsic to the superconformal fixed point rather than being an\nemergent property of an IR gauge theory phase.", "entities_include_in_text": null, "entities": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Revisiting Weakly Supervised Pre-Training of Visual Perception Models"], "authors": ["[arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Laura Gustafson'), arxiv.Result.Author('Aaron Adcock'), arxiv.Result.Author('Vinicius de Freitas Reis'), arxiv.Result.Author('Bugra Gedik'), arxiv.Result.Author('Raj Prateek Kosaraju'), arxiv.Result.Author('Dhruv Mahajan'), arxiv.Result.Author('Ross Girshick'), arxiv.Result.Author('Piotr Doll\u00e1r'), arxiv.Result.Author('Laurens van der Maaten')]"], "link": ["http://arxiv.org/pdf/2201.08371v1"], "summary": "Model pre-training is a cornerstone of modern visual recognition systems.\nAlthough fully supervised pre-training on datasets like ImageNet is still the\nde-facto standard, recent studies suggest that large-scale weakly supervised\npre-training can outperform fully supervised approaches. This paper revisits\nweakly-supervised pre-training of models using hashtag supervision with modern\nversions of residual networks and the largest-ever dataset of images and\ncorresponding hashtags. We study the performance of the resulting models in\nvarious transfer-learning settings including zero-shot transfer. We also\ncompare our models with those obtained via large-scale self-supervised\nlearning. We find our weakly-supervised models to be very competitive across\nall settings, and find they substantially outperform their self-supervised\ncounterparts. We also include an investigation into whether our models learned\npotentially troubling associations or stereotypes. Overall, our results provide\na compelling argument for the use of weakly supervised learning in the\ndevelopment of visual recognition systems. Our models, Supervised Weakly\nthrough hashtAGs (SWAG), are available publicly.", "entities_include_in_text": null, "entities": {"persons": ["Samira Abnar", "Mostafa Dehghani", "Behnam Neyshabur", "Hanie Sedghi", "Adcock", "Singh", "Maaten", "Zhang", "Motwani", "J. Guerin", "Classy", "Hangbo Bao", "Li Dong", "Furu Wei", "Beit", "Bert", "Andrei Barbu", "David Mayo", "Julian Alverio", "William Luo", "Christopher Wang", "Dan Gutfreund", "Josh Tenenbaum", "Boris Katz", "Fox", "Garnett", "Josh Beal", "Dong Huk Park", "Andrew Zhai", "Dmitry Kislyuk", "Emily M. Bender", "Timnit Gebru", "Angelina McMillan-Major", "Lucas Beyer", "Olivier J.", "Alexander Kolesnikov", "Xiaohua Zhai", "Aaron", "Abeba Birhane", "Vinay", "Emmanuel Kahembwe", "Multimodal", "Tom B", "Brown", "Ben Mann", "Nick Ryder", "Melanie Subbiah", "Jared D. Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "Sandhini Agarwal", "Ariel Herbert-Voss", "Gretchen M. Krueger", "Tom Henighan", "Rewon Child", "Aditya Ramesh", "Daniel Ziegler", "Jeffrey Wu", "Clemens Winter", "Chris Hesse", "Mark Chen", "Eric Sigler", "Mateusz Litwin", "Scott Gray", "Benjamin Chess", "Jack Clark", "Christopher Berner", "Sam McCandlish", "Alec Radford", "Ilya Sutskever", "Dario Amodei", "Mathilde Caron", "Piotr Bojanowski", "Armand Joulin", "Matthijs Douze", "Ishan Misra", "Julien Mairal", "Priya Goyal", "Hugo Touvron", "Herve Jegou", "Simon Kornblith", "Kevin Swersky", "Mohammad Norouzi", "Geoffrey Hinton", "Pattern Recognition", "Ekin D. Cubuk", "Barret Zoph", "Dandelion Mane", "Vijay Vasudevan", "Quoc V. Le", "Denton", "J. Weston", "User", "Wang", "Global Challenges", "Piotr Doll", "Mannat Singh", "Ross Girshick", "Fast", "Jeff Donahue", "Jia", "Oriol Vinyals", "Judy Hoffman", "Eric Tzeng", "Trevor Darrell", "Machine Learning", "Alexey Dosovitskiy", "Dirk Weissenborn", "Thomas Unterthiner", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Haoqi Fan", "Bo Xiong", "Karttikeya Mangalam", "Yanghao Li", "Zhicheng Yan", "Jitendra Malik", "Christoph Feichtenhofer", "Multiscale", "Bradford Books", "Soleil", "Esth", "Deepti Ghadiyaram", "Du Tran", "Dhruv Mahajan", "Largescale", "Spyros Gidaris", "Praveer Singh", "Nikos Komodakis", "Benjamin Lefaudeux", "Min Xu", "Pengchao Wang", "Vivek Pai", "Vitaliy Liptchinsky", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Florian Strub", "Florent Altch", "Corentin Tallec", "Pierre H. Richemond", "Elena Buchatskaya", "Carl Doersch", "Bernardo Avila Pires", "Zhaohan Daniel Guo", "Mohammad Gheshlaghi Azar", "Bilal Piot", "Koray Kavukcuoglu", "Remi Munos", "Michal Valko", "Shuai Liu", "Adam Kortylewski", "Cheng Yang", "Yutong Bai", "Changhu Wang", "Alan Yuille", "Transfg", "Yuxin Wu", "Momentum", "Georgia Gkioxari", "Ross Gir", "Mask", "Van Horn", "Pietro Perona", "Li Shen", "Gang Sun", "Zhuang Liu", "Laurens Van Der Maaten", "Kilian Q Weinberger", "Gao Huang", "Yu Sun", "Daniel Sedra", "Kilian Weinberger", "Chao Jia", "Yinfei Yang", "Ye Xia", "Zarana Parekh", "Hieu Pham", "Yunhsuan Sung", "Zhen Li", "Tom Duerig", "Joulin", "Will Kay", "Joao Carreira", "Karen Simonyan", "Brian Zhang", "Chloe Hillier", "Sudheendra Vijayanarasimhan", "Fabio Viola", "Tim Green", "Trevor Back", "Paul Natsev", "Mustafa Suleyman", "Andrew Zisserman", "Vahid Kazemi", "Ali Elqursh", "Show", "Joan Puigcerver", "Jessica Yung", "Neil Houlsby", "Jonathon Shlens", "Lampert", "Ang Li", "Allan Jabri", "Xiujun Li", "Xi Yin", "Chunyuan Li", "Pengchuan Zhang", "Lei Zhang", "Lijuan Wang", "Houdong Hu", "Yejin Choi", "Jianfeng Gao", "Oscar", "Ilya Loshchilov", "Frank Hutter", "Vignesh Ramanathan", "Manohar Paluri", "Yixuan Li", "Ashwin Bharambe", "Tomas Mikolov", "Kai Chen", "Greg S Corrado", "Jeff Dean", "Hinton", "John Platt", "Margin Classifiers", "Polyak", "Branson", "Technical Report", "Huiyu Wang", "Yukun Zhu", "Hartwig Adam", "Ross Wightman", "Cihang Xie", "Boqing Gong", "Jiang Wang", "Alan L Yuille", "Quoc V Le", "Qizhe Xie", "Eduard Hovy", "Zhuowen Tu", "Muhammad Bilal Zafar", "Isabel Valera", "Manuel Gomez Rodriguez", "Krishna P. Gummadi", "Hongyi Zhang", "Moustapha Cisse", "Yann N Dauphin", "David", "Zhifei Zhang", "Yang Song", "Hairong Qi", "Bolei Zhou", "Agata Lapedriza", "Aditya Khosla", "Aude Oliva", "Antonio Torralba", "Pattern Analysis", "Machine Intelligence", "Prabhu", "Filip Radenovic", "Animesh Sinha", "Albert Gordo", "Tamara Berg", "Jong Wook Kim", "Chris Hallacy", "Gabriel Goh", "Pamela Mishkin", "Gretchen Learning", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Ali Sharif Razavian", "Hossein Azizpour", "Josephine Sullivan", "Stefan Carlsson", "Pattern Recognition Workshops", "Benjamin Recht", "Rebecca Roelofs", "Ludwig Schmidt", "Vaishaal Shankar", "Jian Sun", "Faster", "Emanuel Ben-Baruch", "Asaf Noy", "Lihi", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei", "Gunnar A. Sigurdsson", "Aida Nematzadeh", "Lucas Smaira", "Mateusz Malinowski", "Phil Blunsom", "Visual", "Quoc Le", "Andrea Vedaldi", "Herv", "Oisin Mac Aodha", "Yin Cui", "Chen Sun", "Alex Shepard", "Serge Belongie", "Details Hashtag Filtering", "Python", "Ii", "Next", "Model Complexity", "Speed Table", "Model Resolution Flops Params Acts", "Model", "Hyperparameter Selection", "Model Res", "Throughput Classification", "Dataset Size", "Dataset Epochs Samples Name", "Akin", "Results", "Classy Vision", "Likewise", "Weakly", "Platt", "Net F.1", "Hashtag", "Accuracy", "Broader Impact", "Due", "Brazil", "Skin Tone", "Arab EmiratesArgentinaBrazilColombiaEgyptIndonesiaIndiaJapanSouth", "Black", "Fitzpatrick", "Having"], "organizations": ["Curran Associates", "Shmargaret Shmitchell", "ACM Conference", "Fairness", "Accountability", "ImageNet", "modarXiv", "Computer Vision", "KDD", "CVPR Workshop", "recogniIn International Conference", "TransarXiv", "Christiane Fellbaum", "Electronic Lexical Database", "UAI", "arXiv", "IEEE", "Gao Huang", "European Conference", "ECCV", "IEEE Conference", "International Conference", "ICCV", "IEEE International Conference", "XiaoWei Hu", "CVPR", "SIAM Journal", "Control", "segIn", "arXiv 2012.00759", "Mingxing Tan", "AIMechanisms", "IEEE Transactions", "viKrueger", "CNN", "CVPRW", "PMLR", "Tal Ridnik", "Olga Russakovsky", "ImageNet Large Scale Visual", "IJCV", "groundIn", "US", "WordNet", "MIN_LEN", "ALLOWED_SENSES", "FLOPs", "Complexity", "GPUs", "EfficientNets", "SGD", "ViTs", "AdamW", "ViT", "Convolutional Model", "RegNetY", "FLOPs Param", "ResNeXt", "DenseNet", "SE", "EfficientNet", "IG", "Parameters Due", "GFLOPs", "EMA", "iNat", "Supervised", "EfficientNet L2", "EfficientNet B7", "EfficientNet B6", "EfficientNet B8", "ImageNet1k", "ReaL", "JFT", "UTK Faces", "AmericaSouth"], "locations": [], "genpurp": []}}{"title": ["The Compton Amplitude, lattice QCD and the Feynman-Hellmann approach"], "authors": ["[arxiv.Result.Author('K. U. Can'), arxiv.Result.Author('A. Hannaford-Gunn'), arxiv.Result.Author('R. Horsley'), arxiv.Result.Author('Y. Nakamura'), arxiv.Result.Author('H. Perlt'), arxiv.Result.Author('P. E. L. Rakow'), arxiv.Result.Author('E. Sankey'), arxiv.Result.Author('G. Schierholz'), arxiv.Result.Author('H. St\u00fcben'), arxiv.Result.Author('R. D. Young'), arxiv.Result.Author('J. M. Zanotti')]"], "link": ["http://arxiv.org/pdf/2201.08367v1"], "summary": "A major objective of lattice QCD is the computation of hadronic matrix\nelements. The standard method is to use three-point and four-point correlation\nfunctions. An alternative approach, requiring only the computation of two-point\ncorrelation functions is to use the Feynman-Hellmann theorem. In this talk we\ndevelop this method up to second order in perturbation theory, in a context\nappropriate for lattice QCD. This encompasses the Compton Amplitude (which\nforms the basis for deep inelastic scattering) and hadron scattering. Some\nnumerical results are presented showing results indicating what this approach\nmight achieve.", "entities_include_in_text": null, "entities": {"persons": ["Phys", "Wilson", "Adv", "High Energy Phys", "Nucleon Structure Functions", "Operator Product Expansion", "Lett", "Elementary Particle Physics", "Wiley", "Lamb", "Nucl", "Tensor Charges", "Suppl"], "organizations": ["Introduction", "GPDs", "TMDs", "Lattice", "SciPost Physics Submission", "Compton", "Feynman Hellmann", "QCD", "PoS", "Physics", "Standard Model", "BQCD Hybrid Monte Carlo", "EPJ", "Chroma"], "locations": [], "genpurp": []}}{"title": ["Mathematics and Mathematics Education in the 21st Century"], "authors": ["[arxiv.Result.Author('Alexandre Borovik'), arxiv.Result.Author('Zoltan Kocsis'), arxiv.Result.Author('Vladimir Kondratiev')]"], "link": ["http://arxiv.org/pdf/2201.08364v1"], "summary": "Mathematics enters the period of change unprecedented in its history, perhaps\neven a revolution: a switch to use of computers as assistants and checkers in\nproduction of proofs. This requires rethinking traditional approaches to\nmathematics education which is struggling through a crisis of its own,\nsocio-economic and political by its nature. The mathematical community faces\nPandora's box of problems, which, surprisingly, are not usually discussed in\nany connected form. The present paper attempts to address this issue in a bit\nmore joint and cohesive way.", "entities_include_in_text": null, "entities": {"persons": ["Alisher S. Abdullayev", "Gavin Newsom", "Tony Thurmond", "Glen S. Aikenhead", "Math", "Techn", "Igor Vladimirovich Arnold", "Izvesiya APN", "John Baez", "Topos Institute Colloquium", "Alexandre Borovik", "P SL2", "Alexandre V. Borovik", "Mathematics", "Springer International Publishing", "Cham", "Economy", "Springer", "Inna Capdeboscq", "Daniel Gorenstein", "Richard Lyons", "Ronald Solomon", "Part", "Mathematical Surveys", "Joseph Capek", "Karel Capek", "Albatros", "Davide Castelvecchi", "Philip Davis", "Reuben Hersh", "Nicolaas Govert de Bruijn", "Springer Berlin Heidelberg", "Berlin", "Heidelberg", "Paul Ernest", "Albany", "Slava Gerovitch", "Kritika", "Thomas Hales", "Mark Adams", "Gertrud Bauer", "Tat Dat Dange", "John Harrison", "Le Truong Hoang", "Cezary Kaliszyk", "Victor Magron", "Sean McLaughlin", "Tat Thang Nguyen", "Quang Truong Nguyen", "Tobias Nipkow", "Steven Obua", "Joseph Pleso", "Jason Rute", "Alexey Solovyev", "Thi Hoai An Ta", "Nam Trung Tran", "Thi Diep Trieu", "Josef Urban", "Ky Vu", "Mikhail M. Kapranov", "Vladimir A. Voevodsky", "Diff", "Asaf Karagila", "Mathematics Stack Exchange", "Vladimir Khalin", "Nikolai Vavilov", "Alexander Yurkov", "Donald E. Knuth", "Vol", "Zoltan Kocsis", "Manchester", "Nikolay N. Konstantinov", "Alexei L. Semenov", "Chebyshevskii Sbornik", "Jeff Kramer", "Vadim", "Krutetskii", "Teller", "Edward Nelson", "Sankhya", "Series A", "Yuri", "Neretin", "Model Checking", "Abstract Interpretation", "Ulf Persson", "Soc", "Magazine", "Vladimir A. Rokhlin", "Topology", "Peter Scholze", "Xena Project", "Fritz Schweiger", "Brill Sense", "Anna Sfard", "Patrick W. Thompson", "Mathematics EducationNorth America", "Plenary Sessions", "Baton Rouge LA", "Louisiana State University", "Igor Sharygin", "Otech", "Carlos Simpson", "Cambridge University Press", "Stehelin", "George Szpiro", "Certified Programs", "Matthew Towers", "Vladimir", "Voevodsky", "Programme Proposal", "Advanced Study", "Kirk Weller", "Anne Brown", "Ed Dubinskyn", "Michael McDonald", "Cynthia Stenger", "Notices", "Langdon Winner", "Higher School"], "organizations": ["Equitable Math Instruction", "State", "State Board", "Instructional Quality Commission", "Philosophy", "Mathematical Education", "Principles", "De Morgan", "Kolmogorov", "USSR", "Journal", "Microscope", "Mathematical Practice", "RI", "Monographs", "Long Cat Tale", "MATHEMATICS", "CENTURY", "Nature", "State University", "NY", "Kepler Conjecture", "Cahiers", "Cat", "NFU", "Development", "Department", "Commun", "University", "Statistics", "LSD", "International Conference", "VMCAI12", "Fundamental", "Monterrey", "International Commission", "Mathematical Instruction", "ALEXANDRE", "ZOLTAN", "AND", "VLADIMIR", "Anuual Meeting", "International Group", "Psychology", "California Department", "Mathematics Framework", "Community", "Lean", "ACM", "PLAN International Conference", "MathOverflow", "Univalent Foundations", "Institute", "Intima", "AMS", "UK Email"], "locations": [], "genpurp": []}}{"title": ["Physics-informed neural networks for modeling rate- and temperature-dependent plasticity"], "authors": ["[arxiv.Result.Author('Rajat Arora'), arxiv.Result.Author('Pratik Kakkar'), arxiv.Result.Author('Biswadip Dey'), arxiv.Result.Author('Amit Chakraborty')]"], "link": ["http://arxiv.org/pdf/2201.08363v1"], "summary": "This work presents a physics-informed neural network based framework to model\nthe strain-rate and temperature dependence of the deformation fields\n(displacement, stress, plastic strain) in elastic-viscoplastic solids. A\ndetailed discussion on the construction of the physics-based loss criterion\nalong with a brief outline on ways to avoid unbalanced back-propagated\ngradients during training is also presented. We also present a simple strategy\nwith no added computational complexity for choosing scalar weights that balance\nthe interplay between different terms in the composite loss. Moreover, we also\nhighlight a fundamental challenge involving selection of appropriate model\noutputs so that the mechanical problem can be faithfully solved using neural\nnetworks. Finally, the effectiveness of the proposed framework is demonstrated\nby studying two test problems modeling the elastic-viscoplastic deformation in\nsolids at different strain-rates and temperatures, respectively.", "entities_include_in_text": null, "entities": {"persons": ["European Journal", "Xiaohan Zhang", "Amit Acharya", "Finite", "Fleck", "Muller", "Strain", "Acta Metallurgica", "Niordson", "Lynggaard", "Structures", "Shear", "Science", "Carnegie Mellon University", "Christian Miehe", "Fabian Welschinger", "Martina Hofacker", "Michael J Borden", "Thomas JR Hughes", "Chad M Landis", "Clemens V Verhoosel", "Luo Zhirong", "Huang Lilin", "Mao Hong", "Huang Chuanggao", "Lin Kui", "Phase", "Pedro Areias", "Timon Rabczuk", "Charlotte Kuhn", "Ralf M", "Engi", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "Alban Desmaison", "Andreas Kopf", "Edward Yang", "Zachary DeVito", "Martin Raison", "Alykhan Tejani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala", "Fox", "Garnett", "Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S. Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Ian Goodfellow", "Andrew Harp", "Geoffrey Irving", "Michael Isard", "Jia", "Rafal Jozefowicz", "Lukasz Kaiser", "Manjunath Kudlur", "Josh Levenberg", "Dandelion Man", "Rajat Monga", "Sherry Moore", "Derek Murray", "Chris Olah", "Mike Schuster", "Jonathon Shlens", "Ilya Sutskever", "Kunal Talwar", "Paul Tucker", "Vincent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng", "Software", "Keras", "George Cybenko", "Aristidis Likas", "Aristidis C Likas", "Dimitris G Papageorgiou", "Networks", "Maziar Raissi", "Paris Perdikaris", "George Em Karniadakis", "Physics", "George E Karniadakis", "Han Gao", "Shaowu Pan", "Hao Sun", "Yang Liu", "Applied Mechanics Letters", "Xiaowei Jin", "Shengze Cai", "Hui Li", "Luning Sun", "Georgios Kissas", "Yibo Yang", "Eileen Hwuang", "Walter R Witschey", "John A Detre", "Machine", "Daniel E Hurtado", "Ellen Kuhl", "Kousuke Tachida", "Reese Jones", "Machine Learning", "Panos Stinis", "Alexandre Tartakovsky", "Zhang", "Minglang Yin", "Zhu", "Zeliang Liu", "Jinhui Yan", "Daniele Versino", "Alberto Tonda", "Curt A Bronkhorst", "Data", "Zhiyong Li", "Huaibao Zhang", "Sean CC Bailey", "Jesse B Hoagg", "Alexandre Martin", "Francisco Chinesta", "Rafael G", "Nathan Kutz", "Rendus M", "Steven L Brunton", "Bart Van Merri", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio", "W Chen", "K Ehmann", "Jian Cao", "Diab W. Abueidda", "Seid Koric", "Nahil A. Sobh", "Huseyin Sehitoglu", "Deep", "Effects", "Strain Rate", "Applied Mechanics", "Dengpeng Huang", "Jan Niklas Fuhg", "Christian Weienfels", "Peter Wriggers", "Gorji", "Mojtaba Mozaffar", "Julian N. Heidenreich", "Dirk Mohr", "Morton E. Gurtin", "Eliot Fried", "Lallit Anand", "Cambridge University Press", "Sooraj Narayan", "A1092", "William S LePage", "Yuxin Chen", "Eric Kazyak", "Adrian J Sanchez", "Andrea Poli", "Ellen M Arruda", "Neil P Dasgupta", "D Pal", "Materials Processing Technology", "Wang", "Yujun Teng", "Rafael Bischof", "Michael Kraus", "Jimmy Ba", "Adam", "Math", "Marian Czarnecki", "Simon Osindero", "Max Jaderberg", "Grzegorz Swirszcz", "Sobolev", "Razvan Pascanu"], "organizations": ["Computer Methods", "Mechanics", "Physics", "SSD", "GND", "International Journal", "Computational Approximation", "Mesoscale Field Dislocation", "PhD", "International", "MA3574977 Msekh", "Fracture Mechanics", "PyIn", "Curran Associates", "IEEE", "methIEEE Transactions", "Computational Physics", "Technology", "Computational Mechanics", "Methods", "R Bostanabad", "MA Bessa", "National Academy", "LSTM Networks", "Temperature History", "Continua", "Electrochemical Society", "MD Thouless", "JK", "JMLR Workshop", "Conference Proceedings", "Method", "Stochastic Optimization", "ICLR", "ACM Trans", "arXiv"], "locations": [], "genpurp": []}}{"title": ["Stitch it in Time: GAN-Based Facial Editing of Real Videos"], "authors": ["[arxiv.Result.Author('Rotem Tzaban'), arxiv.Result.Author('Ron Mokady'), arxiv.Result.Author('Rinon Gal'), arxiv.Result.Author('Amit H. Bermano'), arxiv.Result.Author('Daniel Cohen-Or')]"], "link": ["http://arxiv.org/pdf/2201.08361v1"], "summary": "The ability of Generative Adversarial Networks to encode rich semantics\nwithin their latent space has been widely adopted for facial image editing.\nHowever, replicating their success with videos has proven challenging. Sets of\nhigh-quality facial videos are lacking, and working with videos introduces a\nfundamental barrier to overcome - temporal coherency. We propose that this\nbarrier is largely artificial. The source video is already temporally coherent,\nand deviations from this state arise in part due to careless treatment of\nindividual components in the editing pipeline. We leverage the natural\nalignment of StyleGAN and the tendency of neural networks to learn low\nfrequency functions, and demonstrate that they provide a strongly consistent\nprior. We draw on these insights and propose a framework for semantic editing\nof faces in videos, demonstrating significant improvements over the current\nstate-of-the-art. Our method produces meaningful face manipulations, maintains\na higher degree of temporal consistency, and can be applied to challenging,\nhigh quality, talking head videos which current methods struggle with.", "entities_include_in_text": null, "entities": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["The Specialized High-Performance Network on Anton 3"], "authors": ["[arxiv.Result.Author('Keun Sup Shim'), arxiv.Result.Author('Brian Greskamp'), arxiv.Result.Author('Brian Towles'), arxiv.Result.Author('Bruce Edwards'), arxiv.Result.Author('J. P. Grossman'), arxiv.Result.Author('David E. Shaw')]"], "link": ["http://arxiv.org/pdf/2201.08357v1"], "summary": "Molecular dynamics (MD) simulation, a computationally intensive method that\nprovides invaluable insights into the behavior of biomolecules, typically\nrequires large-scale parallelization. Implementation of fast parallel MD\nsimulation demands both high bandwidth and low latency for inter-node\ncommunication, but in current semiconductor technology, neither of these\nproperties is scaling as quickly as intra-node computational capacity. This\ndisparity in scaling necessitates architectural innovations to maximize the\nutilization of computational units. For Anton 3, the latest in a family of\nhighly successful special-purpose supercomputers designed for MD simulations,\nwe thus designed and built a completely new specialized network as part of our\nASIC. Tightly integrating this network with specialized computation pipelines\nenables Anton 3 to perform simulations orders of magnitude faster than any\ngeneral-purpose supercomputer, and to outperform its predecessor, Anton 2 (the\nstate of the art prior to Anton 3), by an order of magnitude. In this paper, we\npresent the three key features of the network that contribute to the high\nperformance of Anton 3. First, through architectural optimizations, the network\nachieves very low end-to-end inter-node communication latency for fine-grained\nmessages, allowing for better overlap of computation and communication. Second,\nnovel application-specific compression techniques reduce the size of most\nmessages sent between nodes, thereby increasing effective inter-node bandwidth.\nLastly, a new hardware synchronization primitive, called a network fence,\nsupports fast fine-grained synchronization tailored to the data flow within a\nparallel MD application. These application-driven specializations to the\nnetwork are critical for Anton 3's MD simulation performance advantage over all\nother machines.", "entities_include_in_text": null, "entities": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition"], "authors": ["[arxiv.Result.Author('Chao-Yuan Wu'), arxiv.Result.Author('Yanghao Li'), arxiv.Result.Author('Karttikeya Mangalam'), arxiv.Result.Author('Haoqi Fan'), arxiv.Result.Author('Bo Xiong'), arxiv.Result.Author('Jitendra Malik'), arxiv.Result.Author('Christoph Feichtenhofer')]"], "link": ["http://arxiv.org/pdf/2201.08383v1"], "summary": "While today's video recognition systems parse snapshots or short clips\naccurately, they cannot connect the dots and reason across a longer range of\ntime yet. Most existing video architectures can only process <5 seconds of a\nvideo without hitting the computation or memory bottlenecks.\n  In this paper, we propose a new strategy to overcome this challenge. Instead\nof trying to process more frames at once like most existing methods, we propose\nto process videos in an online fashion and cache \"memory\" at each iteration.\nThrough the memory, the model can reference prior context for long-term\nmodeling, with only a marginal cost. Based on this idea, we build MeMViT, a\nMemory-augmented Multiscale Vision Transformer, that has a temporal support 30x\nlonger than existing models with only 4.5% more compute; traditional methods\nneed >3,000% more compute to do the same. On a wide range of settings, the\nincreased temporal support enabled by MeMViT brings large gains in recognition\naccuracy consistently. MeMViT obtains state-of-the-art results on the AVA,\nEPIC-Kitchens-100 action classification, and action anticipation datasets. Code\nand models will be made publicly available.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Sami Abu-El-Haija", "Nisarg Kothari", "Joonseok Lee", "Paul Natsev", "George Toderici", "Balakrishnan Varadarajan", "Anurag Arnab", "Mostafa Dehghani", "Georg Heigold", "Chen Sun", "Mario Luci", "Gedas Bertasius", "Heng Wang", "Lorenzo Torresani", "Joao Carreira", "Eric Noland", "Andras Banki-Horvath", "Chloe Hillier", "Andrew Zisserman", "Carreira", "Viorica Patraucean", "Laurent Mazare", "Simon Osindero", "Shoufa Chen", "Peize Sun", "Enze Xie", "Chongjian Ge", "Jiannan Wu", "Lan Ma", "Jiajun Shen", "Luo", "Watch", "Yihong Chen", "Yue Cao", "Han Hu", "Liwei Wang", "Memory", "Zhengsu Chen", "Lingxi Xie", "Jianwei Niu", "Xuefeng Liu", "Longhui Wei", "Qi Tian", "Chi Zhang", "Yichen Wei", "Jiang", "Sparse", "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V Le", "Ruslan Salakhutdinov", "Navneet Dalal", "Bill Triggs", "Dima Damen", "Hazel Doughty", "Giovanni Maria Farinella", "Sanja Fidler", "Antonino Furnari", "Evangelos Kazakos", "Davide Moltisanti", "Jonathan Munro", "Toby Perrett", "Will Price", "Michael Wray", "Jia Deng", "Wei Dong", "Richard Socher", "Kai Li", "Li Fei-Fei", "Piotr Doll", "Vincent Rabaud", "Garrison Cottrell", "Serge Belongie", "Behavior", "Visual Surveillance", "Jeff Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Trevor Darrell", "Xiaoyi Dong", "Jianmin Bao", "Dongdong Chen", "Weiming Zhang", "Nenghai Yu", "Lu Yuan", "Dong Chen", "Cswin", "Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Matthias Minderer", "Sylvain Gelly", "Alexei A Efros", "Alexander C Berg", "Greg Mori", "Haoqi Fan", "Yanghao Li", "Bo Xiong", "Christoph Feichtenhofer", "Karttikeya Mangalam", "Zhicheng Yan", "Jitendra Malik", "Multiscale", "Sebastiano Battiato", "Giovanni Farinella", "Rohit Girdhar", "Carl Doersch", "Video", "Kristen Grauman", "Anticipative Video Transformer", "Deva Ramanan", "Abhinav Gupta", "Josef Sivic", "Bryan Russell", "Ross Girshick", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Jia", "Benjamin Graham", "Alaaeldin El-Nouby", "Hugo Touvron", "Pierre Stock", "Armand Joulin", "Herve Jegou", "Matthijs Douze", "Chunhui Gu", "David A. Ross", "Carl Vondrick", "Caroline Pantofaru", "Li", "Sudheendra Vijayanarasimhan", "Susanna Ricco", "Rahul Sukthankar", "Cordelia Schmid", "Efstratios Gavves", "Boyuan Jiang", "Weihao Gan", "Wei Wu", "Junjie Yan", "Will Kay", "Karen Simonyan", "Brian Zhang", "Fabio Viola", "Tim Green", "Trevor Back", "Alexander Klaser", "Marcin Marszaek", "Dan Kondratyuk", "Liangzhe Yuan", "Li Zhang", "Matthew Brown", "Bruno Korbar", "Du Tran", "Scsampler", "Ivan Laptev", "Marcin Marszalek", "Benjamin Rozenfeld", "Sangmin Lee", "Hak Gu Kim", "Dae Hwi Choi", "Kim", "Yong Man Ro", "Sangho Lee", "Jinyoung Sung", "Youngjae Yu", "Gunhee Kim", "Dong Li", "Zhaofan Qiu", "Qi Dai", "Ting Yao", "Tao Mei", "Tushar Nagarajan", "Improved", "Zhenyang Li", "Kirill Gavrilyuk", "Mihir Jain", "Image Understanding", "Chuang Gan", "Song Han", "Bharath Hariharan", "Feature", "Mason Liu", "Yutong Lin", "Yixuan Wei", "Zheng Zhang", "Stephen Lin", "Swin", "Ilya Loshchilov", "Frank Hutter", "Daniel Neimark", "Omri Bar", "Maya Zohar", "Dotan AsarXiv", "Joe", "Matthew Hausknecht", "Oriol Vinyals", "Rajat Monga", "Beyond", "Siyu Chen", "Mike Zheng Shou", "Yu Liu", "Jing Shao", "Hongsheng Li", "Mandela Patrick", "Dylan Campbell", "Yuki M Asano", "Ishan Misra Florian Metze", "Andrea Vedaldi", "Jo Henriques", "Xiaojiang Peng", "Yu Qiao", "Qiang Peng", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Jack W Rae", "Anna Potapenko", "Timothy P Lillicrap", "Ali Razavi", "Jian Sun", "Faster", "Fadime Sener", "Dibyadip Chatterjee", "Angela Yao", "Peter Shaw", "Jakob Uszkoreit", "Ashish Vaswani", "Edouard Grave", "Piotr Bojanowski", "Adaptive", "Da Ju", "Spencer Poff", "Stephen Roller", "Arthur Szlam", "Jason Weston", "Angela Fan", "Kui Jia", "Kevin Chen", "Bertram E Shi", "Silvio Savarese", "Jingru Tan", "Changbao Wang", "Buyu Li", "Quanquan Li", "Wanli Ouyang", "Gang Zhang", "Hanming Deng", "Lewei Lu", "Jifeng Dai", "Jiajun Tang", "Jin Xia", "Xinzhi Mu", "Bo Pang", "Cewu Lu", "Graham W Taylor", "Rob Fergus", "Yann LeCun", "Christoph Bregler", "Matthieu Cord", "Francisco Massa", "Alexandre Sablayrolles", "Gabriel Synnaeve", "Herv", "Lubomir Bourdev", "Manohar Paluri", "Matt Feiszli", "Noam Shazeer", "Niki Parmar", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin", "Alexander Kl", "Dense", "Muhammad Muneeb Ullah", "Limin Wang", "Xiaoou Tang", "Yuanjun Xiong", "Zhe Wang", "Dahua Lin", "Luc Val Gool", "Wenhai Wang", "Xiang Li", "Kaitao Song", "Ding Liang", "Tong Lu", "Ping Luo", "Pyramid", "Xiaolong Wang", "Xiaohan Wang", "Linchao Zhu", "Yi Yang", "Philipp Kr", "Philipp Krahenbuhl", "Towards", "Manzil Zaheer", "Hexiang Hu", "Alexander J Smola", "Zhuowen Tu", "Jonathan Huang", "Kevin Murphy", "Yunpeng Chen", "Tao Wang", "Weihao Yu", "Yujun Shi", "Francis EH Tay", "Jiashi Feng", "Shuicheng Yan", "Bolei Zhou", "Alex Andonian", "Aude Oliva", "Antonio TorIn ECCV", "Xizhou Zhu", "Yujie Wang", "Kamaljeet Singh", "Thomas Brox"], "organizations": ["Sudheendra Vijayanarasimhan", "Cordelia Schmid", "ICCV", "ECCV", "CVPR", "ACM", "ACL", "PAMI", "International Workshop", "Performance Evaluation", "Kate Saenko", "ICLR", "ECCV Workshops", "Priya Goyal", "ConvNets", "Noureldien Hussein", "Arnold", "MengMeng Wang", "Yandong Li", "Mingxing Tan", "Yanghao Li", "Cees", "VideoLSTM", "Computer Vision", "Menglong Zhu", "detecIn Proc", "Siddhant", "TecharXiv", "ICML", "IJCV", "R Manmatha"], "locations": [], "genpurp": []}}{"title": ["Learning Pixel Trajectories with Multiscale Contrastive Random Walks"], "authors": ["[arxiv.Result.Author('Zhangxing Bian'), arxiv.Result.Author('Allan Jabri'), arxiv.Result.Author('Alexei A. Efros'), arxiv.Result.Author('Andrew Owens')]"], "link": ["http://arxiv.org/pdf/2201.08379v1"], "summary": "A range of video modeling tasks, from optical flow to multiple object\ntracking, share the same fundamental challenge: establishing space-time\ncorrespondence. Yet, approaches that dominate each space differ. We take a step\ntowards bridging this gap by extending the recent contrastive random walk\nformulation to much denser, pixel-level space-time graphs. The main\ncontribution is introducing hierarchy into the search problem by computing the\ntransition matrix between two frames in a coarse-to-fine manner, forming a\nmultiscale contrastive random walk when extended in time. This establishes a\nunified technique for self-supervised learning of optical flow, keypoint\ntracking, and video object segmentation. Experiments demonstrate that, for each\nof these tasks, the unified model achieves performance competitive with strong\nself-supervised approaches specific to that task. Project site:\nhttps://jasonbian97.github.io/flowwalk", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Robert Anderson", "David Gallup", "Jonathan T Barron", "Janne Kontkanen", "Noah Snavely", "Carlos Hern", "Sameer Agarwal", "Steven M Seitz", "Jump", "Simon Baker", "Iain Matthews", "Daniel Scharstein", "Stefan Roth", "Michael J Black", "Richard Szeliski", "Paul Anandan", "Thomas Brox", "Christoph Bregler", "Jitendra Malik", "Large", "Andr", "Bruhn", "Nils Papenberg", "Joachim Weickert", "Object", "Springer", "Brain Schunck", "Zhaoyang Huang", "Xiaokun Pan", "Runsen Xu", "Kachun Cheung", "Guofeng Zhang", "Hongsheng Li", "Mirrorflow", "Eddy Ilg", "Nikolaus Mayer", "Tonmoy Saikia", "Margret Keuper", "Alexey Dosovitskiy", "Allan Jabri", "Andrew Owens", "Alexei A Efros", "Max Jaderberg", "Karen Simonyan", "Andrew Zisserman", "Koray Kavukcuoglu", "Joel Janai", "Fatma G", "Anurag Ranjan", "Michael Black", "Andreas Geiger", "Michael J", "Black", "Fatma Guney", "Jonas Wulff", "Slow", "Pattern Recognition", "Hueihan Jhuang", "Juergen Gall", "Silvia Zuffi", "Cordelia Schmid", "Rico Jonschkowski", "Austin Stone", "Ariel Gordon", "Kurt Konolige", "Anelia Angelova", "Ryan Kennedy", "Camillo J Taylor", "Optical", "Diederik P Kingma", "Jimmy Ba", "Adam", "Zihang Lai", "Erika Lu", "Weidi Xie", "Mast", "Cheng Lei", "Li", "Sifei Liu", "Shalini De Mello", "Xiaolong Wang", "Jan Kautz", "Yunpeng Li", "Daniel P Huttenlocher", "Massachusetts Institute", "Liang Liu", "Jiangning Zhang", "Yong Liu", "Yabiao Wang", "Tai", "Donghao Luo", "Chengjie Wang", "Jilin Li", "Feiyue Huang", "Pengpeng Liu", "Irwin King", "Michael R Lyu", "Jia Xu", "Ddflow", "Michael R. Lyu", "Michael Lyu", "Selflow", "Bruce D Lucas", "Takeo Kanade", "Chuan Wang", "Shuaicheng Liu", "Haoqiang Fan", "Jue Wang", "Jian Sun", "Upflow", "Simon Meister", "Junhwa Hur", "Unflow", "Geoffrey Hinton", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "J. Pont-Tuset", "Van Gool", "Jordi Pont-Tuset", "Federico Perazzi", "Sergi Caelles", "Pablo Arbel", "Alexander Sorkine-Hornung", "Luc Van Gool", "Jerome Revaud", "Philippe Weinzaepfel", "Zaid Harchaoui", "Epicflow", "Dan Rosenbaum", "Daniel Zoran", "Yair Weiss", "Victor Lempitsky", "Carsten Rother", "Visual Motion Analysis", "Michael Rubinstein", "Ce Liu", "William T Freeman", "Towards", "Peter Sand", "Seth Teller", "Particle", "Alexander Shekhovtsov", "Ivan Kovtun", "Hlav", "Image Understanding", "Leslie N Smith", "Nicholay Topin", "Machine Learning", "Daniel Maurer", "Alper Ayvaci", "Smurf", "Erik Sudderth", "Layered", "Daniel Vlasic", "Charles Herrmann", "Varun Jampani", "Michael Krainin", "Huiwen Chang", "Ramin Zabih", "Autoflow", "Xiaodong Yang", "Narayanan Sundaram", "Kurt Keutzer", "Dense", "Zhenyu Jiang", "Zhenda Xie", "Yue Cao", "Zheng Zhang", "Philip HS Torr", "Han Hu", "Jia Deng", "Raft", "Sebastian Volz", "Andres Bruhn", "Levi Valgaerts", "Henning Zimmer", "Carl Vondrick", "Abhinav Shrivastava", "Alireza Fathi", "Sergio Guadarrama", "Kevin Murphy", "Wang", "Heng Wang", "Alexander Kl", "Chao Ma", "Wengang Zhou", "Wei Liu", "Houqiang Li", "Yang Wang", "Yi Yang", "Wei Xu", "Zhongdao Wang", "Hengshuang Zhao", "Philip Torr", "Luca Bertinetto", "Deepflow", "Jiarui Xu", "Li Xu", "Jianing Chen", "Jiaya Jia", "Linjie Yang", "Yuchen Fan", "Dingcheng Yue", "Yuchen Liang", "Jianchao Yang", "Thomas Huang", "Zhichao Yin", "Geonet", "Jason J. Yu", "Adam W. Harley", "Konstantinos G. Derpanis", "Bouguet", "Pyramidal", "Microprocessor", "Research Labs", "Yiran Zhong", "Pan Ji", "Jianyuan Wang", "Yuchao Dai", "Hongdong Li", "Xiaojin Zhu", "Zoubin Ghahramani", "Zitnick", "Nebojsa Jojic", "Yuliang Zou", "Zelun Luo", "Huang", "Hyperparameter Learning", "Temperature Video", "Window Size", "Values", "Chairs", "Sintel D. Additional Qualitative"], "organizations": ["ACM Transactions", "TOG", "International Journal", "Computer Vision", "JP Lewis", "IJCV", "Parametric", "Computer", "Berthold Horn", "Artificial Intelligence", "Yan Xu", "IEEE International Conference", "IEEE", "NeurIPS", "ECCV", "IEEE Conference", "International Workshop", "Energy Minimization Methods", "International Conference", "PhD", "distillaIn Proceedings", "AAAI Conference", "Artificial", "AAAI", "IJCAI", "Roland Memisevic", "Cordelia Schmid", "Geometrical Approaches", "ICCV", "International Society", "Optics", "Photonics", "multiIn Proframe", "Yansong Tang", "Information Science", "International", "Shengjin Wang", "Xiaolong Wang", "ECCV 2016 Workshops", "Part", "Jean", "Intel Corporation", "ICCV05", "Random Walk", "KITTI", "RGB", "Smoothness", "PyTorch", "Adam", "ARflow", "CensusCensus"], "locations": [], "genpurp": []}}{"title": ["Omnivore: A Single Model for Many Visual Modalities"], "authors": ["[arxiv.Result.Author('Rohit Girdhar'), arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Nikhila Ravi'), arxiv.Result.Author('Laurens van der Maaten'), arxiv.Result.Author('Armand Joulin'), arxiv.Result.Author('Ishan Misra')]"], "link": ["http://arxiv.org/pdf/2201.08377v1"], "summary": "Prior work has studied different visual modalities in isolation and developed\nseparate architectures for recognition of images, videos, and 3D data. Instead,\nin this paper, we propose a single model which excels at classifying images,\nvideos, and single-view 3D data using exactly the same model parameters. Our\n'Omnivore' model leverages the flexibility of transformer-based architectures\nand is trained jointly on classification tasks from different modalities.\nOmnivore is simple to train, uses off-the-shelf standard datasets, and performs\nat-par or better than modality-specific models of the same size. A single\nOmnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN\nRGB-D. After finetuning, our models outperform prior work on a variety of\nvision tasks and generalize across modalities. Omnivore's shared visual\nrepresentation naturally enables cross-modal recognition without access to\ncorrespondences between modalities. We hope our results motivate researchers to\nmodel visual modalities together.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Higher Symmetries of 5d Orbifold SCFTs"], "authors": ["[arxiv.Result.Author('Michele Del Zotto'), arxiv.Result.Author('Jonathan J. Heckman'), arxiv.Result.Author('Shani Nadir Meynet'), arxiv.Result.Author('Robert Moscrop'), arxiv.Result.Author('Hao Y. Zhang')]"], "link": ["http://arxiv.org/pdf/2201.08372v1"], "summary": "We determine the higher symmetries of 5d SCFTs engineered from M-theory on a\n$\\mathbb{C}^3 / \\Gamma$ background for $\\Gamma$ a finite subgroup of $SU(3)$.\nThis resolves a longstanding question as to how to extract this data when the\nresulting singularity is non-toric (when $\\Gamma$ is non-abelian) and/or not\nisolated (when the action of $\\Gamma$ has fixed loci). The BPS states of the\ntheory are encoded in a 1D quiver quantum mechanics gauge theory which\ndetermines the possible 1-form and 2-form symmetries. We also show that this\nsame data can also be extracted by a direct computation of the corresponding\ndefect group associated with the orbifold singularity. Both methods agree, and\nthese computations do not rely on the existence of a resolution of the\nsingularity. We also observe that when the geometry faithfully captures the\nglobal 0-form symmetry, the abelianization of $\\Gamma$ detects a 2-group\nstructure (when present). As such, this establishes that all of this data is\nindeed intrinsic to the superconformal fixed point rather than being an\nemergent property of an IR gauge theory phase.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Revisiting Weakly Supervised Pre-Training of Visual Perception Models"], "authors": ["[arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Laura Gustafson'), arxiv.Result.Author('Aaron Adcock'), arxiv.Result.Author('Vinicius de Freitas Reis'), arxiv.Result.Author('Bugra Gedik'), arxiv.Result.Author('Raj Prateek Kosaraju'), arxiv.Result.Author('Dhruv Mahajan'), arxiv.Result.Author('Ross Girshick'), arxiv.Result.Author('Piotr Doll\u00e1r'), arxiv.Result.Author('Laurens van der Maaten')]"], "link": ["http://arxiv.org/pdf/2201.08371v1"], "summary": "Model pre-training is a cornerstone of modern visual recognition systems.\nAlthough fully supervised pre-training on datasets like ImageNet is still the\nde-facto standard, recent studies suggest that large-scale weakly supervised\npre-training can outperform fully supervised approaches. This paper revisits\nweakly-supervised pre-training of models using hashtag supervision with modern\nversions of residual networks and the largest-ever dataset of images and\ncorresponding hashtags. We study the performance of the resulting models in\nvarious transfer-learning settings including zero-shot transfer. We also\ncompare our models with those obtained via large-scale self-supervised\nlearning. We find our weakly-supervised models to be very competitive across\nall settings, and find they substantially outperform their self-supervised\ncounterparts. We also include an investigation into whether our models learned\npotentially troubling associations or stereotypes. Overall, our results provide\na compelling argument for the use of weakly supervised learning in the\ndevelopment of visual recognition systems. Our models, Supervised Weakly\nthrough hashtAGs (SWAG), are available publicly.", "entities_include_in_text": ["CUB-2011"], "entities_from_reference": {"persons": ["Samira Abnar", "Mostafa Dehghani", "Behnam Neyshabur", "Hanie Sedghi", "Adcock", "Singh", "Maaten", "Zhang", "Motwani", "J. Guerin", "Classy", "Hangbo Bao", "Li Dong", "Furu Wei", "Beit", "Bert", "Andrei Barbu", "David Mayo", "Julian Alverio", "William Luo", "Christopher Wang", "Dan Gutfreund", "Josh Tenenbaum", "Boris Katz", "Fox", "Garnett", "Josh Beal", "Dong Huk Park", "Andrew Zhai", "Dmitry Kislyuk", "Emily M. Bender", "Timnit Gebru", "Angelina McMillan-Major", "Lucas Beyer", "Olivier J.", "Alexander Kolesnikov", "Xiaohua Zhai", "Aaron", "Abeba Birhane", "Vinay", "Emmanuel Kahembwe", "Multimodal", "Tom B", "Brown", "Ben Mann", "Nick Ryder", "Melanie Subbiah", "Jared D. Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "Sandhini Agarwal", "Ariel Herbert-Voss", "Gretchen M. Krueger", "Tom Henighan", "Rewon Child", "Aditya Ramesh", "Daniel Ziegler", "Jeffrey Wu", "Clemens Winter", "Chris Hesse", "Mark Chen", "Eric Sigler", "Mateusz Litwin", "Scott Gray", "Benjamin Chess", "Jack Clark", "Christopher Berner", "Sam McCandlish", "Alec Radford", "Ilya Sutskever", "Dario Amodei", "Mathilde Caron", "Piotr Bojanowski", "Armand Joulin", "Matthijs Douze", "Ishan Misra", "Julien Mairal", "Priya Goyal", "Hugo Touvron", "Herve Jegou", "Simon Kornblith", "Kevin Swersky", "Mohammad Norouzi", "Geoffrey Hinton", "Pattern Recognition", "Ekin D. Cubuk", "Barret Zoph", "Dandelion Mane", "Vijay Vasudevan", "Quoc V. Le", "Denton", "J. Weston", "User", "Wang", "Global Challenges", "Piotr Doll", "Mannat Singh", "Ross Girshick", "Fast", "Jeff Donahue", "Jia", "Oriol Vinyals", "Judy Hoffman", "Eric Tzeng", "Trevor Darrell", "Machine Learning", "Alexey Dosovitskiy", "Dirk Weissenborn", "Thomas Unterthiner", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Haoqi Fan", "Bo Xiong", "Karttikeya Mangalam", "Yanghao Li", "Zhicheng Yan", "Jitendra Malik", "Christoph Feichtenhofer", "Multiscale", "Bradford Books", "Soleil", "Esth", "Deepti Ghadiyaram", "Du Tran", "Dhruv Mahajan", "Largescale", "Spyros Gidaris", "Praveer Singh", "Nikos Komodakis", "Benjamin Lefaudeux", "Min Xu", "Pengchao Wang", "Vivek Pai", "Vitaliy Liptchinsky", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Florian Strub", "Florent Altch", "Corentin Tallec", "Pierre H. Richemond", "Elena Buchatskaya", "Carl Doersch", "Bernardo Avila Pires", "Zhaohan Daniel Guo", "Mohammad Gheshlaghi Azar", "Bilal Piot", "Koray Kavukcuoglu", "Remi Munos", "Michal Valko", "Shuai Liu", "Adam Kortylewski", "Cheng Yang", "Yutong Bai", "Changhu Wang", "Alan Yuille", "Transfg", "Yuxin Wu", "Momentum", "Georgia Gkioxari", "Ross Gir", "Mask", "Van Horn", "Pietro Perona", "Li Shen", "Gang Sun", "Zhuang Liu", "Laurens Van Der Maaten", "Kilian Q Weinberger", "Gao Huang", "Yu Sun", "Daniel Sedra", "Kilian Weinberger", "Chao Jia", "Yinfei Yang", "Ye Xia", "Zarana Parekh", "Hieu Pham", "Yunhsuan Sung", "Zhen Li", "Tom Duerig", "Joulin", "Will Kay", "Joao Carreira", "Karen Simonyan", "Brian Zhang", "Chloe Hillier", "Sudheendra Vijayanarasimhan", "Fabio Viola", "Tim Green", "Trevor Back", "Paul Natsev", "Mustafa Suleyman", "Andrew Zisserman", "Vahid Kazemi", "Ali Elqursh", "Show", "Joan Puigcerver", "Jessica Yung", "Neil Houlsby", "Jonathon Shlens", "Lampert", "Ang Li", "Allan Jabri", "Xiujun Li", "Xi Yin", "Chunyuan Li", "Pengchuan Zhang", "Lei Zhang", "Lijuan Wang", "Houdong Hu", "Yejin Choi", "Jianfeng Gao", "Oscar", "Ilya Loshchilov", "Frank Hutter", "Vignesh Ramanathan", "Manohar Paluri", "Yixuan Li", "Ashwin Bharambe", "Tomas Mikolov", "Kai Chen", "Greg S Corrado", "Jeff Dean", "Hinton", "John Platt", "Margin Classifiers", "Polyak", "Branson", "Technical Report", "Huiyu Wang", "Yukun Zhu", "Hartwig Adam", "Ross Wightman", "Cihang Xie", "Boqing Gong", "Jiang Wang", "Alan L Yuille", "Quoc V Le", "Qizhe Xie", "Eduard Hovy", "Zhuowen Tu", "Muhammad Bilal Zafar", "Isabel Valera", "Manuel Gomez Rodriguez", "Krishna P. Gummadi", "Hongyi Zhang", "Moustapha Cisse", "Yann N Dauphin", "David", "Zhifei Zhang", "Yang Song", "Hairong Qi", "Bolei Zhou", "Agata Lapedriza", "Aditya Khosla", "Aude Oliva", "Antonio Torralba", "Pattern Analysis", "Machine Intelligence", "Prabhu", "Filip Radenovic", "Animesh Sinha", "Albert Gordo", "Tamara Berg", "Jong Wook Kim", "Chris Hallacy", "Gabriel Goh", "Pamela Mishkin", "Gretchen Learning", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Ali Sharif Razavian", "Hossein Azizpour", "Josephine Sullivan", "Stefan Carlsson", "Pattern Recognition Workshops", "Benjamin Recht", "Rebecca Roelofs", "Ludwig Schmidt", "Vaishaal Shankar", "Jian Sun", "Faster", "Emanuel Ben-Baruch", "Asaf Noy", "Lihi", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei", "Gunnar A. Sigurdsson", "Aida Nematzadeh", "Lucas Smaira", "Mateusz Malinowski", "Phil Blunsom", "Visual", "Quoc Le", "Andrea Vedaldi", "Herv", "Oisin Mac Aodha", "Yin Cui", "Chen Sun", "Alex Shepard", "Serge Belongie", "Details Hashtag Filtering", "Python", "Ii", "Next", "Model Complexity", "Speed Table", "Model Resolution Flops Params Acts", "Model", "Hyperparameter Selection", "Model Res", "Throughput Classification", "Dataset Size", "Dataset Epochs Samples Name", "Akin", "Results", "Classy Vision", "Likewise", "Weakly", "Platt", "Net F.1", "Hashtag", "Accuracy", "Broader Impact", "Due", "Brazil", "Skin Tone", "Arab EmiratesArgentinaBrazilColombiaEgyptIndonesiaIndiaJapanSouth", "Black", "Fitzpatrick", "Having"], "organizations": ["Curran Associates", "Shmargaret Shmitchell", "ACM Conference", "Fairness", "Accountability", "ImageNet", "modarXiv", "Computer Vision", "KDD", "CVPR Workshop", "recogniIn International Conference", "TransarXiv", "Christiane Fellbaum", "Electronic Lexical Database", "UAI", "arXiv", "IEEE", "Gao Huang", "European Conference", "ECCV", "IEEE Conference", "International Conference", "ICCV", "IEEE International Conference", "XiaoWei Hu", "CVPR", "SIAM Journal", "Control", "segIn", "arXiv 2012.00759", "Mingxing Tan", "AIMechanisms", "IEEE Transactions", "viKrueger", "CNN", "CVPRW", "PMLR", "Tal Ridnik", "Olga Russakovsky", "ImageNet Large Scale Visual", "IJCV", "groundIn", "US", "WordNet", "MIN_LEN", "ALLOWED_SENSES", "FLOPs", "Complexity", "GPUs", "EfficientNets", "SGD", "ViTs", "AdamW", "ViT", "Convolutional Model", "RegNetY", "FLOPs Param", "ResNeXt", "DenseNet", "SE", "EfficientNet", "IG", "Parameters Due", "GFLOPs", "EMA", "iNat", "Supervised", "EfficientNet L2", "EfficientNet B7", "EfficientNet B6", "EfficientNet B8", "ImageNet1k", "ReaL", "JFT", "UTK Faces", "AmericaSouth"], "locations": [], "genpurp": []}}{"title": ["The Compton Amplitude, lattice QCD and the Feynman-Hellmann approach"], "authors": ["[arxiv.Result.Author('K. U. Can'), arxiv.Result.Author('A. Hannaford-Gunn'), arxiv.Result.Author('R. Horsley'), arxiv.Result.Author('Y. Nakamura'), arxiv.Result.Author('H. Perlt'), arxiv.Result.Author('P. E. L. Rakow'), arxiv.Result.Author('E. Sankey'), arxiv.Result.Author('G. Schierholz'), arxiv.Result.Author('H. St\u00fcben'), arxiv.Result.Author('R. D. Young'), arxiv.Result.Author('J. M. Zanotti')]"], "link": ["http://arxiv.org/pdf/2201.08367v1"], "summary": "A major objective of lattice QCD is the computation of hadronic matrix\nelements. The standard method is to use three-point and four-point correlation\nfunctions. An alternative approach, requiring only the computation of two-point\ncorrelation functions is to use the Feynman-Hellmann theorem. In this talk we\ndevelop this method up to second order in perturbation theory, in a context\nappropriate for lattice QCD. This encompasses the Compton Amplitude (which\nforms the basis for deep inelastic scattering) and hadron scattering. Some\nnumerical results are presented showing results indicating what this approach\nmight achieve.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Phys", "Wilson", "Adv", "High Energy Phys", "Nucleon Structure Functions", "Operator Product Expansion", "Lett", "Elementary Particle Physics", "Wiley", "Lamb", "Nucl", "Tensor Charges", "Suppl"], "organizations": ["Introduction", "GPDs", "TMDs", "Lattice", "SciPost Physics Submission", "Compton", "Feynman Hellmann", "QCD", "PoS", "Physics", "Standard Model", "BQCD Hybrid Monte Carlo", "EPJ", "Chroma"], "locations": [], "genpurp": []}}{"title": ["Mathematics and Mathematics Education in the 21st Century"], "authors": ["[arxiv.Result.Author('Alexandre Borovik'), arxiv.Result.Author('Zoltan Kocsis'), arxiv.Result.Author('Vladimir Kondratiev')]"], "link": ["http://arxiv.org/pdf/2201.08364v1"], "summary": "Mathematics enters the period of change unprecedented in its history, perhaps\neven a revolution: a switch to use of computers as assistants and checkers in\nproduction of proofs. This requires rethinking traditional approaches to\nmathematics education which is struggling through a crisis of its own,\nsocio-economic and political by its nature. The mathematical community faces\nPandora's box of problems, which, surprisingly, are not usually discussed in\nany connected form. The present paper attempts to address this issue in a bit\nmore joint and cohesive way.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Alisher S. Abdullayev", "Gavin Newsom", "Tony Thurmond", "Glen S. Aikenhead", "Math", "Techn", "Igor Vladimirovich Arnold", "Izvesiya APN", "John Baez", "Topos Institute Colloquium", "Alexandre Borovik", "P SL2", "Alexandre V. Borovik", "Mathematics", "Springer International Publishing", "Cham", "Economy", "Springer", "Inna Capdeboscq", "Daniel Gorenstein", "Richard Lyons", "Ronald Solomon", "Part", "Mathematical Surveys", "Joseph Capek", "Karel Capek", "Albatros", "Davide Castelvecchi", "Philip Davis", "Reuben Hersh", "Nicolaas Govert de Bruijn", "Springer Berlin Heidelberg", "Berlin", "Heidelberg", "Paul Ernest", "Albany", "Slava Gerovitch", "Kritika", "Thomas Hales", "Mark Adams", "Gertrud Bauer", "Tat Dat Dange", "John Harrison", "Le Truong Hoang", "Cezary Kaliszyk", "Victor Magron", "Sean McLaughlin", "Tat Thang Nguyen", "Quang Truong Nguyen", "Tobias Nipkow", "Steven Obua", "Joseph Pleso", "Jason Rute", "Alexey Solovyev", "Thi Hoai An Ta", "Nam Trung Tran", "Thi Diep Trieu", "Josef Urban", "Ky Vu", "Mikhail M. Kapranov", "Vladimir A. Voevodsky", "Diff", "Asaf Karagila", "Mathematics Stack Exchange", "Vladimir Khalin", "Nikolai Vavilov", "Alexander Yurkov", "Donald E. Knuth", "Vol", "Zoltan Kocsis", "Manchester", "Nikolay N. Konstantinov", "Alexei L. Semenov", "Chebyshevskii Sbornik", "Jeff Kramer", "Vadim", "Krutetskii", "Teller", "Edward Nelson", "Sankhya", "Series A", "Yuri", "Neretin", "Model Checking", "Abstract Interpretation", "Ulf Persson", "Soc", "Magazine", "Vladimir A. Rokhlin", "Topology", "Peter Scholze", "Xena Project", "Fritz Schweiger", "Brill Sense", "Anna Sfard", "Patrick W. Thompson", "Mathematics EducationNorth America", "Plenary Sessions", "Baton Rouge LA", "Louisiana State University", "Igor Sharygin", "Otech", "Carlos Simpson", "Cambridge University Press", "Stehelin", "George Szpiro", "Certified Programs", "Matthew Towers", "Vladimir", "Voevodsky", "Programme Proposal", "Advanced Study", "Kirk Weller", "Anne Brown", "Ed Dubinskyn", "Michael McDonald", "Cynthia Stenger", "Notices", "Langdon Winner", "Higher School"], "organizations": ["Equitable Math Instruction", "State", "State Board", "Instructional Quality Commission", "Philosophy", "Mathematical Education", "Principles", "De Morgan", "Kolmogorov", "USSR", "Journal", "Microscope", "Mathematical Practice", "RI", "Monographs", "Long Cat Tale", "MATHEMATICS", "CENTURY", "Nature", "State University", "NY", "Kepler Conjecture", "Cahiers", "Cat", "NFU", "Development", "Department", "Commun", "University", "Statistics", "LSD", "International Conference", "VMCAI12", "Fundamental", "Monterrey", "International Commission", "Mathematical Instruction", "ALEXANDRE", "ZOLTAN", "AND", "VLADIMIR", "Anuual Meeting", "International Group", "Psychology", "California Department", "Mathematics Framework", "Community", "Lean", "ACM", "PLAN International Conference", "MathOverflow", "Univalent Foundations", "Institute", "Intima", "AMS", "UK Email"], "locations": [], "genpurp": []}}{"title": ["Physics-informed neural networks for modeling rate- and temperature-dependent plasticity"], "authors": ["[arxiv.Result.Author('Rajat Arora'), arxiv.Result.Author('Pratik Kakkar'), arxiv.Result.Author('Biswadip Dey'), arxiv.Result.Author('Amit Chakraborty')]"], "link": ["http://arxiv.org/pdf/2201.08363v1"], "summary": "This work presents a physics-informed neural network based framework to model\nthe strain-rate and temperature dependence of the deformation fields\n(displacement, stress, plastic strain) in elastic-viscoplastic solids. A\ndetailed discussion on the construction of the physics-based loss criterion\nalong with a brief outline on ways to avoid unbalanced back-propagated\ngradients during training is also presented. We also present a simple strategy\nwith no added computational complexity for choosing scalar weights that balance\nthe interplay between different terms in the composite loss. Moreover, we also\nhighlight a fundamental challenge involving selection of appropriate model\noutputs so that the mechanical problem can be faithfully solved using neural\nnetworks. Finally, the effectiveness of the proposed framework is demonstrated\nby studying two test problems modeling the elastic-viscoplastic deformation in\nsolids at different strain-rates and temperatures, respectively.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["European Journal", "Xiaohan Zhang", "Amit Acharya", "Finite", "Fleck", "Muller", "Strain", "Acta Metallurgica", "Niordson", "Lynggaard", "Structures", "Shear", "Science", "Carnegie Mellon University", "Christian Miehe", "Fabian Welschinger", "Martina Hofacker", "Michael J Borden", "Thomas JR Hughes", "Chad M Landis", "Clemens V Verhoosel", "Luo Zhirong", "Huang Lilin", "Mao Hong", "Huang Chuanggao", "Lin Kui", "Phase", "Pedro Areias", "Timon Rabczuk", "Charlotte Kuhn", "Ralf M", "Engi", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "Alban Desmaison", "Andreas Kopf", "Edward Yang", "Zachary DeVito", "Martin Raison", "Alykhan Tejani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala", "Fox", "Garnett", "Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S. Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Ian Goodfellow", "Andrew Harp", "Geoffrey Irving", "Michael Isard", "Jia", "Rafal Jozefowicz", "Lukasz Kaiser", "Manjunath Kudlur", "Josh Levenberg", "Dandelion Man", "Rajat Monga", "Sherry Moore", "Derek Murray", "Chris Olah", "Mike Schuster", "Jonathon Shlens", "Ilya Sutskever", "Kunal Talwar", "Paul Tucker", "Vincent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng", "Software", "Keras", "George Cybenko", "Aristidis Likas", "Aristidis C Likas", "Dimitris G Papageorgiou", "Networks", "Maziar Raissi", "Paris Perdikaris", "George Em Karniadakis", "Physics", "George E Karniadakis", "Han Gao", "Shaowu Pan", "Hao Sun", "Yang Liu", "Applied Mechanics Letters", "Xiaowei Jin", "Shengze Cai", "Hui Li", "Luning Sun", "Georgios Kissas", "Yibo Yang", "Eileen Hwuang", "Walter R Witschey", "John A Detre", "Machine", "Daniel E Hurtado", "Ellen Kuhl", "Kousuke Tachida", "Reese Jones", "Machine Learning", "Panos Stinis", "Alexandre Tartakovsky", "Zhang", "Minglang Yin", "Zhu", "Zeliang Liu", "Jinhui Yan", "Daniele Versino", "Alberto Tonda", "Curt A Bronkhorst", "Data", "Zhiyong Li", "Huaibao Zhang", "Sean CC Bailey", "Jesse B Hoagg", "Alexandre Martin", "Francisco Chinesta", "Rafael G", "Nathan Kutz", "Rendus M", "Steven L Brunton", "Bart Van Merri", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio", "W Chen", "K Ehmann", "Jian Cao", "Diab W. Abueidda", "Seid Koric", "Nahil A. Sobh", "Huseyin Sehitoglu", "Deep", "Effects", "Strain Rate", "Applied Mechanics", "Dengpeng Huang", "Jan Niklas Fuhg", "Christian Weienfels", "Peter Wriggers", "Gorji", "Mojtaba Mozaffar", "Julian N. Heidenreich", "Dirk Mohr", "Morton E. Gurtin", "Eliot Fried", "Lallit Anand", "Cambridge University Press", "Sooraj Narayan", "A1092", "William S LePage", "Yuxin Chen", "Eric Kazyak", "Adrian J Sanchez", "Andrea Poli", "Ellen M Arruda", "Neil P Dasgupta", "D Pal", "Materials Processing Technology", "Wang", "Yujun Teng", "Rafael Bischof", "Michael Kraus", "Jimmy Ba", "Adam", "Math", "Marian Czarnecki", "Simon Osindero", "Max Jaderberg", "Grzegorz Swirszcz", "Sobolev", "Razvan Pascanu"], "organizations": ["Computer Methods", "Mechanics", "Physics", "SSD", "GND", "International Journal", "Computational Approximation", "Mesoscale Field Dislocation", "PhD", "International", "MA3574977 Msekh", "Fracture Mechanics", "PyIn", "Curran Associates", "IEEE", "methIEEE Transactions", "Computational Physics", "Technology", "Computational Mechanics", "Methods", "R Bostanabad", "MA Bessa", "National Academy", "LSTM Networks", "Temperature History", "Continua", "Electrochemical Society", "MD Thouless", "JK", "JMLR Workshop", "Conference Proceedings", "Method", "Stochastic Optimization", "ICLR", "ACM Trans", "arXiv"], "locations": [], "genpurp": []}}{"title": ["Stitch it in Time: GAN-Based Facial Editing of Real Videos"], "authors": ["[arxiv.Result.Author('Rotem Tzaban'), arxiv.Result.Author('Ron Mokady'), arxiv.Result.Author('Rinon Gal'), arxiv.Result.Author('Amit H. Bermano'), arxiv.Result.Author('Daniel Cohen-Or')]"], "link": ["http://arxiv.org/pdf/2201.08361v1"], "summary": "The ability of Generative Adversarial Networks to encode rich semantics\nwithin their latent space has been widely adopted for facial image editing.\nHowever, replicating their success with videos has proven challenging. Sets of\nhigh-quality facial videos are lacking, and working with videos introduces a\nfundamental barrier to overcome - temporal coherency. We propose that this\nbarrier is largely artificial. The source video is already temporally coherent,\nand deviations from this state arise in part due to careless treatment of\nindividual components in the editing pipeline. We leverage the natural\nalignment of StyleGAN and the tendency of neural networks to learn low\nfrequency functions, and demonstrate that they provide a strongly consistent\nprior. We draw on these insights and propose a framework for semantic editing\nof faces in videos, demonstrating significant improvements over the current\nstate-of-the-art. Our method produces meaningful face manipulations, maintains\na higher degree of temporal consistency, and can be applied to challenging,\nhigh quality, talking head videos which current methods struggle with.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["The Specialized High-Performance Network on Anton 3"], "authors": ["[arxiv.Result.Author('Keun Sup Shim'), arxiv.Result.Author('Brian Greskamp'), arxiv.Result.Author('Brian Towles'), arxiv.Result.Author('Bruce Edwards'), arxiv.Result.Author('J. P. Grossman'), arxiv.Result.Author('David E. Shaw')]"], "link": ["http://arxiv.org/pdf/2201.08357v1"], "summary": "Molecular dynamics (MD) simulation, a computationally intensive method that\nprovides invaluable insights into the behavior of biomolecules, typically\nrequires large-scale parallelization. Implementation of fast parallel MD\nsimulation demands both high bandwidth and low latency for inter-node\ncommunication, but in current semiconductor technology, neither of these\nproperties is scaling as quickly as intra-node computational capacity. This\ndisparity in scaling necessitates architectural innovations to maximize the\nutilization of computational units. For Anton 3, the latest in a family of\nhighly successful special-purpose supercomputers designed for MD simulations,\nwe thus designed and built a completely new specialized network as part of our\nASIC. Tightly integrating this network with specialized computation pipelines\nenables Anton 3 to perform simulations orders of magnitude faster than any\ngeneral-purpose supercomputer, and to outperform its predecessor, Anton 2 (the\nstate of the art prior to Anton 3), by an order of magnitude. In this paper, we\npresent the three key features of the network that contribute to the high\nperformance of Anton 3. First, through architectural optimizations, the network\nachieves very low end-to-end inter-node communication latency for fine-grained\nmessages, allowing for better overlap of computation and communication. Second,\nnovel application-specific compression techniques reduce the size of most\nmessages sent between nodes, thereby increasing effective inter-node bandwidth.\nLastly, a new hardware synchronization primitive, called a network fence,\nsupports fast fine-grained synchronization tailored to the data flow within a\nparallel MD application. These application-driven specializations to the\nnetwork are critical for Anton 3's MD simulation performance advantage over all\nother machines.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition"], "authors": ["[arxiv.Result.Author('Chao-Yuan Wu'), arxiv.Result.Author('Yanghao Li'), arxiv.Result.Author('Karttikeya Mangalam'), arxiv.Result.Author('Haoqi Fan'), arxiv.Result.Author('Bo Xiong'), arxiv.Result.Author('Jitendra Malik'), arxiv.Result.Author('Christoph Feichtenhofer')]"], "link": ["http://arxiv.org/pdf/2201.08383v1"], "summary": "While today's video recognition systems parse snapshots or short clips\naccurately, they cannot connect the dots and reason across a longer range of\ntime yet. Most existing video architectures can only process <5 seconds of a\nvideo without hitting the computation or memory bottlenecks.\n  In this paper, we propose a new strategy to overcome this challenge. Instead\nof trying to process more frames at once like most existing methods, we propose\nto process videos in an online fashion and cache \"memory\" at each iteration.\nThrough the memory, the model can reference prior context for long-term\nmodeling, with only a marginal cost. Based on this idea, we build MeMViT, a\nMemory-augmented Multiscale Vision Transformer, that has a temporal support 30x\nlonger than existing models with only 4.5% more compute; traditional methods\nneed >3,000% more compute to do the same. On a wide range of settings, the\nincreased temporal support enabled by MeMViT brings large gains in recognition\naccuracy consistently. MeMViT obtains state-of-the-art results on the AVA,\nEPIC-Kitchens-100 action classification, and action anticipation datasets. Code\nand models will be made publicly available.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Sami Abu-El-Haija", "Nisarg Kothari", "Joonseok Lee", "Paul Natsev", "George Toderici", "Balakrishnan Varadarajan", "Anurag Arnab", "Mostafa Dehghani", "Georg Heigold", "Chen Sun", "Mario Luci", "Gedas Bertasius", "Heng Wang", "Lorenzo Torresani", "Joao Carreira", "Eric Noland", "Andras Banki-Horvath", "Chloe Hillier", "Andrew Zisserman", "Carreira", "Viorica Patraucean", "Laurent Mazare", "Simon Osindero", "Shoufa Chen", "Peize Sun", "Enze Xie", "Chongjian Ge", "Jiannan Wu", "Lan Ma", "Jiajun Shen", "Luo", "Watch", "Yihong Chen", "Yue Cao", "Han Hu", "Liwei Wang", "Memory", "Zhengsu Chen", "Lingxi Xie", "Jianwei Niu", "Xuefeng Liu", "Longhui Wei", "Qi Tian", "Chi Zhang", "Yichen Wei", "Jiang", "Sparse", "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V Le", "Ruslan Salakhutdinov", "Navneet Dalal", "Bill Triggs", "Dima Damen", "Hazel Doughty", "Giovanni Maria Farinella", "Sanja Fidler", "Antonino Furnari", "Evangelos Kazakos", "Davide Moltisanti", "Jonathan Munro", "Toby Perrett", "Will Price", "Michael Wray", "Jia Deng", "Wei Dong", "Richard Socher", "Kai Li", "Li Fei-Fei", "Piotr Doll", "Vincent Rabaud", "Garrison Cottrell", "Serge Belongie", "Behavior", "Visual Surveillance", "Jeff Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Trevor Darrell", "Xiaoyi Dong", "Jianmin Bao", "Dongdong Chen", "Weiming Zhang", "Nenghai Yu", "Lu Yuan", "Dong Chen", "Cswin", "Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Matthias Minderer", "Sylvain Gelly", "Alexei A Efros", "Alexander C Berg", "Greg Mori", "Haoqi Fan", "Yanghao Li", "Bo Xiong", "Christoph Feichtenhofer", "Karttikeya Mangalam", "Zhicheng Yan", "Jitendra Malik", "Multiscale", "Sebastiano Battiato", "Giovanni Farinella", "Rohit Girdhar", "Carl Doersch", "Video", "Kristen Grauman", "Anticipative Video Transformer", "Deva Ramanan", "Abhinav Gupta", "Josef Sivic", "Bryan Russell", "Ross Girshick", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Jia", "Benjamin Graham", "Alaaeldin El-Nouby", "Hugo Touvron", "Pierre Stock", "Armand Joulin", "Herve Jegou", "Matthijs Douze", "Chunhui Gu", "David A. Ross", "Carl Vondrick", "Caroline Pantofaru", "Li", "Sudheendra Vijayanarasimhan", "Susanna Ricco", "Rahul Sukthankar", "Cordelia Schmid", "Efstratios Gavves", "Boyuan Jiang", "Weihao Gan", "Wei Wu", "Junjie Yan", "Will Kay", "Karen Simonyan", "Brian Zhang", "Fabio Viola", "Tim Green", "Trevor Back", "Alexander Klaser", "Marcin Marszaek", "Dan Kondratyuk", "Liangzhe Yuan", "Li Zhang", "Matthew Brown", "Bruno Korbar", "Du Tran", "Scsampler", "Ivan Laptev", "Marcin Marszalek", "Benjamin Rozenfeld", "Sangmin Lee", "Hak Gu Kim", "Dae Hwi Choi", "Kim", "Yong Man Ro", "Sangho Lee", "Jinyoung Sung", "Youngjae Yu", "Gunhee Kim", "Dong Li", "Zhaofan Qiu", "Qi Dai", "Ting Yao", "Tao Mei", "Tushar Nagarajan", "Improved", "Zhenyang Li", "Kirill Gavrilyuk", "Mihir Jain", "Image Understanding", "Chuang Gan", "Song Han", "Bharath Hariharan", "Feature", "Mason Liu", "Yutong Lin", "Yixuan Wei", "Zheng Zhang", "Stephen Lin", "Swin", "Ilya Loshchilov", "Frank Hutter", "Daniel Neimark", "Omri Bar", "Maya Zohar", "Dotan AsarXiv", "Joe", "Matthew Hausknecht", "Oriol Vinyals", "Rajat Monga", "Beyond", "Siyu Chen", "Mike Zheng Shou", "Yu Liu", "Jing Shao", "Hongsheng Li", "Mandela Patrick", "Dylan Campbell", "Yuki M Asano", "Ishan Misra Florian Metze", "Andrea Vedaldi", "Jo Henriques", "Xiaojiang Peng", "Yu Qiao", "Qiang Peng", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Jack W Rae", "Anna Potapenko", "Timothy P Lillicrap", "Ali Razavi", "Jian Sun", "Faster", "Fadime Sener", "Dibyadip Chatterjee", "Angela Yao", "Peter Shaw", "Jakob Uszkoreit", "Ashish Vaswani", "Edouard Grave", "Piotr Bojanowski", "Adaptive", "Da Ju", "Spencer Poff", "Stephen Roller", "Arthur Szlam", "Jason Weston", "Angela Fan", "Kui Jia", "Kevin Chen", "Bertram E Shi", "Silvio Savarese", "Jingru Tan", "Changbao Wang", "Buyu Li", "Quanquan Li", "Wanli Ouyang", "Gang Zhang", "Hanming Deng", "Lewei Lu", "Jifeng Dai", "Jiajun Tang", "Jin Xia", "Xinzhi Mu", "Bo Pang", "Cewu Lu", "Graham W Taylor", "Rob Fergus", "Yann LeCun", "Christoph Bregler", "Matthieu Cord", "Francisco Massa", "Alexandre Sablayrolles", "Gabriel Synnaeve", "Herv", "Lubomir Bourdev", "Manohar Paluri", "Matt Feiszli", "Noam Shazeer", "Niki Parmar", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin", "Alexander Kl", "Dense", "Muhammad Muneeb Ullah", "Limin Wang", "Xiaoou Tang", "Yuanjun Xiong", "Zhe Wang", "Dahua Lin", "Luc Val Gool", "Wenhai Wang", "Xiang Li", "Kaitao Song", "Ding Liang", "Tong Lu", "Ping Luo", "Pyramid", "Xiaolong Wang", "Xiaohan Wang", "Linchao Zhu", "Yi Yang", "Philipp Kr", "Philipp Krahenbuhl", "Towards", "Manzil Zaheer", "Hexiang Hu", "Alexander J Smola", "Zhuowen Tu", "Jonathan Huang", "Kevin Murphy", "Yunpeng Chen", "Tao Wang", "Weihao Yu", "Yujun Shi", "Francis EH Tay", "Jiashi Feng", "Shuicheng Yan", "Bolei Zhou", "Alex Andonian", "Aude Oliva", "Antonio TorIn ECCV", "Xizhou Zhu", "Yujie Wang", "Kamaljeet Singh", "Thomas Brox"], "organizations": ["Sudheendra Vijayanarasimhan", "Cordelia Schmid", "ICCV", "ECCV", "CVPR", "ACM", "ACL", "PAMI", "International Workshop", "Performance Evaluation", "Kate Saenko", "ICLR", "ECCV Workshops", "Priya Goyal", "ConvNets", "Noureldien Hussein", "Arnold", "MengMeng Wang", "Yandong Li", "Mingxing Tan", "Yanghao Li", "Cees", "VideoLSTM", "Computer Vision", "Menglong Zhu", "detecIn Proc", "Siddhant", "TecharXiv", "ICML", "IJCV", "R Manmatha"], "locations": [], "genpurp": []}}{"title": ["Learning Pixel Trajectories with Multiscale Contrastive Random Walks"], "authors": ["[arxiv.Result.Author('Zhangxing Bian'), arxiv.Result.Author('Allan Jabri'), arxiv.Result.Author('Alexei A. Efros'), arxiv.Result.Author('Andrew Owens')]"], "link": ["http://arxiv.org/pdf/2201.08379v1"], "summary": "A range of video modeling tasks, from optical flow to multiple object\ntracking, share the same fundamental challenge: establishing space-time\ncorrespondence. Yet, approaches that dominate each space differ. We take a step\ntowards bridging this gap by extending the recent contrastive random walk\nformulation to much denser, pixel-level space-time graphs. The main\ncontribution is introducing hierarchy into the search problem by computing the\ntransition matrix between two frames in a coarse-to-fine manner, forming a\nmultiscale contrastive random walk when extended in time. This establishes a\nunified technique for self-supervised learning of optical flow, keypoint\ntracking, and video object segmentation. Experiments demonstrate that, for each\nof these tasks, the unified model achieves performance competitive with strong\nself-supervised approaches specific to that task. Project site:\nhttps://jasonbian97.github.io/flowwalk", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Robert Anderson", "David Gallup", "Jonathan T Barron", "Janne Kontkanen", "Noah Snavely", "Carlos Hern", "Sameer Agarwal", "Steven M Seitz", "Jump", "Simon Baker", "Iain Matthews", "Daniel Scharstein", "Stefan Roth", "Michael J Black", "Richard Szeliski", "Paul Anandan", "Thomas Brox", "Christoph Bregler", "Jitendra Malik", "Large", "Andr", "Bruhn", "Nils Papenberg", "Joachim Weickert", "Object", "Springer", "Brain Schunck", "Zhaoyang Huang", "Xiaokun Pan", "Runsen Xu", "Kachun Cheung", "Guofeng Zhang", "Hongsheng Li", "Mirrorflow", "Eddy Ilg", "Nikolaus Mayer", "Tonmoy Saikia", "Margret Keuper", "Alexey Dosovitskiy", "Allan Jabri", "Andrew Owens", "Alexei A Efros", "Max Jaderberg", "Karen Simonyan", "Andrew Zisserman", "Koray Kavukcuoglu", "Joel Janai", "Fatma G", "Anurag Ranjan", "Michael Black", "Andreas Geiger", "Michael J", "Black", "Fatma Guney", "Jonas Wulff", "Slow", "Pattern Recognition", "Hueihan Jhuang", "Juergen Gall", "Silvia Zuffi", "Cordelia Schmid", "Rico Jonschkowski", "Austin Stone", "Ariel Gordon", "Kurt Konolige", "Anelia Angelova", "Ryan Kennedy", "Camillo J Taylor", "Optical", "Diederik P Kingma", "Jimmy Ba", "Adam", "Zihang Lai", "Erika Lu", "Weidi Xie", "Mast", "Cheng Lei", "Li", "Sifei Liu", "Shalini De Mello", "Xiaolong Wang", "Jan Kautz", "Yunpeng Li", "Daniel P Huttenlocher", "Massachusetts Institute", "Liang Liu", "Jiangning Zhang", "Yong Liu", "Yabiao Wang", "Tai", "Donghao Luo", "Chengjie Wang", "Jilin Li", "Feiyue Huang", "Pengpeng Liu", "Irwin King", "Michael R Lyu", "Jia Xu", "Ddflow", "Michael R. Lyu", "Michael Lyu", "Selflow", "Bruce D Lucas", "Takeo Kanade", "Chuan Wang", "Shuaicheng Liu", "Haoqiang Fan", "Jue Wang", "Jian Sun", "Upflow", "Simon Meister", "Junhwa Hur", "Unflow", "Geoffrey Hinton", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "J. Pont-Tuset", "Van Gool", "Jordi Pont-Tuset", "Federico Perazzi", "Sergi Caelles", "Pablo Arbel", "Alexander Sorkine-Hornung", "Luc Van Gool", "Jerome Revaud", "Philippe Weinzaepfel", "Zaid Harchaoui", "Epicflow", "Dan Rosenbaum", "Daniel Zoran", "Yair Weiss", "Victor Lempitsky", "Carsten Rother", "Visual Motion Analysis", "Michael Rubinstein", "Ce Liu", "William T Freeman", "Towards", "Peter Sand", "Seth Teller", "Particle", "Alexander Shekhovtsov", "Ivan Kovtun", "Hlav", "Image Understanding", "Leslie N Smith", "Nicholay Topin", "Machine Learning", "Daniel Maurer", "Alper Ayvaci", "Smurf", "Erik Sudderth", "Layered", "Daniel Vlasic", "Charles Herrmann", "Varun Jampani", "Michael Krainin", "Huiwen Chang", "Ramin Zabih", "Autoflow", "Xiaodong Yang", "Narayanan Sundaram", "Kurt Keutzer", "Dense", "Zhenyu Jiang", "Zhenda Xie", "Yue Cao", "Zheng Zhang", "Philip HS Torr", "Han Hu", "Jia Deng", "Raft", "Sebastian Volz", "Andres Bruhn", "Levi Valgaerts", "Henning Zimmer", "Carl Vondrick", "Abhinav Shrivastava", "Alireza Fathi", "Sergio Guadarrama", "Kevin Murphy", "Wang", "Heng Wang", "Alexander Kl", "Chao Ma", "Wengang Zhou", "Wei Liu", "Houqiang Li", "Yang Wang", "Yi Yang", "Wei Xu", "Zhongdao Wang", "Hengshuang Zhao", "Philip Torr", "Luca Bertinetto", "Deepflow", "Jiarui Xu", "Li Xu", "Jianing Chen", "Jiaya Jia", "Linjie Yang", "Yuchen Fan", "Dingcheng Yue", "Yuchen Liang", "Jianchao Yang", "Thomas Huang", "Zhichao Yin", "Geonet", "Jason J. Yu", "Adam W. Harley", "Konstantinos G. Derpanis", "Bouguet", "Pyramidal", "Microprocessor", "Research Labs", "Yiran Zhong", "Pan Ji", "Jianyuan Wang", "Yuchao Dai", "Hongdong Li", "Xiaojin Zhu", "Zoubin Ghahramani", "Zitnick", "Nebojsa Jojic", "Yuliang Zou", "Zelun Luo", "Huang", "Hyperparameter Learning", "Temperature Video", "Window Size", "Values", "Chairs", "Sintel D. Additional Qualitative"], "organizations": ["ACM Transactions", "TOG", "International Journal", "Computer Vision", "JP Lewis", "IJCV", "Parametric", "Computer", "Berthold Horn", "Artificial Intelligence", "Yan Xu", "IEEE International Conference", "IEEE", "NeurIPS", "ECCV", "IEEE Conference", "International Workshop", "Energy Minimization Methods", "International Conference", "PhD", "distillaIn Proceedings", "AAAI Conference", "Artificial", "AAAI", "IJCAI", "Roland Memisevic", "Cordelia Schmid", "Geometrical Approaches", "ICCV", "International Society", "Optics", "Photonics", "multiIn Proframe", "Yansong Tang", "Information Science", "International", "Shengjin Wang", "Xiaolong Wang", "ECCV 2016 Workshops", "Part", "Jean", "Intel Corporation", "ICCV05", "Random Walk", "KITTI", "RGB", "Smoothness", "PyTorch", "Adam", "ARflow", "CensusCensus"], "locations": [], "genpurp": []}}{"title": ["Omnivore: A Single Model for Many Visual Modalities"], "authors": ["[arxiv.Result.Author('Rohit Girdhar'), arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Nikhila Ravi'), arxiv.Result.Author('Laurens van der Maaten'), arxiv.Result.Author('Armand Joulin'), arxiv.Result.Author('Ishan Misra')]"], "link": ["http://arxiv.org/pdf/2201.08377v1"], "summary": "Prior work has studied different visual modalities in isolation and developed\nseparate architectures for recognition of images, videos, and 3D data. Instead,\nin this paper, we propose a single model which excels at classifying images,\nvideos, and single-view 3D data using exactly the same model parameters. Our\n'Omnivore' model leverages the flexibility of transformer-based architectures\nand is trained jointly on classification tasks from different modalities.\nOmnivore is simple to train, uses off-the-shelf standard datasets, and performs\nat-par or better than modality-specific models of the same size. A single\nOmnivore model obtains 86.0% on ImageNet, 84.1% on Kinetics, and 67.1% on SUN\nRGB-D. After finetuning, our models outperform prior work on a variety of\nvision tasks and generalize across modalities. Omnivore's shared visual\nrepresentation naturally enables cross-modal recognition without access to\ncorrespondences between modalities. We hope our results motivate researchers to\nmodel visual modalities together.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Higher Symmetries of 5d Orbifold SCFTs"], "authors": ["[arxiv.Result.Author('Michele Del Zotto'), arxiv.Result.Author('Jonathan J. Heckman'), arxiv.Result.Author('Shani Nadir Meynet'), arxiv.Result.Author('Robert Moscrop'), arxiv.Result.Author('Hao Y. Zhang')]"], "link": ["http://arxiv.org/pdf/2201.08372v1"], "summary": "We determine the higher symmetries of 5d SCFTs engineered from M-theory on a\n$\\mathbb{C}^3 / \\Gamma$ background for $\\Gamma$ a finite subgroup of $SU(3)$.\nThis resolves a longstanding question as to how to extract this data when the\nresulting singularity is non-toric (when $\\Gamma$ is non-abelian) and/or not\nisolated (when the action of $\\Gamma$ has fixed loci). The BPS states of the\ntheory are encoded in a 1D quiver quantum mechanics gauge theory which\ndetermines the possible 1-form and 2-form symmetries. We also show that this\nsame data can also be extracted by a direct computation of the corresponding\ndefect group associated with the orbifold singularity. Both methods agree, and\nthese computations do not rely on the existence of a resolution of the\nsingularity. We also observe that when the geometry faithfully captures the\nglobal 0-form symmetry, the abelianization of $\\Gamma$ detects a 2-group\nstructure (when present). As such, this establishes that all of this data is\nindeed intrinsic to the superconformal fixed point rather than being an\nemergent property of an IR gauge theory phase.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["Revisiting Weakly Supervised Pre-Training of Visual Perception Models"], "authors": ["[arxiv.Result.Author('Mannat Singh'), arxiv.Result.Author('Laura Gustafson'), arxiv.Result.Author('Aaron Adcock'), arxiv.Result.Author('Vinicius de Freitas Reis'), arxiv.Result.Author('Bugra Gedik'), arxiv.Result.Author('Raj Prateek Kosaraju'), arxiv.Result.Author('Dhruv Mahajan'), arxiv.Result.Author('Ross Girshick'), arxiv.Result.Author('Piotr Doll\u00e1r'), arxiv.Result.Author('Laurens van der Maaten')]"], "link": ["http://arxiv.org/pdf/2201.08371v1"], "summary": "Model pre-training is a cornerstone of modern visual recognition systems.\nAlthough fully supervised pre-training on datasets like ImageNet is still the\nde-facto standard, recent studies suggest that large-scale weakly supervised\npre-training can outperform fully supervised approaches. This paper revisits\nweakly-supervised pre-training of models using hashtag supervision with modern\nversions of residual networks and the largest-ever dataset of images and\ncorresponding hashtags. We study the performance of the resulting models in\nvarious transfer-learning settings including zero-shot transfer. We also\ncompare our models with those obtained via large-scale self-supervised\nlearning. We find our weakly-supervised models to be very competitive across\nall settings, and find they substantially outperform their self-supervised\ncounterparts. We also include an investigation into whether our models learned\npotentially troubling associations or stereotypes. Overall, our results provide\na compelling argument for the use of weakly supervised learning in the\ndevelopment of visual recognition systems. Our models, Supervised Weakly\nthrough hashtAGs (SWAG), are available publicly.", "entities_include_in_text": ["CUB-2011"], "entities_from_reference": {"persons": ["Samira Abnar", "Mostafa Dehghani", "Behnam Neyshabur", "Hanie Sedghi", "Adcock", "Singh", "Maaten", "Zhang", "Motwani", "J. Guerin", "Classy", "Hangbo Bao", "Li Dong", "Furu Wei", "Beit", "Bert", "Andrei Barbu", "David Mayo", "Julian Alverio", "William Luo", "Christopher Wang", "Dan Gutfreund", "Josh Tenenbaum", "Boris Katz", "Fox", "Garnett", "Josh Beal", "Dong Huk Park", "Andrew Zhai", "Dmitry Kislyuk", "Emily M. Bender", "Timnit Gebru", "Angelina McMillan-Major", "Lucas Beyer", "Olivier J.", "Alexander Kolesnikov", "Xiaohua Zhai", "Aaron", "Abeba Birhane", "Vinay", "Emmanuel Kahembwe", "Multimodal", "Tom B", "Brown", "Ben Mann", "Nick Ryder", "Melanie Subbiah", "Jared D. Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "Sandhini Agarwal", "Ariel Herbert-Voss", "Gretchen M. Krueger", "Tom Henighan", "Rewon Child", "Aditya Ramesh", "Daniel Ziegler", "Jeffrey Wu", "Clemens Winter", "Chris Hesse", "Mark Chen", "Eric Sigler", "Mateusz Litwin", "Scott Gray", "Benjamin Chess", "Jack Clark", "Christopher Berner", "Sam McCandlish", "Alec Radford", "Ilya Sutskever", "Dario Amodei", "Mathilde Caron", "Piotr Bojanowski", "Armand Joulin", "Matthijs Douze", "Ishan Misra", "Julien Mairal", "Priya Goyal", "Hugo Touvron", "Herve Jegou", "Simon Kornblith", "Kevin Swersky", "Mohammad Norouzi", "Geoffrey Hinton", "Pattern Recognition", "Ekin D. Cubuk", "Barret Zoph", "Dandelion Mane", "Vijay Vasudevan", "Quoc V. Le", "Denton", "J. Weston", "User", "Wang", "Global Challenges", "Piotr Doll", "Mannat Singh", "Ross Girshick", "Fast", "Jeff Donahue", "Jia", "Oriol Vinyals", "Judy Hoffman", "Eric Tzeng", "Trevor Darrell", "Machine Learning", "Alexey Dosovitskiy", "Dirk Weissenborn", "Thomas Unterthiner", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Haoqi Fan", "Bo Xiong", "Karttikeya Mangalam", "Yanghao Li", "Zhicheng Yan", "Jitendra Malik", "Christoph Feichtenhofer", "Multiscale", "Bradford Books", "Soleil", "Esth", "Deepti Ghadiyaram", "Du Tran", "Dhruv Mahajan", "Largescale", "Spyros Gidaris", "Praveer Singh", "Nikos Komodakis", "Benjamin Lefaudeux", "Min Xu", "Pengchao Wang", "Vivek Pai", "Vitaliy Liptchinsky", "Pieter Noordhuis", "Lukasz Wesolowski", "Aapo Kyrola", "Andrew Tulloch", "Florian Strub", "Florent Altch", "Corentin Tallec", "Pierre H. Richemond", "Elena Buchatskaya", "Carl Doersch", "Bernardo Avila Pires", "Zhaohan Daniel Guo", "Mohammad Gheshlaghi Azar", "Bilal Piot", "Koray Kavukcuoglu", "Remi Munos", "Michal Valko", "Shuai Liu", "Adam Kortylewski", "Cheng Yang", "Yutong Bai", "Changhu Wang", "Alan Yuille", "Transfg", "Yuxin Wu", "Momentum", "Georgia Gkioxari", "Ross Gir", "Mask", "Van Horn", "Pietro Perona", "Li Shen", "Gang Sun", "Zhuang Liu", "Laurens Van Der Maaten", "Kilian Q Weinberger", "Gao Huang", "Yu Sun", "Daniel Sedra", "Kilian Weinberger", "Chao Jia", "Yinfei Yang", "Ye Xia", "Zarana Parekh", "Hieu Pham", "Yunhsuan Sung", "Zhen Li", "Tom Duerig", "Joulin", "Will Kay", "Joao Carreira", "Karen Simonyan", "Brian Zhang", "Chloe Hillier", "Sudheendra Vijayanarasimhan", "Fabio Viola", "Tim Green", "Trevor Back", "Paul Natsev", "Mustafa Suleyman", "Andrew Zisserman", "Vahid Kazemi", "Ali Elqursh", "Show", "Joan Puigcerver", "Jessica Yung", "Neil Houlsby", "Jonathon Shlens", "Lampert", "Ang Li", "Allan Jabri", "Xiujun Li", "Xi Yin", "Chunyuan Li", "Pengchuan Zhang", "Lei Zhang", "Lijuan Wang", "Houdong Hu", "Yejin Choi", "Jianfeng Gao", "Oscar", "Ilya Loshchilov", "Frank Hutter", "Vignesh Ramanathan", "Manohar Paluri", "Yixuan Li", "Ashwin Bharambe", "Tomas Mikolov", "Kai Chen", "Greg S Corrado", "Jeff Dean", "Hinton", "John Platt", "Margin Classifiers", "Polyak", "Branson", "Technical Report", "Huiyu Wang", "Yukun Zhu", "Hartwig Adam", "Ross Wightman", "Cihang Xie", "Boqing Gong", "Jiang Wang", "Alan L Yuille", "Quoc V Le", "Qizhe Xie", "Eduard Hovy", "Zhuowen Tu", "Muhammad Bilal Zafar", "Isabel Valera", "Manuel Gomez Rodriguez", "Krishna P. Gummadi", "Hongyi Zhang", "Moustapha Cisse", "Yann N Dauphin", "David", "Zhifei Zhang", "Yang Song", "Hairong Qi", "Bolei Zhou", "Agata Lapedriza", "Aditya Khosla", "Aude Oliva", "Antonio Torralba", "Pattern Analysis", "Machine Intelligence", "Prabhu", "Filip Radenovic", "Animesh Sinha", "Albert Gordo", "Tamara Berg", "Jong Wook Kim", "Chris Hallacy", "Gabriel Goh", "Pamela Mishkin", "Gretchen Learning", "Ilija Radosavovic", "Raj Prateek Kosaraju", "Ali Sharif Razavian", "Hossein Azizpour", "Josephine Sullivan", "Stefan Carlsson", "Pattern Recognition Workshops", "Benjamin Recht", "Rebecca Roelofs", "Ludwig Schmidt", "Vaishaal Shankar", "Jian Sun", "Faster", "Emanuel Ben-Baruch", "Asaf Noy", "Lihi", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei", "Gunnar A. Sigurdsson", "Aida Nematzadeh", "Lucas Smaira", "Mateusz Malinowski", "Phil Blunsom", "Visual", "Quoc Le", "Andrea Vedaldi", "Herv", "Oisin Mac Aodha", "Yin Cui", "Chen Sun", "Alex Shepard", "Serge Belongie", "Details Hashtag Filtering", "Python", "Ii", "Next", "Model Complexity", "Speed Table", "Model Resolution Flops Params Acts", "Model", "Hyperparameter Selection", "Model Res", "Throughput Classification", "Dataset Size", "Dataset Epochs Samples Name", "Akin", "Results", "Classy Vision", "Likewise", "Weakly", "Platt", "Net F.1", "Hashtag", "Accuracy", "Broader Impact", "Due", "Brazil", "Skin Tone", "Arab EmiratesArgentinaBrazilColombiaEgyptIndonesiaIndiaJapanSouth", "Black", "Fitzpatrick", "Having"], "organizations": ["Curran Associates", "Shmargaret Shmitchell", "ACM Conference", "Fairness", "Accountability", "ImageNet", "modarXiv", "Computer Vision", "KDD", "CVPR Workshop", "recogniIn International Conference", "TransarXiv", "Christiane Fellbaum", "Electronic Lexical Database", "UAI", "arXiv", "IEEE", "Gao Huang", "European Conference", "ECCV", "IEEE Conference", "International Conference", "ICCV", "IEEE International Conference", "XiaoWei Hu", "CVPR", "SIAM Journal", "Control", "segIn", "arXiv 2012.00759", "Mingxing Tan", "AIMechanisms", "IEEE Transactions", "viKrueger", "CNN", "CVPRW", "PMLR", "Tal Ridnik", "Olga Russakovsky", "ImageNet Large Scale Visual", "IJCV", "groundIn", "US", "WordNet", "MIN_LEN", "ALLOWED_SENSES", "FLOPs", "Complexity", "GPUs", "EfficientNets", "SGD", "ViTs", "AdamW", "ViT", "Convolutional Model", "RegNetY", "FLOPs Param", "ResNeXt", "DenseNet", "SE", "EfficientNet", "IG", "Parameters Due", "GFLOPs", "EMA", "iNat", "Supervised", "EfficientNet L2", "EfficientNet B7", "EfficientNet B6", "EfficientNet B8", "ImageNet1k", "ReaL", "JFT", "UTK Faces", "AmericaSouth"], "locations": [], "genpurp": []}}{"title": ["The Compton Amplitude, lattice QCD and the Feynman-Hellmann approach"], "authors": ["[arxiv.Result.Author('K. U. Can'), arxiv.Result.Author('A. Hannaford-Gunn'), arxiv.Result.Author('R. Horsley'), arxiv.Result.Author('Y. Nakamura'), arxiv.Result.Author('H. Perlt'), arxiv.Result.Author('P. E. L. Rakow'), arxiv.Result.Author('E. Sankey'), arxiv.Result.Author('G. Schierholz'), arxiv.Result.Author('H. St\u00fcben'), arxiv.Result.Author('R. D. Young'), arxiv.Result.Author('J. M. Zanotti')]"], "link": ["http://arxiv.org/pdf/2201.08367v1"], "summary": "A major objective of lattice QCD is the computation of hadronic matrix\nelements. The standard method is to use three-point and four-point correlation\nfunctions. An alternative approach, requiring only the computation of two-point\ncorrelation functions is to use the Feynman-Hellmann theorem. In this talk we\ndevelop this method up to second order in perturbation theory, in a context\nappropriate for lattice QCD. This encompasses the Compton Amplitude (which\nforms the basis for deep inelastic scattering) and hadron scattering. Some\nnumerical results are presented showing results indicating what this approach\nmight achieve.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Phys", "Wilson", "Adv", "High Energy Phys", "Nucleon Structure Functions", "Operator Product Expansion", "Lett", "Elementary Particle Physics", "Wiley", "Lamb", "Nucl", "Tensor Charges", "Suppl"], "organizations": ["Introduction", "GPDs", "TMDs", "Lattice", "SciPost Physics Submission", "Compton", "Feynman Hellmann", "QCD", "PoS", "Physics", "Standard Model", "BQCD Hybrid Monte Carlo", "EPJ", "Chroma"], "locations": [], "genpurp": []}}{"title": ["Mathematics and Mathematics Education in the 21st Century"], "authors": ["[arxiv.Result.Author('Alexandre Borovik'), arxiv.Result.Author('Zoltan Kocsis'), arxiv.Result.Author('Vladimir Kondratiev')]"], "link": ["http://arxiv.org/pdf/2201.08364v1"], "summary": "Mathematics enters the period of change unprecedented in its history, perhaps\neven a revolution: a switch to use of computers as assistants and checkers in\nproduction of proofs. This requires rethinking traditional approaches to\nmathematics education which is struggling through a crisis of its own,\nsocio-economic and political by its nature. The mathematical community faces\nPandora's box of problems, which, surprisingly, are not usually discussed in\nany connected form. The present paper attempts to address this issue in a bit\nmore joint and cohesive way.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Alisher S. Abdullayev", "Gavin Newsom", "Tony Thurmond", "Glen S. Aikenhead", "Math", "Techn", "Igor Vladimirovich Arnold", "Izvesiya APN", "John Baez", "Topos Institute Colloquium", "Alexandre Borovik", "P SL2", "Alexandre V. Borovik", "Mathematics", "Springer International Publishing", "Cham", "Economy", "Springer", "Inna Capdeboscq", "Daniel Gorenstein", "Richard Lyons", "Ronald Solomon", "Part", "Mathematical Surveys", "Joseph Capek", "Karel Capek", "Albatros", "Davide Castelvecchi", "Philip Davis", "Reuben Hersh", "Nicolaas Govert de Bruijn", "Springer Berlin Heidelberg", "Berlin", "Heidelberg", "Paul Ernest", "Albany", "Slava Gerovitch", "Kritika", "Thomas Hales", "Mark Adams", "Gertrud Bauer", "Tat Dat Dange", "John Harrison", "Le Truong Hoang", "Cezary Kaliszyk", "Victor Magron", "Sean McLaughlin", "Tat Thang Nguyen", "Quang Truong Nguyen", "Tobias Nipkow", "Steven Obua", "Joseph Pleso", "Jason Rute", "Alexey Solovyev", "Thi Hoai An Ta", "Nam Trung Tran", "Thi Diep Trieu", "Josef Urban", "Ky Vu", "Mikhail M. Kapranov", "Vladimir A. Voevodsky", "Diff", "Asaf Karagila", "Mathematics Stack Exchange", "Vladimir Khalin", "Nikolai Vavilov", "Alexander Yurkov", "Donald E. Knuth", "Vol", "Zoltan Kocsis", "Manchester", "Nikolay N. Konstantinov", "Alexei L. Semenov", "Chebyshevskii Sbornik", "Jeff Kramer", "Vadim", "Krutetskii", "Teller", "Edward Nelson", "Sankhya", "Series A", "Yuri", "Neretin", "Model Checking", "Abstract Interpretation", "Ulf Persson", "Soc", "Magazine", "Vladimir A. Rokhlin", "Topology", "Peter Scholze", "Xena Project", "Fritz Schweiger", "Brill Sense", "Anna Sfard", "Patrick W. Thompson", "Mathematics EducationNorth America", "Plenary Sessions", "Baton Rouge LA", "Louisiana State University", "Igor Sharygin", "Otech", "Carlos Simpson", "Cambridge University Press", "Stehelin", "George Szpiro", "Certified Programs", "Matthew Towers", "Vladimir", "Voevodsky", "Programme Proposal", "Advanced Study", "Kirk Weller", "Anne Brown", "Ed Dubinskyn", "Michael McDonald", "Cynthia Stenger", "Notices", "Langdon Winner", "Higher School"], "organizations": ["Equitable Math Instruction", "State", "State Board", "Instructional Quality Commission", "Philosophy", "Mathematical Education", "Principles", "De Morgan", "Kolmogorov", "USSR", "Journal", "Microscope", "Mathematical Practice", "RI", "Monographs", "Long Cat Tale", "MATHEMATICS", "CENTURY", "Nature", "State University", "NY", "Kepler Conjecture", "Cahiers", "Cat", "NFU", "Development", "Department", "Commun", "University", "Statistics", "LSD", "International Conference", "VMCAI12", "Fundamental", "Monterrey", "International Commission", "Mathematical Instruction", "ALEXANDRE", "ZOLTAN", "AND", "VLADIMIR", "Anuual Meeting", "International Group", "Psychology", "California Department", "Mathematics Framework", "Community", "Lean", "ACM", "PLAN International Conference", "MathOverflow", "Univalent Foundations", "Institute", "Intima", "AMS", "UK Email"], "locations": [], "genpurp": []}}{"title": ["Physics-informed neural networks for modeling rate- and temperature-dependent plasticity"], "authors": ["[arxiv.Result.Author('Rajat Arora'), arxiv.Result.Author('Pratik Kakkar'), arxiv.Result.Author('Biswadip Dey'), arxiv.Result.Author('Amit Chakraborty')]"], "link": ["http://arxiv.org/pdf/2201.08363v1"], "summary": "This work presents a physics-informed neural network based framework to model\nthe strain-rate and temperature dependence of the deformation fields\n(displacement, stress, plastic strain) in elastic-viscoplastic solids. A\ndetailed discussion on the construction of the physics-based loss criterion\nalong with a brief outline on ways to avoid unbalanced back-propagated\ngradients during training is also presented. We also present a simple strategy\nwith no added computational complexity for choosing scalar weights that balance\nthe interplay between different terms in the composite loss. Moreover, we also\nhighlight a fundamental challenge involving selection of appropriate model\noutputs so that the mechanical problem can be faithfully solved using neural\nnetworks. Finally, the effectiveness of the proposed framework is demonstrated\nby studying two test problems modeling the elastic-viscoplastic deformation in\nsolids at different strain-rates and temperatures, respectively.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["European Journal", "Xiaohan Zhang", "Amit Acharya", "Finite", "Fleck", "Muller", "Strain", "Acta Metallurgica", "Niordson", "Lynggaard", "Structures", "Shear", "Science", "Carnegie Mellon University", "Christian Miehe", "Fabian Welschinger", "Martina Hofacker", "Michael J Borden", "Thomas JR Hughes", "Chad M Landis", "Clemens V Verhoosel", "Luo Zhirong", "Huang Lilin", "Mao Hong", "Huang Chuanggao", "Lin Kui", "Phase", "Pedro Areias", "Timon Rabczuk", "Charlotte Kuhn", "Ralf M", "Engi", "Adam Paszke", "Sam Gross", "Francisco Massa", "Adam Lerer", "James Bradbury", "Gregory Chanan", "Trevor Killeen", "Zeming Lin", "Natalia Gimelshein", "Luca Antiga", "Alban Desmaison", "Andreas Kopf", "Edward Yang", "Zachary DeVito", "Martin Raison", "Alykhan Tejani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala", "Fox", "Garnett", "Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S. Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin", "Sanjay Ghemawat", "Ian Goodfellow", "Andrew Harp", "Geoffrey Irving", "Michael Isard", "Jia", "Rafal Jozefowicz", "Lukasz Kaiser", "Manjunath Kudlur", "Josh Levenberg", "Dandelion Man", "Rajat Monga", "Sherry Moore", "Derek Murray", "Chris Olah", "Mike Schuster", "Jonathon Shlens", "Ilya Sutskever", "Kunal Talwar", "Paul Tucker", "Vincent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng", "Software", "Keras", "George Cybenko", "Aristidis Likas", "Aristidis C Likas", "Dimitris G Papageorgiou", "Networks", "Maziar Raissi", "Paris Perdikaris", "George Em Karniadakis", "Physics", "George E Karniadakis", "Han Gao", "Shaowu Pan", "Hao Sun", "Yang Liu", "Applied Mechanics Letters", "Xiaowei Jin", "Shengze Cai", "Hui Li", "Luning Sun", "Georgios Kissas", "Yibo Yang", "Eileen Hwuang", "Walter R Witschey", "John A Detre", "Machine", "Daniel E Hurtado", "Ellen Kuhl", "Kousuke Tachida", "Reese Jones", "Machine Learning", "Panos Stinis", "Alexandre Tartakovsky", "Zhang", "Minglang Yin", "Zhu", "Zeliang Liu", "Jinhui Yan", "Daniele Versino", "Alberto Tonda", "Curt A Bronkhorst", "Data", "Zhiyong Li", "Huaibao Zhang", "Sean CC Bailey", "Jesse B Hoagg", "Alexandre Martin", "Francisco Chinesta", "Rafael G", "Nathan Kutz", "Rendus M", "Steven L Brunton", "Bart Van Merri", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio", "W Chen", "K Ehmann", "Jian Cao", "Diab W. Abueidda", "Seid Koric", "Nahil A. Sobh", "Huseyin Sehitoglu", "Deep", "Effects", "Strain Rate", "Applied Mechanics", "Dengpeng Huang", "Jan Niklas Fuhg", "Christian Weienfels", "Peter Wriggers", "Gorji", "Mojtaba Mozaffar", "Julian N. Heidenreich", "Dirk Mohr", "Morton E. Gurtin", "Eliot Fried", "Lallit Anand", "Cambridge University Press", "Sooraj Narayan", "A1092", "William S LePage", "Yuxin Chen", "Eric Kazyak", "Adrian J Sanchez", "Andrea Poli", "Ellen M Arruda", "Neil P Dasgupta", "D Pal", "Materials Processing Technology", "Wang", "Yujun Teng", "Rafael Bischof", "Michael Kraus", "Jimmy Ba", "Adam", "Math", "Marian Czarnecki", "Simon Osindero", "Max Jaderberg", "Grzegorz Swirszcz", "Sobolev", "Razvan Pascanu"], "organizations": ["Computer Methods", "Mechanics", "Physics", "SSD", "GND", "International Journal", "Computational Approximation", "Mesoscale Field Dislocation", "PhD", "International", "MA3574977 Msekh", "Fracture Mechanics", "PyIn", "Curran Associates", "IEEE", "methIEEE Transactions", "Computational Physics", "Technology", "Computational Mechanics", "Methods", "R Bostanabad", "MA Bessa", "National Academy", "LSTM Networks", "Temperature History", "Continua", "Electrochemical Society", "MD Thouless", "JK", "JMLR Workshop", "Conference Proceedings", "Method", "Stochastic Optimization", "ICLR", "ACM Trans", "arXiv"], "locations": [], "genpurp": []}}{"title": ["Stitch it in Time: GAN-Based Facial Editing of Real Videos"], "authors": ["[arxiv.Result.Author('Rotem Tzaban'), arxiv.Result.Author('Ron Mokady'), arxiv.Result.Author('Rinon Gal'), arxiv.Result.Author('Amit H. Bermano'), arxiv.Result.Author('Daniel Cohen-Or')]"], "link": ["http://arxiv.org/pdf/2201.08361v1"], "summary": "The ability of Generative Adversarial Networks to encode rich semantics\nwithin their latent space has been widely adopted for facial image editing.\nHowever, replicating their success with videos has proven challenging. Sets of\nhigh-quality facial videos are lacking, and working with videos introduces a\nfundamental barrier to overcome - temporal coherency. We propose that this\nbarrier is largely artificial. The source video is already temporally coherent,\nand deviations from this state arise in part due to careless treatment of\nindividual components in the editing pipeline. We leverage the natural\nalignment of StyleGAN and the tendency of neural networks to learn low\nfrequency functions, and demonstrate that they provide a strongly consistent\nprior. We draw on these insights and propose a framework for semantic editing\nof faces in videos, demonstrating significant improvements over the current\nstate-of-the-art. Our method produces meaningful face manipulations, maintains\na higher degree of temporal consistency, and can be applied to challenging,\nhigh quality, talking head videos which current methods struggle with.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}{"title": ["The Specialized High-Performance Network on Anton 3"], "authors": ["[arxiv.Result.Author('Keun Sup Shim'), arxiv.Result.Author('Brian Greskamp'), arxiv.Result.Author('Brian Towles'), arxiv.Result.Author('Bruce Edwards'), arxiv.Result.Author('J. P. Grossman'), arxiv.Result.Author('David E. Shaw')]"], "link": ["http://arxiv.org/pdf/2201.08357v1"], "summary": "Molecular dynamics (MD) simulation, a computationally intensive method that\nprovides invaluable insights into the behavior of biomolecules, typically\nrequires large-scale parallelization. Implementation of fast parallel MD\nsimulation demands both high bandwidth and low latency for inter-node\ncommunication, but in current semiconductor technology, neither of these\nproperties is scaling as quickly as intra-node computational capacity. This\ndisparity in scaling necessitates architectural innovations to maximize the\nutilization of computational units. For Anton 3, the latest in a family of\nhighly successful special-purpose supercomputers designed for MD simulations,\nwe thus designed and built a completely new specialized network as part of our\nASIC. Tightly integrating this network with specialized computation pipelines\nenables Anton 3 to perform simulations orders of magnitude faster than any\ngeneral-purpose supercomputer, and to outperform its predecessor, Anton 2 (the\nstate of the art prior to Anton 3), by an order of magnitude. In this paper, we\npresent the three key features of the network that contribute to the high\nperformance of Anton 3. First, through architectural optimizations, the network\nachieves very low end-to-end inter-node communication latency for fine-grained\nmessages, allowing for better overlap of computation and communication. Second,\nnovel application-specific compression techniques reduce the size of most\nmessages sent between nodes, thereby increasing effective inter-node bandwidth.\nLastly, a new hardware synchronization primitive, called a network fence,\nsupports fast fine-grained synchronization tailored to the data flow within a\nparallel MD application. These application-driven specializations to the\nnetwork are critical for Anton 3's MD simulation performance advantage over all\nother machines.", "entities_include_in_text": [], "entities_from_reference": {"persons": ["Plusieurs"], "organizations": [], "locations": [], "genpurp": []}}